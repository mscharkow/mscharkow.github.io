---
title: "Anwendungsorientierte Analyseverfahren"
author: "Prof. Dr. Michael Scharkow"
date: today
date-format: "[Sommersemester] 2025"
format: minimalist-revealjs
df-print: kable
bibliography: references.bib
csl: https://www.zotero.org/styles/apa

embed-resources: true
---

```{r child = '_common.qmd'}
```

# Sitzung 1 {#s1}

## Warum (noch) eine Vorlesung zur Statistik?

-   **Literacy**: Wenn man aktuelle Forschung lesen möchte (oder muss), führt kein Weg an etwas komplexeren Analysen vorbei.
-   **Selbstwirksamkeit**: Wer einmal eine Analyse durchgeführt hat, kann in Seminar- und Abschlussarbeiten besser Daten auswerten.
-   **Jobaussichten**: Viele AbsolventInnen berichten rückblickend, dass gerade die Methodenskills am besten verwertbar waren bei der Jobsuche und im Beruf.

## Ziele der Vorlesung

-   Studierende werden dazu befähigt, die Anwendung ausgewählter Analyseverfahren nachzuvollziehen sowie entsprechende Forschungsergebnisse und Interpretationen zu verstehen.
-   Studierende sind in der Lage, für ausgewählte Analyseverfahren anhand vorgegebener Daten Ergebnisse aus der Forschungsliteratur mittels Statistiksoftware zu reproduzieren.
-   Studierende verfügen über die die Kompetenz, Angemessenheit und Güte von methodischen Vorgehensweisen zu beurteilen.
-   (Studierende finden Statistik weniger schlimm und langweilig).

## Was die Vorlesung (nicht) ist

-   keine Wiederholung der VL Statistik oder der Datenanalyse-Übungen
-   Fokus auf das Verständnis für und die Anwendung von statistischen Verfahren, weniger die Mathematik dahinter
-   das Allgemeine Lineare Modell (GLM) als grundlegendes Verfahren
-   kein reines Ablesen von p-Werten und Signifikanz-Sternchen
-   emanzipierter Umgang mit statistischen Verfahren statt Rezepte abarbeiten

## Vorlesungsplan

```{r}
#| layout-ncol: 2
plan <- readr::read_tsv("plan.tsv") |> 
  mutate(Datum = strftime(Datum, "%d.%m.%Y"))
knitr::kable(plan[1:6, ])
knitr::kable(plan[7:12, ])
```

## Ablauf der Sitzungen und Anwesenheit

### Ablauf

1.  Besprechung der praktischen Übungen/Hausaufgabe (max. 15 min)
2.  Vorlesungsteil (max. 60 min)
3.  Fragen und Antworten zur Vorlesung und praktischen Übung

### Anwesenheit

-   keine Anwesenheitspflicht, aber auch keine Nachhilfepflicht meinerseits
-   eigenständige Nachbereitung der praktischen Übungen

## E-Learning und Studienleistung

### Material

-   Folien und Übungsmaterialien samt Daten und R-Code auf <br/> <https://stats.ifp.uni-mainz.de/ba-aa-vl>

### Studienleistung

-   während der Vorlesungszeit **3** Teil-Studienleistungen (je ca. 15 min)
-   sowohl Interpretations- als auch praktische Analyseaufgaben
-   Deadline jeweils 2 Wochen nach Aufgabenstellung, Mi 12h
-   Benotung jeweils Pass/Fail, 3x Pass nötig (ggf. Zusatzaufgabe)

## Praktische Übungen

-   zu jeder Sitzung eine praktische Übung auf Basis einer publizierten Studie
-   kurze Besprechung in der Vorlesung, meist mit einer exemplarischen Analyse
-   R-Code zum Replizieren der Analysen zuhause oder während der Vorlesung
-   praktische Anwendung als integraler Teil der Vorlesung und der Studienleistung
-   Copy & Paste/Anpassung von bestehendem Code ist ok!

## Software

-   in der VL vorgestellten Analysen lassen sich mit praktisch jeder Statistiksoftware reproduzieren
-   jede Statistiksoftware ist nur ein Werkzeug
-   Lektürekompetenz heißt auch, man kann sowohl SPSS als auch Stata oder R-Output lesen
-   wegen Verfügbarkeit und Zukunftsfähigkeit verwende ich R

### Für die Studienleistung ist irrelevant, welche Software Sie verwenden!

## Warum muss ich jetzt auch noch R lernen?

-   **Sie müssen nicht!**
-   R ist freie Software und durch viele tausend Pakete (packages) erweiterbar, u.a. für
    -   Datenerhebung: Web-Scraping, APIs (z.B. für TikTok oder Spotify), Textdaten
    -   Auswertung: Statistik, Textanalyse, Audiodaten, Psychophysiologie, etc.
    -   Datenpräsentation und -visualisierung: Grafiken, Berichte, Folien (z.B. diese)
-   grundlegende Programmierkenntnisse, die auch ohne Statistik nützlich sein können
-   das IfP hat auf R umgestellt, siehe Kurz-Websites <https://stats.ifp.uni-mainz.de/>

## Kleines R-Beispiel: Breaking Bad Deaths

Was macht dieser Code?

```{r, echo = T, eval = F}
library(tidyverse)
read_csv('https://wegweisr.haim.it/Daten/breaking_bad_deaths.csv') |>  
  count(method, sort = TRUE) |> 
  head(n = 5)
```

## Kleines R-Beispiel: Breaking Bad Deaths

Was macht dieser Code?

```{r, echo = T}
library(tidyverse)
read_csv('https://wegweisr.haim.it/Daten/breaking_bad_deaths.csv') |>  
  count(method, sort = TRUE) |> 
  head(n = 5)
```

## Literaturempfehlungen

Field, A., Miles, J., & Field, Z. (2012). Discovering statistics using R. London: Sage.

Miles, J., & Shevlin, M. (2001). Applying regression and correlation: A guide for students and researchers. London: Sage.

Darlington, R. B., & Hayes, A. F. (2016). Regression analysis and linear models: Concepts, applications, and implementation. Guilford Publications.

McElreath, R. (2020). Statistical rethinking: A Bayesian course with examples in R and Stan. CRC press. (für Interessierte)

# Refresher Inferenzstatistik

## Self-Assessment

Interpretieren Sie die folgenden Analysen:

1.  Sie vergleichen mit einem T-Test die Körpergröße zwischen Männern und Frauen. Der berechnete T-Wert: t(100) = 3.45
2.  Sie vergleichen die Hausarbeitsnoten über alle 6 Parallelkurse Inhaltsanalyse mittels Varianzanalyse: p = .074
3.  Sie berechnen die Korrelation zwischen Anwesenheit und Punkten in der Klausur: r = .41 95%-CI (.24;.58)

## Was ist Inferenzstatistik?

> "Die Inferenzstatistik (d.h. schließende Statistik) beschäftigt sich mit der Frage, wie man aufgrund von Stichprobendaten auf Sachverhalte in einer zugrundeliegenden Population schließen kann." (Eid et al., 2010, p. 191)

-   Uns interessieren Verfahren für die statistische **Punkt**- und **Intervallschätzung**.
-   Die Verfahren basieren auf bestimmten Annahmen über die Stichprobe und Variable(n).
-   Klassische (asymptotische) Inferenzstatistik basiert auf ausreichend großen Zufallsstichproben.
-   Alternative Ansätze, wie z.B. Bootstrapping, kommen mit weniger strengen Annahmen aus, sind dafür aber weniger mathematisch abgesichert und elegant.

## Ein simuliertes Beispiel

:::::: columns
::: {.column width="40%"}
### Simulation

-   Wir simulieren die Körpergröße in der Grundgesamtheit von N = 1200 Studentinnen und Studenten am IfP.
-   Dadurch können wir prüfen, wie gut unsere Schätzung der Körpergröße durch eine einzelne Stichprobe gelingt.
:::

::: {.column width="10%"}
:::

::: {.column width="50%"}
### Grundgesamtheit

```{r, fig.height = 5, fig.width = 10, echo = F}
set.seed(123)
GG <- rbeta(1200, 2, 5) * 62 + 152 ## Simulierte Grundgesamtheit mit N = 10.000
ggplot(data.frame(GG), aes(GG)) +
  geom_histogram(fill = "#999999") +
  geom_vline(xintercept = mean(GG), color = "#C1002B") +
  labs(title = "Körpergröße in der Grundgesamtheit", y = "Häufigkeit", x = paste0("Körpergröße (M = ", round(mean(GG), 0), ", SD = ", round(sd(GG), 0), ")")) +
  xlim(150, 210)
```

-   Grundgesamtheit: M = `r round(mean(GG), 0)`, SD = `r round(sd(GG), 0)`
:::
::::::

## Stichprobenziehung und -kennwerte

:::::: columns
::: {.column width="40%"}
### Eine einzelne Stichprobe

```{r}
set.seed(10)
STP <- sample(GG, 30)
STP.mean <- mean(STP)
STP.sd <- sd(STP)
```

-   Wir ziehen **eine** Zufallsstichprobe von n = 30 Studierenden und erheben deren Körpergröße.
-   In dieser Stichprobe beträgt die mittlere Körpergröße M = `r round(STP.mean)` (SD = `r round(STP.sd)`).
:::

::: {.column width="10%"}
:::

::: {.column width="50%"}
### Stichprobenkennwerte

```{r, fig.height = 5, fig.width = 10, echo = F}
## Grafische Darstellung der Körpergrößesverteilung in der Stichprobe
ggplot(data.frame(STP), aes(STP)) +
  geom_histogram(fill = "#999999") +
  geom_vline(xintercept = STP.mean, color = "#C1002B") +
  labs(title = "Körpergröße in der Stichprobe (n = 30)", y = "Häufigkeit", x = paste0("Körpergröße (M = ", round(STP.mean, 0), ", SD = ", round(STP.sd, 0), ")"))
```
:::
::::::

## Wiederholte Stichproben

:::::: columns
::: {.column width="40%"}
-   Asymptotische Inferenz basiert auf der Annahme, dass die Mittelwerte **vieler** Stichproben derselben Grundgesamtheit normalverteilt sind.
-   wir ziehen 1000 Stichproben mit jeweils n = 30
-   Blau: Mittelwert in der Grundgesamtheit, Rot: Mittelwert in der einzelnen Stichprobe
:::

::: {.column width="10%"}
:::

::: {.column width="50%"}
```{r, fig.width=10, fig.height=8}
set.seed(1223)
STPx1000 <- replicate(1000, (sample(GG, 30)))
## Mittelwerte und Standardabweichungen in den 1000 Stichproben
STPx1000.mean <- apply(STPx1000, 2, mean)
STPx1000.sd <- apply(STPx1000, 2, sd)
## Grafische Darstellung der Körpergrößesverteilung in den ersten X Stichproben
STPx1000.vis <- reshape2::melt(data.frame(STPx1000[, 1:20]), id.vars = NULL)
STPx1000.vis$facet <- rep(1:20, each = 30)
STPx1000.vis$mean <- rep(STPx1000.mean[1:20], each = 30)
ggplot(filter(STPx1000.vis, facet < 5)) +
  geom_histogram(aes(value), fill = "#999999") +
  geom_vline(aes(xintercept = mean), color = "#C1002B", size = 1.5) +
  geom_vline(aes(xintercept = 170), color = "steelblue1", size = 1.5) +
  labs(title = "Körpergröße in den ersten 4 Stichproben (n = 30)", x = "Körpergröße", y = "") +
  facet_wrap(~ paste("Stichprobe Nr.", facet), ncol = 2)
```
:::
::::::

## Stichprobenmittelwerte und SE

:::::: columns
::: {.column width="40%"}
-   Die Mittelwerte der einzelnen Stichproben streuen um den wahren Populationsmittelwert von `r round(mean(GG))` = Standardfehler (SE).

-   SE = $SD(x)/\sqrt(n-1)$, den wir anhand **einer** Stichprobe berechnen können, als Schätzer für die Streuung der Stichprobenmittelwerte.

-   SE auf Basis unserer ersten Stichprobe: SE = $11/\sqrt(29)$ = `r round(STP.sd/sqrt(29),1)`.
:::

::: {.column width="10%"}
:::

::: {.column width="50%"}
```{r}
ggplot(data.frame(STPx1000.mean)) +
  geom_histogram(aes(STPx1000.mean), fill = "#999999") +
  geom_vline(xintercept = mean(GG), color = "#C1002B") +
  labs(title = "Mittelwerte aus 1000 Stichproben mit n = 30", x = paste0("Körpergröße (M(GG) = ", round(mean(GG), 0), ", SD = ", round(sd(STPx1000.mean), 1)))
```

-   Bei unseren 1000 simulierten Stichproben ist der Mittelwert der Mittelwerte M = `r round(mean(STPx1000.mean), 1)`.
-   Die Standardabweichung der Mittelwerte ist SE = `r round(sd(STPx1000.mean),1)`.
:::
::::::

## Stichprobentheorie und -empirie

:::::: columns
::: {.column width="40%"}
-   Stichprobentheorie sagt uns wie bestimmte Kennwerte (z.B. Mittelwerte) in unendlich wiederholten Stichproben verteilt sind.
-   Diese Information können wir mit den Schätzern aus *einer* Stichprobe kombinieren.
-   Darauf basieren die Intervallschätzung und Hypothesentests.
:::

::: {.column width="10%"}
:::

::: {.column width="50%"}
```{r}
gg_df <- tibble(x = rnorm(1000000, 170, STP.sd / sqrt(29)))

ggplot(data.frame(x = STPx1000.mean), aes(x)) +
  geom_histogram(aes(y = ..density..), fill = "#999999") +
  labs(title = "Mittelwerte aus 1000 Stichproben mit n = 30", x = paste0("Körpergröße (M(GG) = ", round(mean(GG), 0), ", SD = ", round(sd(STPx1000.mean), 1))) +
  geom_density(data = gg_df, aes(x), color = "#C1002B", size = 1)
```

*Rot: Normalverteilungskurve mit Mittelwert und Standardfehler aus der ersten Stichprobe.*
:::
::::::

## Konfidenzintervalle

:::::: columns
::: {.column width="40%"}
-   basieren auf der Annahme, dass ein Schätzer einer bestimmten Verteilung folgt.
-   Bei einer Standardnormalverteilung (M = 0, SD = 1) liegen 95% aller Werte zwischen -1,96 und 1,96.
-   Wenn wir M und SE einsetzen, bekommen wir ein 95%-CI für den Mittelwert, d.h. M - 1.96xSE und M + 1.96xSE.
:::

::: {.column width="10%"}
:::

::: {.column width="50%"}
```{r}
dd <- density(rnorm(1000000, STP.mean, STP.sd / sqrt(29)))

gg_df <- tibble(x = dd$x, y = dd$y) |>
  mutate(fi = x < STP.mean - 1.96 * STP.sd / sqrt(29) | x > STP.mean + 1.96 * STP.sd / sqrt(29))

gg_df |>
  ggplot(aes(x)) +
  ## geom_histogram(aes(y = ..density..), fill = "## 999999")+
  labs(title = "Normalverteilung der Mittelwerte auf Basis einer Stichprobe") +
  geom_line(data = gg_df, aes(x, y), color = "#C1002B", size = 1) +
  geom_area(data = filter(gg_df, fi == F), aes(x, y), fill = "#999999")
```

95%-Konfidenzintervall auf Basis unserer ersten Stichprobe (M und SE): `r round(STP.mean - 1.96*STP.sd/sqrt(29),1)` - `r round(STP.mean + 1.96*STP.sd/sqrt(29),1)`
:::
::::::

## Interpretation eines Konfidenzintervalls

-   Ein 95%-Konfidenzintervall bedeutet: in 95 Prozent aller denkbaren Stichproben würde das Konfidenzintervall den wahren Populationswert enthalten.
-   Die Wahrscheinlichkeit, den wahren Wert zu enthalten, bezieht sich auf die **Konstruktion** von Konfidenzintervallen, nicht auf ein einzelnes Intervall.
-   Wir wissen aber bei einer einzigen, konkreten Stichprobe **nicht**, ob unser Konfidenzintervall den wahren Wert enthält.
-   Aber wir sind **zuversichtlich** ("confident"), dass unsere Stichprobe zu den 95% "Treffern" gehört, nicht zu den 5% Abweichlern.
-   Wenn der Wert unter der Nullhypothese nicht im Konfidenzintervall liegt, bezeichnen wir das Ergebnis als statistisch signifikant.

## Abdeckung der Konfidenzintervalle

Je größer die Stichprobe (n), desto kleiner der Standardfehler (SE), d.h. desto enger das Konfidenzintervall. Es gilt aber immer, bei 95%-CI enthalten langfristig 5 von 100 Intervallen **nicht** den Populationswert.

```{r, fig.width = 10, fig.height = 3.5}
stp100.grph <- function(input) {
  STPx100 <- replicate(100, (sample(GG, input)), simplify = F)
  STPx100.mean <- sapply(STPx100, mean)
  STPx100.sd <- sapply(STPx100, sd)
  STPx100.n <- sapply(STPx100, length)
  STPx100.se <- STPx100.sd / sqrt(STPx100.n)
  STPx100.ci <- cbind(STPx100.mean - 1.96 * STPx100.se, STPx100.mean + 1.96 * STPx100.se)
  STPx100.vis <- data.frame(STPx100.mean, STPx100.ci, STPx100.n)
  names(STPx100.vis) <- c("M", "lo", "hi", "n")
  STPx100.vis$x <- rank(STPx100.vis$M, ties.method = "random")
  STPx100.vis$n_lab <- ifelse(STPx100.vis$lo < mean(GG) & STPx100.vis$hi > mean(GG), T, F)
  ggplot(STPx100.vis) +
    geom_pointrange(aes(x, M, ymin = lo, ymax = hi, color = n_lab), size = .5) +
    geom_hline(yintercept = mean(GG), color = "#C1002B", size = 1) +
    theme(legend.position = "none") +
    labs(title = paste("Stichprobengröße n =", input)) +
    coord_cartesian(ylim = c(160, 180))
}
set.seed(1214)
a1 = stp100.grph(30)
set.seed(4)
a2 = stp100.grph(10)
library(patchwork)
a1 + a2
```

## Die Welt der Nullhypothese?

-   Im Gegensatz zu den unendlich vielen Alternativhypothesen, die man haben kann, gibt es immer nur eine Nullhypothese.
    -   Es besteht kein Unterschied/Abhängigekeit zwischen Gruppen oder Variablen.
-   Von fast allen Verfahren (T-Test, Korrelation, Chi-Quadrat-Test, etc.) wissen wir, wie die "Welt der Nullhypothese aussieht.
-   Wir prüfen Stichprobenkennwerte daraufhin, wie häufig oder wahrscheinlich sie in der Welt der Nullhypothese sind.
-   Diese Wahrscheinlichkeit ist der p-Wert.

## Was bedeutet der p-Wert?

**p(Daten\|H0)**

-   Der p-Wert ist die bedingte Wahrscheinlichkeit, die empirischen Daten (z.B. eine Mittelwertdifferenz zwischen zwei Gruppen) zu beobachten, wenn die Nullhypothese in der Grundgesamtheit gilt.
-   Beispiel bei einem t-Test für eine Mittelwertdifferenz erhalten wir einen p-Wert von p = .08. Das bedeutet, wir würden in 8 von 100 Fällen eine mindestens gleich große Differenz beobachten, auch wenn in der Grundgesamtheit gar kein Unterschied ist.

## Was bedeutet der p-Wert **nicht**?

-   **p(Daten\|H1)**: Die Wahrscheinlichkeit, die empirischen Daten zu beoachten, wenn die Alternativhypothese gilt.

-   **p(H0\|Daten)**: Die Wahrscheinlichkeit für die Richtigkeit der Nullhypothese im Lichte der Daten.

-   **p(H1\|Daten)**: Die Wahrscheinlichkeit für die Richtigkeit der Alternativhypothese im Licht der Daten.

-   Der p-Wert sagt also **nichts** über die Wahrscheinlichkeit der Null- **oder** Alternativhypothese!

außerdem:

-   Das Ablehnen der Nullhypothese sagt nichts über die Alternativhypothese!
-   Die meisten von uns interessieren sich nicht für die Frage, die der p-Wert beantwortet!

## Was bedeutet dann statistische Signifikanz?

-   Wir nennen ein Ergebnis statistisch signifikant, wenn $p < \alpha$, wobei $\alpha$ das zuvor angenommene Signifikanzniveau ist.
-   Zwei mögliche Ursachen:
    -   Die Nullhypothese gilt, aber wir beobachten zufällig ein sehr seltenes Ereignis *oder*
    -   Die Nullhypothese gilt nicht. (Das heißt nicht, die Alternativhypothese gilt.)
-   Wenn $p < .05$, sind wir zuversichtlich, dass unsere Stichprobe nicht zu den 5% Abweichlern in der Welt der Nullhypothese gehört, sondern einfach die Nullhypothese nicht stimmt.

# Fehler in der Inferenz

## Alpha- und Beta-Fehler

![Quelle: https://www.statisticssolutions.com](https://miro.medium.com/v2/resize:fit:1093/0*FZY5VvXtWRk19FAH.jpg)

## Alpha-Fehler

:::::: columns
::: {.column width="40%"}
-   Ein $\alpha = .05$ bedeutet, dass wir in 5 von 100 Fällen ein signifikantes Ergebnis bekommen, obwohl die Nullhypothese gilt.
-   Mit unseren 1000 Stichproben und $\mu_0 = 170$ sollten wir beim T-Test grob 50 fälschlich signifikante Ergebnisse bekommen.
-   Fehler ist abhängig von $\alpha$, aber unabhängig von den Daten und der konkreten $H_0$.
:::

::: {.column width="10%"}
:::

::: {.column width="50%"}
```{r}
1:1000 |>
  map(~ sample(GG, 30)) |>
  map(~ t.test(.x, mu = 170)) |>
  map_dbl("statistic") |>
  as.tibble() |>
  ggplot(aes(x = value, fill = ifelse(abs(value) > 2, "signifikant", "n.s."))) +
  geom_histogram() +
  scale_fill_manual(values = c("#999999", "#C1002B")) +
  labs(fill = "", x = "t-Wert", y = "Häufigkeit", title = "1000 Einstichproben-T-Tests (n=30)")
```

-   Problem: Wir wissen (wie immer!) nicht, ob unsere Stichprobe zu den grauen oder roten Stichproben gehört.
:::
::::::

## Beta-Fehler und statistische Power

-   Um Beta-Fehler (H0 wird fälschlich angenommen) zu verringern, brauchen wir statistische Power bzw. Präzision (vgl. Konfidenzintervalle).
-   Um die Power/Präzision eines Tests/einer Schätzung zu erhöhen, muss man zumeist die Stichprobengröße erhöhen.
-   Per Umstellung der SE-Formel kann man die nötige Stichprobengröße für erwartete Schätzer berechnen.

::: {layout-ncol="2"}
```{r}
1:1000 |>
  map(~ sample(GG, 10)) |>
  map(~ t.test(.x, mu = 175)) |>
  map_dbl("statistic") |>
  as.tibble() |>
  ggplot(aes(x = value, fill = ifelse(abs(value) > 2, "signifikant", "n.s."))) +
  geom_histogram() +
  scale_fill_manual(values = c("#999999", "#C1002B")) +
  labs(fill = "", x = "t-Wert", y = "Häufigkeit", title = "1000 Einstichproben-T-Tests (n=10)")
```

```{r}
1:1000 |>
  map(~ sample(GG, 50)) |>
  map(~ t.test(.x, mu = 175)) |>
  map_dbl("statistic") |>
  as.tibble() |>
  ggplot(aes(x = value, fill = ifelse(abs(value) > 2, "signifikant", "n.s."))) +
  geom_histogram() +
  scale_fill_manual(values = c("#999999", "#C1002B")) +
  labs(fill = "", x = "t-Wert", y = "Häufigkeit", title = "1000 Einstichproben-T-Tests (n=50)")
```
:::

## Take home message

Inferenzstatistik ‚funktioniert', weil...

-   wir die Form der Verteilung von Kennwerten bei wiederholter Durchführung von Zufallsstichproben kennen (zentrales Grenzwerttheorem) und
-   wir die Parameter der Verteilung aus den Daten unserer Stichprobe schätzen können.
-   Aber: wir kennen **nur** die Welt der Nullhypothese (egal für welchen Test und welchen Schätzer), d.h. alle Aussagen der NHST beziehen sich auf diese Welt.
-   Die Präzision unserer Schätzung bzw. Power unseres Tests hängt ab von der Streuung des Merkmals und der Größe der Stichprobe (je größer, desto präziser). Entsprechend sollten Untersuchungen geplant werden.
-   Es gibt immer Alpha- und Beta-Fehler, und für eine Stichprobe können wir nie exakt wissen, wo wir stehen.

## Hauptsache signifikant?

-   Hypothesentests als stumpfe Rituale mit dem Ziel, p \< .05 zu erhalten.
-   von Konvention zum reinen Selbstzweck (Signifikanz = gut, keine = schlecht).
-   Das sog. **p-Hacking** bedeutet, die Daten und Analysen so zu frisieren, bis ein stat. signifikantes Ergebnis erscheint.
-   Signifikanz sagt nichts über substanzielle Bedeutung!
-   Bitte in Zukunft beachten:
    -   Nicht p-hacken, nicht im Nachhinein am Alpha-Niveau schrauben!
    -   Kein Bedauern nicht-signifikanter Ergebnisse ("leider knapp nicht signifikant")!

# Fragen? {background-color="rgb(193,0,42)"}

# Sitzung 2 {#s2}

# Klassische Statistiklehre

![Quelle: https://onishlab.colostate.edu/wp-content/uploads/2019/07/which_test_flowchart.png](https://onishlab.colostate.edu/wp-content/uploads/2019/07/which_test_flowchart.png)

## Datenanalyse als Rezeptsammlung

-   In der klassischen Statistikausbildung (auch bei uns) als Rezeptesammlung:

    -   Mittelwerte in (genau) zwei Gruppen vergleichen - T-Test
    -   Mittelwerte in mehr als zwei Gruppen vergleichen - Varianzanalyse (ANOVA)
    -   Zusammenhänge von kategoriellen Variablen testen - $\chi^2$-Test
    -   ...

-   Fokus auf Unterschieden und Spezifika statt auf Gemeinsamkeiten

-   Viele Verfahren sind aber mindestens funktional, oft auch mathematisch äquivalent!

## Beispielstudie: @auty2004

> There has been little attempt to understand the influence on children of branded products that appear in television programs and movies. A study exposed children of two different age groups (6--7 and 11--12) in classrooms to a brief film clip. Half of each class was shown a scene from Home Alone that shows Pepsi Cola being spilled during a meal. The other half was shown a similar clip from Home Alone but without branded products. All children were invited to help themselves from a choice of Pepsi or Coke at the outset of the individual interviews.

## Beispielstudie: Daten

```{r, echo = F}
autylewis04 <- haven::read_sav("data/Auty_Lewis_2004.sav")
autylewis04 |> sample_n(5)
```

## Beispielstudie: Chi-Quadrat Test

### Kreuztabelle (Spaltenprozente)

```{r, echo = F}
autylewis04 |>
  group_by(pepsi_placement) |>
  count(pepsi_chosen) |>
  mutate(n = n / sum(n) * 100) |>
  spread(pepsi_placement, n) |>
  rename(no_placement = 2, placement = 3) |> 
  mutate_if(is.numeric, round)
```

\

### Chi-Quadrat Test

```{r}
table(
  autylewis04$pepsi_placement,
  autylewis04$pepsi_chosen
) |>
  chisq.test(correct = FALSE) |> 
  model_table()
```

## Beispielstudie: Bivariate Korrelation

### Pearson Korrelation

```{r}
cor.test(~ pepsi_placement + pepsi_chosen, data = autylewis04) |> 
  model_table() 
```

\

### Kendall Korrelation

```{r}
cor.test(~ pepsi_placement + pepsi_chosen, data = autylewis04, method = "kendall") |> 
  model_table() 
```

## Beispielstudie: Mittelwertvergleiche

### t-Test

```{r}
t.test(pepsi_chosen ~ pepsi_placement, data = autylewis04, var.equal = TRUE) |> 
  model_table()
```

\

### ANOVA

```{r}
aov(pepsi_chosen ~ pepsi_placement, data = autylewis04) |>
  model_table()
```

## Gemeinsamkeiten und Unterschiede

-   dieselbe Testentscheidung (signifikanter Unterschied zwischen den Gruppen bzw. signifikanter Zusammenhang zwischen Placement und Produktwahl).
-   bei 3 Verfahren exakt gleicher p-Wert (d.h. Berechnung ist identisch), beim Chi-Quadrat-Test einen (leicht) abweichenden (d.h. Berechnung ist nicht identisch).
-   die Verfahren unterscheiden sich vor allem im Modelloutput
-   manchmal nur globale Teststatistiken (Chi-Quadrat, F-, t-Wert), manchmal auch Konfidenzintervalle oder Effektgrößen
-   auch wenn es z.T. substanziell-statistische Unterschiede gibt, unterscheiden sich vor allem die Konventionen des Berichtens

# Das Allgemeine Lineare Modell <br/> (General linear model, GLM)

 

"The only formula you'll ever need." Andy Field

## Datenanalyse als statistische Modellierung

-   Datenanalyse als Anwendung und Test bestimmter statistischer **Modelle**
-   ein statistisches Modell ist eine vereinfachte Vorstellung, wie die beobachteten Daten zustande kommen (könnten)
-   wir wenden diese Modell an und prüfen, wie gut die empirischen Daten dazu passen

$$
outcome_i = Model_i + error_i
$$

-   beobachtete Daten (Outcome) als Summe von modellierten und nicht-modellierten Zusammenhängen

## Das Nullmodell

Frage: Wenn wir nur einen Schätzwert $a$ für $Y$ haben, welcher ist der beste Schätzer?

$$
Y_i = a + \epsilon_i
$$

-   das beste $a$ ist dasjenige, das den Fehler $\epsilon$ minimiert ($\epsilon_i = Y_i - a$)
-   bester Schätzer = kleinste Summe quadrierter Abweichungen $\epsilon_i$ von $y$
-   Kriterium der *least squares* -\> Ordinary Least Squares (OLS)

Antwort: Mittelwert $\bar{x}$ als der beste Modellkoeffizient im Nullmodell

Problem: damit erklärt das Modell aber nichts, es fehlt eine Prädiktorvariable $X$

## Modellformel für das GLM (bivariat)

$$
Y_i = b_0 + b_1 X_i + \epsilon_i
$$

-   Grundidee, eine Variable $Y$ (abhängige Variable, Outcome) durch ein statistisches Modell mit einem oder mehr Parametern $b$ vorhersagen zu lassen
-   Annahme: linearer Zusammenhang, d.h. $Y$ hängt nur von $b_0$ und der durch $b_1$ gewichteten (unabhängige) Prädiktorvariable $X$ ab
-   $b_0$ = Intercept = Achsenabschnitt = vorhergesagter Wert von $Y$, wenn $X = 0$
-   grundlegende Interpretation:
    -   "je mehr X, desto mehr Y", wenn $b_1 > 0$, und
    -   "je mehr X, desto weniger Y", wenn $b_1<0$.
-   es bleibt ein Vorhersage- bzw. Residualfehler $\epsilon$ (der minimiert wird)

## Modellformel für das GLM (multivariat)

$$
Y_i = b_0 + b_1 X_1 + + b_2 X_2 + b_3 X_3 + ... + \epsilon_i
$$

-   weil der Modell eine lineare Gleichung ist, können wir problemlos mehrere Prädikorvariablen $X$ hinzufügen
-   Outcome $Y$ als eine (gewichtete) Linearkombination der Prädiktorvariablen $X_1$ ... $X_k$
-   Parameter $b_1$, $b_2$, $b3$ ... sind die Gewichte, mit denen die Prädiktoren $X$ zur Vorhersage von $Y$ beitragen
-   Interpretation von jedem $b$ ist dieselbe wie im bivariaten Fall
-   Intercept $b_0$ ist der vorhergesagte Wert von $Y$, wenn **alle** $X_1 = X_2 = X_3 = 0$.

## Anwendungsfälle des GLM

-   Wenn die Prädiktorvariablen $X$ kategoriell sind, entspricht das GLM dem T-Test bzw. der Varianzanalyse.
-   Wenn die Prädiktorvariablen $X$ metrisch sind, entspricht das GLM der linearen Regression bzw. Korrelation.
-   Man kann problemlos beliebig viele kategorielle und metrische Prädiktoren mischen.
-   Die Interpretation ist immer dieselbe, d.h. man muss nur eine Interpretationsregel lernen.

## Annahmen und Erweiterungen

-   Annahme: Zusammenhang zwischen $X$ und $Y$ ist linear
    -   wenn die Annahme nicht gerechtfertigt ist, kann man auch andere funktionale Zusammenhänge modellieren, <br/>siehe Sitzung zur logistischen Regression
-   Annahme: Untersuchungseinheiten sind unabhängig voneinander
    -   wenn die Annahme verletzt ist, kann man Abhängigkeiten zwischen Fällen modellieren, <br/> siehe Sitzung zu Multilevel-Modellen

## Welche Kennziffern sind relevant?

-   Modellparameter bzw. Regressionskoeffizienten $b$ geben die geschätzten Zusammenhänge bzw. Unterschiede wieder
-   Koeffizienten haben einen Punktschätzer und einen Standardfehler bzw. ein Konfidenzintervall (Inferenzstatistik)
-   (Null-)Hypothesentests der Koeffizienten = testen, ob die beobachteten Daten zur Nullhypothese $b=0$ passen
-   Modellgütemaße wie $R^2$ quantifizieren, wie gut das statistische Modell insgesamt die Werte von $Y$ vorhersagen kann (Verhältnis von vorhergesagter und Residualvarianz)

## Modellvorhersagen

-   Regressionsmodelle sind Vorhersageinstrumente
-   mit Hilfe der Regressionskoeffizienten kann man für jede Kombination von Prädiktoren $X$ das Outcome $Y$ vorhersagen
-   Vorhersagen für einzelne Individuen oder spezifische Gruppen (siehe Sitzung Modellvorhersagen)
-   vorhergesagte Werte für die Visualisierung von Unterschieden und Zusammenhängen verwenden
-   Vorhersagen oft intuitiver zu verstehen als einzelne Parameterschätzungen

## Wie ist nun unser GLM-Rezept?

1.  Daten einlesen und Outcome $Y$ deskriptiv auswerten
2.  GLM spezifizieren (d.h. welches sind unsere Prädiktorvariablen?) und schätzen
3.  Regressionskoeffizienten interpretieren (Vorzeichen, Größe, Konfidenzintervall, stat. Signifikanz)
4.  Modellgüte und ggf. globale Teststatistik interpretieren
5.  durch das Modell vorhergesagte Werte schätzen, vergleichen, visualisieren

## Beispielstudie: GLM

### Modelloutput (Regressionstabelle)

```{r}
lm(pepsi_chosen ~ pepsi_placement, data = autylewis04) |>
  model_table()
```

## Interpretation

-   Intercept $b_0$: in der Kontrollgruppe (kein Placement, $X = 0$) vorhergesagte Wahrscheinlichkeit von .43 für Pepsi
-   Regressionskoeffizient $b_1$: bei Placement ($X = 1$) ist die vorhergesagte Wahrscheinlichkeit für Pepsi .20 **höher** als ohne Placement
-   der Regressionskoeffizient $b_1$ ist stat. signifikant (p \< .05), d.h. er deckt sich nicht mit der Nullhypothese, dass es keinen Unterschied gibt
-   Modellvorhersage bei Pepsi-Placement: $0.43 + 0.20 * 1 = .63$ in der Placement-Bedingung
-   $R^2$: das Modell kann 4% der Varianz im Outcome $Y$ erklären, der Rest bleibt unerklärt.

## Was sind die Nachteile der GLM-Perspektive?

-   viele SozialwissenschaftlerInnen haben es anders gelernt und verinnerlicht ("Warum machst du nicht T-Test statt Regression?").
-   Fachzeitschriften und Reviewer haben bestimmte Erwartungen und Vorgaben, AutorInnen präsentieren daher t-Test, ANOVA, etc.
-   für Lektürekompetenz müssen wir (leider!) weiterhin auch die anderen Verfahren interpretieren können

# Fragen? {background-color="rgb(193,0,42)"}

# Sitzung 3 {#s3}

# Fragen zur praktischen Übung?

## Korrelation, Regression und GLM

-   historisch zwei unterschiedliche Ansätze, den Zusammenhang zweier metrischer Variablen zu analysieren: Korrelation und Regression
-   Korrelation basiert auf der Idee der Kovarianz, d.h. dem "gemeinsamen Variieren" zweier Variablen
-   bivariate Regression als GLM, bei dem ein metrisches Outcome $Y$ durch eine metrische Prädiktorvariable $X$ vorhergesagt werden soll

## Form des Zusammenhangs

```{r}
#| fig-align: center
anscombe |>
  pivot_longer(
    cols = everything(),
    names_to = c(".value", "set"),
    names_pattern = "(.)(.)"
  ) |>
  ggplot(aes(x = x, y = y)) +
  geom_smooth(method = "lm", alpha = .33, color = "#C1002A") +
  geom_point(alpha = .67, size = 3) +
  facet_wrap("set") +
  labs(title = "Anscombe's quartet (r = .82)")
```

## Regressions- vs. Korrelationskoeffizienten

-   unstandardisierter Regressionskoeffizient $B$ als Anstieg, d.h. zunächst Richtung des Zusammenhangs
-   Korrelationskoeffizient $r$ als Effektstärke, d.h. wie nahe die Werte von $Y$ der Regressionsgeraden sind
-   starker Zusammenhang = wenig Residualvarianz = hohe Korrelation $r$ = hohe Varianzaufklärung $R^2$

## Unterschiedlich starke Zusammenhänge

```{r}
#| fig-align: center
c(0, .3, .5, .8) |>
  map_df(~ faux::rnorm_multi(n = 100, r = .x, varnames = c("x", "y"), empirical = FALSE), .id = "set") |>
  mutate(set = factor(set, levels = 1:4, labels = paste0("r=", c(0, .3, .5, .8)))) |>
  ggplot(aes(x = x, y = y)) +
  geom_smooth(method = "lm", alpha = .33, color = "#C1002A") +
  geom_point(alpha = .67, size = 2) +
  facet_wrap("set")
```

## Korrelationsmatrizen

![Quelle: Scharkow, Festl, Vogelgesang & Quandt, 2013](images/scharkow13.png){fig-align="center"}

## Mal wieder: Korrelation und Kausalität

![Quelle: https://www.cjr.org/tow_center_reports/the_curious_journalists_guide_to_data.php](images/dj31.png){fig-align="center"}

## Bivariate Regression

-   linearer Zusammenhang zwischen $X$ und $Y$ wieder, wobei *wir* definieren, was Prädiktor $X$ und was Outcome $Y$ ist
-   die Modellformel wie immer: $$ Y_i = b_0 + b_1 X_i + \epsilon_i $$
-   $b_0$ ist der vorhergesagte Wert von $Y$, wenn $x=0$
-   $b_1$ ist der vorhergesagte Anstieg von $Y$, wenn $X$ um eine Einheit steigt (d.h. der Ansteig in Originalmetrik)
-   ändert sich die Metrik von $X$ oder $Y$, ändert sich die Interpretation von $b_1$

## Intercepts und Zentrierung

-   Intercept bzw. Konstante als vorausgesagte Wert von $Y$, wenn $X=0$
-   nur sinnvoll zu interpretieren, wenn $X$ auch die Ausprägung 0 haben kann
-   man kann $X$ *zentrieren*, z.B. von allen Werten $x_i$ eine Konstante $c$ subtrahieren, dann ist Intercept der vorausgesagte Wert für $x = c$
-   häufigste Zentrierung ist die **Mittelwertzentrierung**, d.h. $c = \bar{x}$, der Intercept bezieht sich auf den durchschnittlichen Wert von $X$
-   Zentrierung ändert nichts an den Regressionskoeffizienten oder am Globalfit, sondern nur am Intercept

## Effektgrößen und Modellgüte

-   jeder Koeffizient $B$ hat einen Standardfehler SE(B) und ein Konfindenzintervall
-   mit beiden lässt sich $H_0$ prüfen können, dass *kein* linearer Zusammenhang existiert - bzw. ob die Daten sich mit $B=0$ decken
-   $B$ lässt sich substantiell in der Metrik von $Y$ interpretieren (eine Einheit mehr/weniger $X$ entspricht $B$ Einheiten mehr/weniger $Y$), er sagt aber nichts über die Stärke des Zusammenhangs oder Modellgüte
-   wie gut das lineare Modell (im Vergleich zum Nullmodell ohne Prädiktoren) vorhersagt, kann man am $R^2$ erkennen
-   im bivariaten Fall entspricht das exakt dem quadrierten Korrelationskoeffizienten $r_{XY}$

## Unstandardisierte B vs. standardisierte Beta

-   Interpretation von unstandardisiertem $B$ setzt voraus, dass wir die Metriken von $X$ und vor allem $Y$ kennen
-   oft wird (z.B. für Vergleiche oder Meta-Analysen) ein standardisiertes Maß gewünscht, das unabhängig von $X$ und $Y$ ist
-   wir können Regressionskoeffizienten standardisieren, in dem wir
    -   entweder die Daten $X$ und $Y$ *vor der Analyse* z-standardisieren (M = 0, SD = 1)
    -   oder den Koeffizienten selbst standardisieren, durch $\beta = b \frac{s_x}{s_y}$
-   im bivariaten Fall (nur dort!) entspricht $\beta$ dem Korrelationskoeffizienten $r$

## Korrelation vs. bivariate Regression/GLM

-   $r$ als standardisierte Größe, d.h. auch ohne Kenntnis der Skalen von $X$ und $Y$ interpretierbar
-   Korrelationsanalyse verführt ggf. weniger zu kausalen (Fehl-)Interpretationen als ein GLM mit unabhängiger und abhängiger Variable
-   bei Korrelationen sind alternative Verfahren für nicht-metrische Daten (z.B. Spearmans Rangkorrelation) verbreitet
-   beim GLM bekommt mehr Informationen: unstandardisierte Effektgrößen (inkl. Intercept)
-   beide Verfahren liefern dieselben Schätzer und dieselben Testentscheidungen, basieren auf denselben Annahmen

## Beispielstudie @johannes2022:

![](images/johannes_etal22.png)

## Daten

:::::: columns
::: {.column width="45%"}
```{r}
johannes22 <- haven::read_sav("data/Johannes_2022.sav")
johannes22 |>
  select(tv_time, age, games_time, music_time) |> 
  head()
```
:::

::: {.column width="10%"}
:::

::: {.column width="45%"}
```{r}
johannes22 |>
  select(tv_time, age, games_time, music_time) |> 
  report::report_sample()
```
:::
::::::

## Outcome-Variable

```{r}
johannes22 |>
  ggplot(aes(x = music_time)) +
  geom_histogram()
```

## Scatterplot

```{r}
#| fig-align: center
johannes22 |>
  ggplot(aes(x = age, y = music_time)) +
  geom_point(alpha = .3) +
  geom_smooth(method = "lm")
```

## Korrelation samt Hypothesentest

```{r}
cor.test(~ age + music_time, data = johannes22) |> 
  model_table()
```

## Bivariate lineare Regression

```{r}
lm(music_time ~ age, data = johannes22) |> 
  model_table()
```

::: aside
Reminder: t-Wert = $B/SE(B)$

Interpretation: stat. signifikant, wenn t \< -1.96 oder \> 1.96 (kritischer Wert der Normalverteilung)
:::

```{r}
johannes22 <- johannes22 |>
  mutate(
    age18 = age - 18,
    age_centered = age - mean(age, na.rm = TRUE),
    age_zstd = scale(age),
    music_time_zstd = scale(music_time),
    music_time_m = music_time * 60,
    books_time_m = books_time * 60
  )
```

## Zentrierung Alter = 18

```{r}
lm(music_time ~ age18, data = johannes22) |> 
  model_table()
```

## Mittelwertzentrierung

```{r}
lm(music_time ~ age_centered, data = johannes22) |> 
  model_table()
```

## Transformierte Y-Variable (Minuten)

```{r}
lm(music_time_m ~ age_centered, data = johannes22) |> 
  model_table()
```

## Z-standardisierte Variablen

```{r}
lm(music_time_zstd ~ age_zstd, data = johannes22) |> 
  model_table()
```

# Sitzung 4 {#s4}

# Fragen zur praktischen Übung?

## Wiederholung: TV Time (h/Tag)

```{r}
johannes22 <- haven::read_sav("data/Johannes_2022.sav")
lm(tv_time ~ age, data = johannes22) |> 
  model_table()
```

::: aside
Daten: Johannes et al., 2022
:::

## Mittelwerte vergleichen

-   in Experimenten werden oft Mittelwerte einer oder mehrerer Outcome-Variablen $Y$ zwischen verschiedenen Versuchsbedingungen verglichen.
-   auch in nicht-experimentellen Analysen sind Mittelwertvergleiche häufig
-   Nullhypothese, dass zwischen den Gruppen kein Unterschied besteht, d.h. die Mittelwerte sich nicht unterscheiden
-   meistverwendet: t-Test oder einfaktorielle Varianzanalyse

## Dichotome Prädiktoren

-   Gruppierungsvariable wird in eine Dummy-Variablen recodiert (0 = Merkmal nicht vorhanden, 1 = Merkmal vorhanden)
-   Dummy-Variable wird in das Regressionsmodell aufgenommen: $Y_i = b_0 + b_1 X_i + \epsilon_i$
-   Referenzgruppe ($X = 0$), ergibt $Y = b_0$ (Intercept = Mittelwert der Kontrollgruppe)
-   $b_1$ als Differenz zwischen der Gruppe 1 und der Referenzgruppe
-   t-Wert (B/SE(B) des Regressionskoeffizienten exakt wie beim t-Test

## Alternative Codierung für X

-   Dummy-Codierung als meistverbreitete, aber nicht einzige Art, kategorielle Variablen abzubilden
-   wichtig ist nur, dass
    -   unterschiedliche Gruppen unterschiedliche Zahlenwerte erhalten
    -   klar ist, was ein Unterschied von 1 bedeutet (Interpretation Regressionskoeffizient)
    -   der Intercept sinnvoll interpretierbar ist
-   Beispiel: **simple coding** mit -0.5 und 0.5 bei zwei Gruppen (vgl. Zentrierung) - <br/> $b_0$ ist der Gesamtmittelwert, $b_1$ wieder der Unterschied zwischen den Gruppen

::: aside
Beispiele: <https://stats.oarc.ucla.edu/r/library/r-library-contrast-coding-systems-for-categorical-variables/>
:::

## Mehr als zwei Mittelwerte vergleichen

-   traditionell die einfaktorielle Varianzanalyse (ANOVA) als Standardauswertung
-   F-Test der Varianzanalyse prüft die Nullhypothese, dass *alle* Mittelwerte gleich sind (keine Unterschiede zwischen den Gruppen)
-   Alternativhypothese ("Irgendwelche Gruppen unterscheiden sich in $Y$") oft theoretisch sehr unbefriedigend
-   weil der F-Test nicht sagt, *welche* Gruppen sich im Mittelwert von $Y$ signifikant unterscheiden, ist oft ein zweiter Analyseschritt nötig
-   Post-hoc-Tests oder Kontraste, d.h. (ausgewählte oder alle) paarweisen Vergleiche zwischen zwei Gruppen

## GLM mit mehr als zwei Gruppen

-   um $k$ Gruppen zu vergleichen, werden $k-1$ Prädiktor-Variablen erstellt (vor oder automatisch während der Analyse)
-   die $k-1$ Variablen werden in das Regressionsmodell aufgenommen: $Y_i = b_0 + b_1 X_1 + b_2 X_2 + ... + b_{k-1} X_{k-1} + \epsilon_i$.
-   in der Referenzgruppe (alle $X_1 = X_2 = ... = 0$) ergibt sich $Y = b_0$ (Intercept = Mittelwert der Referenzgruppe)
-   $b_1$ gibt (bei Dummy-Codierung) die Differenz zwischen der Gruppe 1 und der Referenzgruppe wider, $b_2$ die Differenz zwischen der Gruppe 2 und der Referenzgruppe, etc.
-   man kann mehrere, aber **nicht alle** paarweisen Vergleiche gleichzeitig modellieren

## Dummy-Codierung 4 Gruppen

::::: {layout-ncol="2"}
::: column
### Gruppe A als Referenz

```{r}
x = paste("Gruppe", c("A", "B", "C", "D")) |> factor()
contrasts(x) |> as.data.frame() |> rownames_to_column("Zugehörigkeit")
```
:::

::: column
### Gruppe D als Referenz

```{r}
relevel(x, "Gruppe D") |> 
contrasts() |> as.data.frame() |> rownames_to_column("Zugehörigkeit")
```
:::
:::::

## Kontraste durch gezielte Codierung

-   spezifische Kontraste durch verschiedene Codierungen für die Prädiktorvariablen (vgl. Davis, 2010)
-   einfache Alternative: Referenzgruppe ändern, Modell neu schätzen
-   zahlreiche z.T. komplexe Codierungsverfahren, um z.B. ordinale Gruppenvariablen abzubilden
-   Beispiel: **Helmert coding** , bei dem eine Gruppe mit jeweils allen nachfolgenden Gruppen verglichen werden,
    (1) Kontrollgruppe mit allen Treatments
    (2) Treatment 1 mit Treatment 2, etc.

::: aside
Beispiele: <https://stats.oarc.ucla.edu/r/library/r-library-contrast-coding-systems-for-categorical-variables/>
:::

## Post-hoc-Tests

-   für kategorielle Prädiktoren kann man anhand des geschätzten Modells alle Mittelwerte paarweise vergleichen
-   entspricht separaten T-Tests mit je zwei Gruppen
-   aufgrund der Vielzahl einzelner Tests erhöht sich die Gefahr von Alpha-Fehlern (d.h. irrtümlich signifikante Ergebnisse)
-   p-Werte (manchmal auch die CI) sollten daher korrigiert werden sollten (vgl. Bender & Lange, 2001)
-   verschiedenste Korrekturverfahren möglich (Bonferroni, Hochberg), eines sollte gewählt werden

## GLM vs. t-Test/ANOVA

### Vorteile

-   keine unterschiedliche Nomenklatur und Testverfahren, egal ob 2 oder mehr Gruppen
-   $b$-Koeffizienten sind direkt als Mittelwertdifferenzen zwischen Gruppen interpretierbar, d.h. oft sind Post-Hoc-Tests unnötig
-   beliebig erweiterbar durch weitere kategorielle und metrische Prädiktoren
-   oft wird der globale F-Test sowie das $R^2$ als Effektstärkemaß zusätzlich ausgegeben

### Nachteile

-   Konvention und Fachgeschichte, d.h. GutachterInnen erwarten ANOVA oder t-Test
-   Dummy-Codierung (oder andere Effekt-Codierungen) machen ggf. Zusatzaufwand

## Beispielstudie: @kümpel2019

> Coming across news on social network sites (SNS) largely depends on news-related activities in one's network. Although there are many different ways to stumble upon news, limited research has been conducted on how distinct news curation practices influence users' intention to consume encountered content. In this mixed-methods investigation, using Facebook as an example, we first examine the results of an experiment (study 1, n = 524), showing that getting tagged in comments to news posts promotes news consumption the most.

## Daten

```{r, echo = F}
library(tidyverse)
kuempel19 <- haven::read_sav("data/Kuempel_2019.sav") |>
  select(
    modus = Kurationsmodus_SNS,
    rw = Rezeptionswahrscheinlichkeit
  ) |>
  mutate(
    modus = as_factor(modus) |> relevel("Chronik"), # Faktor mit Referenz Chronik
    modus_tag = ifelse(modus == "Tag", 1, 0), # Dummy-Variable
    rw = as.numeric(rw) # Numerische Variable
  ) |>
  haven::zap_labels()

```

:::::: columns
::: {.column width="45%"}
```{r}
kuempel19 |> head()
```
:::

::: {.column width="10%"}
:::

::: {.column width="45%"}
### Outcome-Variable

```{r}
kuempel19 |>
  select(rw) |> 
  report::report_sample()
```

\

### Gruppenmittelwerte

```{r}
kuempel19 |>
  group_by(modus) |>
  summarise(
    n = n(),
    M = mean(rw, na.rm = TRUE),
    SD = sd(rw, na.rm = TRUE)
  )
```
:::
::::::

## Outcome-Variable

```{r}
kuempel19 |>
  ggplot(aes(x = rw)) +
  geom_histogram()
```

## t-Test

```{r}
t.test(rw ~ modus_tag, data = kuempel19, var.equal = TRUE) |>
  model_table()
```

## GLM mit zwei Gruppen

```{r}
m1_tag <- lm(rw ~ modus_tag, data = kuempel19)
model_table(m1_tag)
```

## ANOVA mit vier Gruppen

```{r}
aov(rw ~ modus, data = kuempel19) |>
  model_table()
```

## GLM mit vier Gruppen

```{r}
m2_modus <- lm(rw ~ modus, kuempel19)
model_table(m2_modus)
```

## Referenzkategorie ändern

```{r}
kuempel19 <- kuempel19 |>
  mutate(modus_dm = relevel(modus, "DM"))

m2_modus_dm <- lm(rw ~ modus_dm, kuempel19)
model_table(m2_modus_dm)
```

## Post-hoc/Kontraste

```{r}
posthocs = marginaleffects::avg_comparisons(m2_modus,
  variables = list(modus = "pairwise")
) 
p_adj =  marginaleffects::hypotheses(posthocs, multcomp = "bonferroni") 


posthocs |> 
  as_tibble() |> 
  mutate(p_adjusted = p_adj$p.value) |> 
  select(-s.value)

#m2_modus |> 
#  marginaleffects::hypotheses( ~ pairwise, multcomp = "bonferroni")
```

::: aside
p-Werte (adjusted) mit Bonferroni-Korrektur
:::

## Vorhergesagte Mittelwerte

```{r}
marginaleffects::avg_predictions(m2_modus, variables = "modus") |> 
  as_tibble() |> 
  select(-s.value)
```

## Visualisierungsvorschlag

```{r}
marginaleffects::avg_predictions(m2_modus, variables="modus") |> 
  ggplot(aes(x = modus, y = estimate))+
  geom_pointrange(aes(ymin = conf.low, ymax = conf.high))+
  labs(x  = "Versuchsbedingung", y = "Vorhergesagte Rezeptionswahrscheinlichkeit", caption = "Daten: Kümpel (2019)")
```

# Fragen?

## Literatur

Bender, R., & Lange, S. (2001). Adjusting for multiple testing---when and how?. Journal of clinical epidemiology, 54(4), 343-349.

Davis, M. J. (2010). Contrast coding in multiple regression analysis: Strengths, weaknesses, and utility of popular coding structures. Journal of data science, 8(1), 61-73.

Kümpel, A. S. (2019). Getting tagged, getting involved with news? A mixed-methods investigation of the effects and motives of news-related tagging activities on social network sites. Journal of Communication, 69(4), 373-395.

## Take-home Aufgabe #1

Wir vergleichen die Tanzbarkeit (danceability) und musikalische Stimmung (valence) der Top 10-Hits über 4 Dekaden (1990er bis 2020er) auf Basis von Billboard und Spotify-Daten.

Beide Variablen sind von 0 (niedrig) - 100 (hoch) skaliert. Die Mittelwerte und Fallzahlen pro Dekade sind wie folgt:

\

```{r, echo = F}
library(tidyverse)
bb <- readr::read_csv("https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2021/2021-09-14/billboard.csv")
af <- readr::read_csv("https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2021/2021-09-14/audio_features.csv")
top <- bb |>
  filter(str_detect(week_id, "199|200|201|202")) |>
  filter(week_position <= 10) |>
  left_join(af) |>
  mutate(
    year = str_extract(week_id, "/(\\d+)$") |> parse_number(),
    decade = substr(year, 1, 3) |> paste0("0s")
  ) |>
  distinct(decade, spotify_track_id, .keep_all = T) |>
  select(decade, song, performer, danceability, valence, speechiness, energy) |>
  mutate_if(is.numeric, ~ . * 100) |>
  na.omit()

top |>
  select(decade, danceability, valence) |>
  group_by(decade) |>
  summarise_at(vars(danceability, valence), mean) |>
  left_join(top |> count(decade))
```

## Studienleistung, Teil 1

(1) Interpretieren sie die Ergebnisse der **beiden** linearen Modelle, in denen die Mittelwertunterschiede getestet werden, Zeile für Zeile.

(2) Welche Dekaden werden *nicht* miteinander verglichen, d.h. für diese bräuchten wir Post-Hoc Vergleiche?

Lösung bitte bis 04.06.2025, 10 Uhr in Moodle eintragen.

\

:::::: columns
::: {.column width="50%"}
```{r, echo=FALSE}
lm(danceability ~ decade, data = top) |>
  sjPlot::tab_model(show.ci = F, show.se = T, emph.p = F, show.r2 = F, show.obs = F, string.est = "Coefficient (B)", string.se = "SE (B)")
```
:::

::: {.column width="5%"}
:::

::: {.column width="45%"}
```{r, echo=FALSE}
top <- top |> mutate(decade = relevel(factor(decade), "2020s"))
lm(valence ~ decade, data = top) |>
  sjPlot::tab_model(show.r2 = F, show.obs = F, show.p = F, string.est = "Coefficient (B)", string.ci = "95% CI (B)")
```
:::
::::::

# Sitzung 5 {#s5}

# Fragen zur praktischen Übung?

## Wiederholung: Facebook-News

```{r}
kuempel19 <- haven::read_sav("data/Kuempel_2019.sav") |>
  select(
    modus = Kurationsmodus_SNS,
    rw = Rezeptionswahrscheinlichkeit
  ) |>
  mutate(
    modus = as_factor(modus) |> relevel("Tag"), # Faktor mit Referenz Chronik
    modus_tag = ifelse(modus == "Tag", 1, 0), # Dummy-Variable
    rw = as.numeric(rw) # Numerische Variable
  ) |>
  haven::zap_labels()

lm(rw ~ modus, data = kuempel19) |> 
  model_table()
```

::: aside
Outcome: Rezeptionswahrscheinlichkeit, Referenzkategorie: Tagging, Daten: Kümpel, 2019
:::

## Multiple Regression und das GLM

-   im GLM können mehrere Prädiktorvariablen in einem Modell kombiniert werden
-   die Regressionskoeffizienten $B$ sind wie sonst auch zu interpretieren, mit der Annahme, dass die anderen Prädiktoren sich nicht ändern ("ceteris paribus")
-   der Intercept $B_0$ ist der erwartete Wert von $Y$, wenn **alle** Prädiktoren $X=0$ sind
-   das $R^2$ ist die durch *alle* Prädiktoren erklärte Varianz in $Y$, d.h. nicht mehr nur die quadrierte Korrelation von $X$ und $Y$
-   der F-Test ist nun ein Omnibustest, d.h. er prüft, ob *irgendeine* Variable $X$ einen signifikanten Zusammenhang mit $Y$ hat

## Multiple vs. viele bivariate Regressionen

-   in klassischen Befragungsstudien haben wir oft mehrere plausible Prädiktoren
-   eine multiple Regression vermeidete unnötig viele Einzeltests
-   technisch ist es trivial, mehrere Prädiktoren ins Modell zu nehmen
-   die Zusammenhänge zwischen Prädiktoren und Outcome werden unter Berücksichtigung der anderen Variablen im Modell geschätzt (Drittvariablenkontrolle)
-   ein Modell mit mehreren Prädiktoren kann besser $Y$ voraussagen als ein Modell mit weniger Prädiktoren

## Regressionskoeffizienten

-   bei multiplen Regressionen sollten standardisierte und unstandardisierte Regressionskoeffizienten berichtet werden
-   **unstandardisierte** Koeffizienten lassen sich
    (1) in der Originalmetrik von $X$ und $Y$ interpretieren *und*
    (2) sind beim Vergleich von Modellen mit verschiedenen $Y$, aber denselben $X$ sinnvoll
-   **standardisierte Koeffizienten** sind sinnvoll, um
    (1) generell die Größe der Effekte abschätzen und
    (2) *innerhalb* desselben Modells den relativen Einfluss verschiedener Variablen vergleichen zu können

## Drittvariablen & Multikollinearität

-   durch Hinzunahme einer weiteren $X_2$ Prädiktorvariable wird deren gemeinsamer Einfluss auf $X_1$ und $Y$ in der Schätzung berücksichtigt
-   eine statistische Berücksichtigung ist jedoch keinesfalls mit einer kausalen Berücksichtigung oder Konstanthaltung zu verwechseln
-   wenn $X_1$ und $X_2$ untereinander korrelieren, sprechen wir von Multikollinearität
-   obwohl die Schätzer $B_1$ und $B_2$ unverzerrt sind, wird die Präzision bei Multikollinearität geringer, d.h. die Standardfehler größer
-   Multikollinearität ist *kein* statistisches Problem und kann daher auch nicht statistisch (z.B. durch Zentrierung) gelöst werden, sondern nur durch Änderungen in der Messung oder Variablenauswahl

## Modellgüte: $R^2$ und F-Test

-   im bivariaten Fall entspricht das $R^2$ dem Determinationskoeffizienten $r^2$, also der quadrierten Korrelation
-   alternative Herleitung als Verhältnis von erklärter (modellierter) und nicht erklärter (Residual-) Varianz
-   Beispiel Nullmodell: keine Erklärungskraft, d.h. Residualvarianz $var(\epsilon) = var(Y)$, also Gesamtvarianz von $Y$
-   $R2 = 1 - var(\epsilon)/var(Y)$, d.h. Anteil erklärter Varianz, den *alle* Prädiktoren zusammen ermöglichen
-   F-Test: ist der Anteil erklärter Varianz signifikant von 0 verschieden

## Korrigiertes $R^2$

-   ein lineares Regressionsmodell wird durch Hinzunahme einer zusätzlichen Prädiktorvariable *nie* schlechter
-   d.h. das naive $R^2$ kann durch zusätzliche Prädiktoren nur ansteigen oder sich schlimmstenfalls nicht (sichtbar) ändern, aber nie sinken
-   würde man nun verschiedene Modelle miteinander vergleichen, würde das komplexere (= mehr Prädiktoren) Modell besser abschneiden, obwohl wir erkenntnistheoretisch eher an Modellsparsamkeit interessiert sind
-   daher betrachten wir bei multiplen Regressionen immer ein (durch die Anzahl Prädiktoren $k$) korrigiertes $\bar R^2 = 1-(1-R^2){n-1 \over n-k-1}$

## Schrittweise oder hierarchische Regression

-   manchmal werden Regressionsmodelle schrittweise geschätzt, d.h. einzelne Prädiktoren (oder Prädiktorenblöcke) nacheinander in das Modell eingeführt
-   Differenz $\Delta$ im $R^2$ und/oder ein sog. partieller F-Test durchgeführt, der prüft, ob die Hinzunahme der Prädiktoren das Modell signifikant verbessert hat
-   in der Schätzung der Regression gibt es **keine Reihenfolge-Effekte**, d.h. das finale Modell ist immer dasselbe, egal, ob man mit $X_1$ oder $X_2$ startet
-   grundsätzlich nur die Regressionskoeffizienten aus dem finalen Modell interpretieren, das alle theoretisch postulierten Variablen enthält
-   Vorteil schrittweise Testung: Übersichtlichkeit der Darstellung, Nachteil: unnötig viele Zwischenschritte, voreilige Interpretationen

## Beispiel @kümpel2019

![](images/kuempel_hier.png){fig-align="center"}

## Partieller F-Test

-   globaler F-Test als Modellvergleich: Residualvarianz mein Modell vs. Nullmodell
-   partieller F-Test: Modell 1 vs. Modell 2 (wobei Modell 2 auch alle Prädiktoren von 1 enthalten muss)
-   Interpretation, wenn der F-Test signifikant ist: Modell 2 kann sig. mehr Varianz in $Y$ erklären als Modell 1
-   Modell 2 ist damit auch signifikant besser darin, $Y$ vorauszusagen

## Kitchen-sink regression

-   oft ist es verführerisch, einfach möglichst viele (plausible) Prädiktoren ins Modell aufzunehmen
-   Problem 1: Gefahr von Multikollinearität steigt, weil viele Variablen untereinander korrelieren
-   Problem 2: durch falsche Einbeziehung von sog. Collider-Variablen, die von $X$ und $Y$ beeinflusst werden, werden die Schätzungen verzerrt (vgl. Sitzung zu Annahmen)
-   Problem 3: sehr umfangreiche Regressionstabellen, die gelesen werden müssen

## Beispiel: @vanerkel2021

> Does exposure to news affect what people know about politics? This old question attracted new scholarly interest as the political informa- tion environment is changing rapidly. In particular, since citizens have new channels at their disposal, such as Twitter and Facebook, which increasingly complement or even replace traditional channels of information. This study investigates to what extent citizens have knowledge about daily politics and to what extent news on social media can provide this knowledge. It does so by means of a large online survey in Belgium (Flanders), in which we measured what people know about current political events, their so-called general surveillance knowledge. Our findings demonstrate that unlike following news via traditional media channels, citizens do not gain more political knowledge from following news on social media. We even find a negative association between following the news on Facebook and political knowledge.

## Daten

```{r}
vanerkel21 <- haven::read_sav("data/Vanerkel_Vanaelst_2021.sav") |>
  mutate(
    Education = as_factor(Education),
    Gender = as_factor(Gender)
  ) |>
  haven::zap_labels()

vanerkel21 |>
  select(Age, Gender, Education,  TV, Newspaper, Websites, Facebook, PK) |> 
  sample_n(5)
```

## Deskriptivstatistik

```{r}
vanerkel21 |>
   select(Age, Gender, Education,  TV, Newspaper, Websites, Facebook, PK) |> 
  report::report_sample()
```

## Outcome-Variable

```{r}
vanerkel21 |>
  ggplot(aes(x = PK)) +
  geom_histogram()
```

## Regressionsmodell I (nur Soziodemographie)

```{r}
m1_socdem <- lm(PK ~ Gender + Age + Education, data = vanerkel21)
model_table(m1_socdem)
```

## Regressionsmodell II (Mediennutzung)

::: scrollable
```{r}
m2_media <- lm(PK ~ Gender + Age + Education +  TV + Newspaper + Websites + Facebook + Twitter, data = vanerkel21)
model_table(m2_media)
```
:::

## Partieller F-Test (Modellverbesserung)

```{r}
anova(m1_socdem, m2_media)|> 
  as.data.frame() |> 
  rownames_to_column("Modell")
```

## Bonus: Visualisierung der Ergebnisse

:::::: columns
::: {.column width="45%"}
```{r, fig.asp=1, fig.width=7 }
sjPlot::plot_model(m2_media, type = "est") + labs(
  title = "Predicting political knowledge",
  subtitle = "OLS regression (unstandardized)", y = "Unstandardized coefficient",
  caption = "n = 987"
)
```
:::

::: {.column width="10%"}
:::

::: {.column width="45%"}
```{r, fig.asp=1, fig.width=7 }
sjPlot::plot_model(m2_media, type = "std") + labs(
  title = "Predicting political knowledge",
  subtitle = "OLS regression (standardized)", y = "Standardized coefficient",
  caption = "n = 987"
)
```
:::
::::::

## Literatur
