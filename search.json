[
  {
    "objectID": "ccs/index.html#description",
    "href": "ccs/index.html#description",
    "title": "MA Computational Communication Science",
    "section": "Description",
    "text": "Description\nComputational communication science focuses on analyzing communication processes and structures using computational methods such as automated content analysis or agent-based modeling.\nIn this seminar, we will examine key concepts, theoretical foundations, and empirical studies within this research field. We will also apply computational methods in practical exercises to better understand how they can be used to investigate media content and processes of media use."
  },
  {
    "objectID": "ccs/index.html#schedule",
    "href": "ccs/index.html#schedule",
    "title": "MA Computational Communication Science",
    "section": "Schedule",
    "text": "Schedule\n\n\n\n\n\n\n\n\n\n\n\nSitzung\nDatum\nThema\n\n\n\n\n1\n23.04.2025\nIntroduction\n\n\n2\n30.04.2025\nCCS Paper Potpourri\n\n\n3\n07.05.2025\nEthical and legal perspectives\n\n\n4\n21.05.2025\nDigital trace data\n\n\n5\n28.05.2025\nDigital trace data\n\n\n6\n04.06.2025\nAutomatic content analysis\n\n\n7\n11.06.2025\nAutomatic content analysis\n\n\n8\n18.06.2025\nAutomatic content analysis\n\n\n9\n25.06.2025\nAutomatic content analysis\n\n\n10\n02.07.2025\nSimulation and computational experiments\n\n\n11\n09.07.2025\nSimulation and computational experiments\n\n\n12\n16.07.2025\nQ & A"
  },
  {
    "objectID": "ccs/index.html#1",
    "href": "ccs/index.html#1",
    "title": "MA Computational Communication Science",
    "section": "Session 1 ",
    "text": "Session 1 \n\nTopics\n\nIntroduction, course structure, credits\nWhat is Computational Communication Science?\n\n\n\nReading\nHilbert et al. (2019); Lazer et al. (2009)\n\n\nTasks for the next session\nSelect a study on Moodle and repare a poster (A1) for the study you selected."
  },
  {
    "objectID": "ccs/index.html#2",
    "href": "ccs/index.html#2",
    "title": "MA Computational Communication Science",
    "section": "Session 2 ",
    "text": "Session 2 \n\nTopics\nPoster Session: Interesting studies in computational communication science."
  },
  {
    "objectID": "ccs/index.html#3",
    "href": "ccs/index.html#3",
    "title": "MA Computational Communication Science",
    "section": "Session 3 ",
    "text": "Session 3 \n\nTopics\n\nBasic of research ethics\nApplication of ethical principles to computational research\nRisks in computational research on, with and by big social media platforms\n\n\n\nReading\nSalganik (2018, Ch. 6); Freelon (2018); 2025 Reddit/AI experiment\n\n\nTasks for the next session\nRefresh your R skills."
  },
  {
    "objectID": "ccs/index.html#4",
    "href": "ccs/index.html#4",
    "title": "MA Computational Communication Science",
    "section": "Session 4 ",
    "text": "Session 4 \n\nTopics\n\nbasics of digital trace data\nanalyzing digital download packages (DDP)\n\n\n\nReading\nOhme et al. (2023)\n\n\nTasks for the next session\n\nComplete the first coding assignments in R.\nWork through the second chapter on digital trace data in R."
  },
  {
    "objectID": "ccs/index.html#5",
    "href": "ccs/index.html#5",
    "title": "MA Computational Communication Science",
    "section": "Session 5 ",
    "text": "Session 5 \n\nTopics\n\nanalyzing large-scale digital trace data\ncombining trace data with survey or content analysis data\n\n\n\nReading\nParry & Toth (2025);Clemm von Hohenberg et al. (2024)"
  },
  {
    "objectID": "ccs/index.html#6",
    "href": "ccs/index.html#6",
    "title": "MA Computational Communication Science",
    "section": "Session 6 ",
    "text": "Session 6 \n\nTopics\n\ncollecting data for content analysis\nautomatic content analysis basics\n\n\n\nReading\nVan Atteveldt et al. (2022)\n\n\nTasks for the next session\n\nComplete the next coding assignments in R."
  },
  {
    "objectID": "ccs/index.html#7",
    "href": "ccs/index.html#7",
    "title": "MA Computational Communication Science",
    "section": "Session 7 ",
    "text": "Session 7 \n\nTopics\n\nautomatic text analysis\n\n\n\nReading\nVan Atteveldt et al. (2022)\n\n\nTasks for the next session\n\nComplete the next coding assignments in R."
  },
  {
    "objectID": "ccs/index.html#8",
    "href": "ccs/index.html#8",
    "title": "MA Computational Communication Science",
    "section": "Session 8 ",
    "text": "Session 8 \n\nTopics\n\nautomatic image analysis\n\n\n\nReading\nVan Atteveldt et al. (2022)\n\n\nTasks for the next session\n\nComplete the next coding assignments in R."
  },
  {
    "objectID": "ccs/index.html#9",
    "href": "ccs/index.html#9",
    "title": "MA Computational Communication Science",
    "section": "Session 9 ",
    "text": "Session 9 \n\nTopics\n\nsimulation and generative agents\n\n\n\nReading\nVan Atteveldt et al. (2022)\n\n\nTasks for the next session\n\nComplete the next coding assignments in R."
  },
  {
    "objectID": "ccs/index.html#10",
    "href": "ccs/index.html#10",
    "title": "MA Computational Communication Science",
    "section": "Session 10 ",
    "text": "Session 10 \n\nTopics\n\nsimulation and generative agents\nquarto publishing\n\n\n\nTasks for the next session\n\nCheck example paper qmd file."
  },
  {
    "objectID": "ccs/index.html#11",
    "href": "ccs/index.html#11",
    "title": "MA Computational Communication Science",
    "section": "Session 11 ",
    "text": "Session 11 \n\nTopics\n\nquarto documents with branding\ncloseread extension\n\n\n\nTasks for the next session\n\nBring all your term-paper questions."
  },
  {
    "objectID": "experiment/index.html#beschreibung",
    "href": "experiment/index.html#beschreibung",
    "title": "BA Experiment",
    "section": "Beschreibung",
    "text": "Beschreibung\nIm Kurs werden eigene Experimente zu einem selbstgewählten Thema von der Entwicklung der Forschungsfrage bis hin zur Darstellung der Ergebnisse praktisch eingeübt.\nDer Kurs ist als inverted classroom konzipiert, d.h. die Studierenden eignen sich allein oder in der Gruppe die Inhalte an, die Sitzungen dienen vornehmlich dem Austausch und der gemeinsamen Arbeit am Forschungsprojekt."
  },
  {
    "objectID": "experiment/index.html#seminarplan",
    "href": "experiment/index.html#seminarplan",
    "title": "BA Experiment",
    "section": "Seminarplan",
    "text": "Seminarplan\n\n\n\n\n\n\nSitzung\nDatum\nThema\n\n\n\n\n1\n14.04.2025\nEinführung (keine Sitzung)\n\n\n2\n28.04.2025\nThemen\n\n\n3\n05.05.2025\nCCS: Simulation\n\n\n4\n12.05.2025\nForschungsfragen & Hypothesen\n\n\n5\n19.05.2025\nStudiendesign und Stichprobe*\n\n\n6\n26.05.2025\nCCS: Stimuluserstellung*\n\n\n7\n02.06.2025\nMessung & Fragebogen*\n\n\n8\n16.06.2025\nCCS: Soscisurvey*\n\n\n9\n23.06.2025\nPretest\n\n\n10\n30.06.2025\nFeldphase\n\n\n11\n07.07.2025\nErgebnisaufbereitung\n\n\n12\n14.07.2025\nAbschluss\n\n\n\n\n\n\n* = 5-Minuten-Präsentation des Zwischenstands"
  },
  {
    "objectID": "experiment/index.html#1",
    "href": "experiment/index.html#1",
    "title": "BA Experiment",
    "section": "Sitzung 1 ",
    "text": "Sitzung 1 \n\nThemen\n\nEinführung, Ablauf, Leistungsanforderungen, Formalia\n\n\n\nLiteratur\nKoch et al. (2019, Kapitel 1, 2)\n\n\nAufgabe zur nächsten Sitzung\n\nVideos zu Grundlagen des Experiments schauen\nVorschlag für ein eigenes Experiment erstellen (1/2 A4 Seite), vor allem Versuchsbedingungen und Outcome-Variable(n)"
  },
  {
    "objectID": "experiment/index.html#2",
    "href": "experiment/index.html#2",
    "title": "BA Experiment",
    "section": "Sitzung 2 ",
    "text": "Sitzung 2 \n\nThemen\n\nThemenwahl\nGruppenfindung\n\n\n\nAufgabe zur nächsten Sitzung\n\nGruppen und Thema finden, Literatur recherchieren\nR und RStudio installieren bzw. prüfen, Notebook mitbringen"
  },
  {
    "objectID": "experiment/index.html#3",
    "href": "experiment/index.html#3",
    "title": "BA Experiment",
    "section": "Sitzung 3 ",
    "text": "Sitzung 3 \n\nThemen\n\nSimulation von Studien und agentenbasierte Modelle\npraktische R-Übung\n\n\n\nLiteratur\nLarooij & Törnberg (2025);Waldherr & Wettstein (2019)\n\n\nAufgabe zur nächsten Sitzung\n\nR-Hausaufgabe zur Simulation"
  },
  {
    "objectID": "experiment/index.html#4",
    "href": "experiment/index.html#4",
    "title": "BA Experiment",
    "section": "Sitzung 4 ",
    "text": "Sitzung 4 \n\nThemen\n\nKausalität im Experiment\nDrittvariablen, Mediation, Moderation\nHypothesen, Forschungsfragen, Begriffe\n\n\n\nLiteratur\nKoch et al. (2019, Kapitel 2 und 3)\n\n\nAufgabe zur nächsten Sitzung\n\nForschungsfragen und Hypothesen aufstellen\nBegriffsarbeit\nLiteratur recherchieren"
  },
  {
    "objectID": "experiment/index.html#5",
    "href": "experiment/index.html#5",
    "title": "BA Experiment",
    "section": "Sitzung 5 ",
    "text": "Sitzung 5 \n\nThemen\n\nForschungsdesign\nStichprobe\n\n\n\nLiteratur\nKoch et al. (2019, Kapitel 5 und 6)\n\n\nAufgabe zur nächsten Sitzung\n\nForschungdesign finalisieren\nPower-Analyse und Stichprobenplan"
  },
  {
    "objectID": "experiment/index.html#6",
    "href": "experiment/index.html#6",
    "title": "BA Experiment",
    "section": "Sitzung 6 ",
    "text": "Sitzung 6 \n\nThemen\n\nStimulusdesign\ninterne und externe Validität\n\n\n\nAufgabe zur nächsten Sitzung\n\nStimuli entwerfen"
  },
  {
    "objectID": "experiment/index.html#7",
    "href": "experiment/index.html#7",
    "title": "BA Experiment",
    "section": "Sitzung 7 ",
    "text": "Sitzung 7 \n\nThemen\n\nMessung\nBriefing, Informed Consent, Debriefing\n\n\n\nAufgabe zur nächsten Sitzung\n\nStimuli finalisieren\nMessinstrumente recherchieren und auswählen\nFragebogen entwerfen"
  },
  {
    "objectID": "experiment/index.html#8",
    "href": "experiment/index.html#8",
    "title": "BA Experiment",
    "section": "Sitzung 8 ",
    "text": "Sitzung 8 \n\nThemen\n\nFragebogen und Randomisierung in Soscisurvey\nDatenmanagement und -analyse bei Within-Subject-Designs\n\n\n\nAufgabe zur nächsten Sitzung\n\nFragebogen inkl. Stimuli und Messinstrumente finalisieren\nTechnischen Pretest durchführen, ggf. eigentlichen Pretest (n ~ 5) durchführen\nCode für Datenanalyse vorbereiten"
  },
  {
    "objectID": "experiment/index.html#9",
    "href": "experiment/index.html#9",
    "title": "BA Experiment",
    "section": "Sitzung 9 ",
    "text": "Sitzung 9"
  },
  {
    "objectID": "experiment/index.html#11",
    "href": "experiment/index.html#11",
    "title": "BA Experiment",
    "section": "Sitzung 11 ",
    "text": "Sitzung 11 \n\nThemen\n\nFeldphase\nDatenauswertung\n\n\n\nAufgabe zur nächsten Sitzung\n\nDatenauswertung und Abschlusspräsentationen"
  },
  {
    "objectID": "experiment/index.html#12",
    "href": "experiment/index.html#12",
    "title": "BA Experiment",
    "section": "Sitzung 12 ",
    "text": "Sitzung 12 \n\nThemen\n\nAbschlusspräsentationen\nProjektbericht\nFragen und Antworten"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Michael Scharkow",
    "section": "",
    "text": "I am professor for Computational Communication Science at the Department of Communication, Johannes Gutenberg University Mainz. My main research interests are online communication, media use and effects, and quantitative methods, especially data collection and statistical modeling.\n\n\nJohannes-Gutenberg University Mainz  Department of Communication  Jakob-Welder-Weg 12  55128 Mainz  Germany\nscharkow@uni-mainz.de"
  },
  {
    "objectID": "index.html#about",
    "href": "index.html#about",
    "title": "Michael Scharkow",
    "section": "",
    "text": "I am professor for Computational Communication Science at the Department of Communication, Johannes Gutenberg University Mainz. My main research interests are online communication, media use and effects, and quantitative methods, especially data collection and statistical modeling.\n\n\nJohannes-Gutenberg University Mainz  Department of Communication  Jakob-Welder-Weg 12  55128 Mainz  Germany\nscharkow@uni-mainz.de"
  },
  {
    "objectID": "index.html#teaching",
    "href": "index.html#teaching",
    "title": "Michael Scharkow",
    "section": "Teaching",
    "text": "Teaching"
  },
  {
    "objectID": "inhaltsanalyse/index.html#beschreibung",
    "href": "inhaltsanalyse/index.html#beschreibung",
    "title": "BA Inhaltsanalyse",
    "section": "Beschreibung",
    "text": "Beschreibung\nIm Kurs werden eigene Inhaltsanalysen zu einem selbstgewählten Thema von der Entwicklung der Forschungsfrage bis hin zur Darstellung der Ergebnisse praktisch eingeübt.\nDer Kurs ist als inverted classroom konzipiert, d.h. die Studierenden eignen sich allein oder in der Gruppe die Inhalte an, die Sitzungen dienen vornehmlich dem Austausch und der gemeinsamen Arbeit am Forschungsprojekt."
  },
  {
    "objectID": "inhaltsanalyse/index.html#seminarplan",
    "href": "inhaltsanalyse/index.html#seminarplan",
    "title": "BA Inhaltsanalyse",
    "section": "Seminarplan",
    "text": "Seminarplan\n\n\n\n\n\n\n\n\n\n\n\nSitzung\nDatum\nThema\n\n\n\n\n1\n25.10.2024\nEinführung und Grundlagen\n\n\n2\n08.11.2024\nCCS: Inhaltsanalyse mit LLM\n\n\n3\n15.11.2024\nThemenwahl und Forschungsfragen\n\n\n4\n22.11.2024\nStudiendesign und Stichprobe*\n\n\n5\n29.11.2024\nCCS: Datenerhebung\n\n\n6\n06.12.2024\nKategorien und Codierung*\n\n\n7\n13.12.2024\nCCS: Reli-Test und Validierung*\n\n\n8\n20.12.2024\nCodebuch-Finalisierung\n\n\n9\n10.01.2025\nFeldphase (Sprechstunde)\n\n\n10\n17.01.2025\nDatenanalyse und -visualisierung*\n\n\n11\n24.01.2025\nCCS: Zero-Shot Codierung/Validierung\n\n\n12\n31.01.2025\nErgebnisaufbereitung\n\n\n13\n07.02.2025\nAbschluss\n\n\n\n\n\n\n* = 5-Minuten-Präsentation des Zwischenstands"
  },
  {
    "objectID": "inhaltsanalyse/index.html#1",
    "href": "inhaltsanalyse/index.html#1",
    "title": "BA Inhaltsanalyse",
    "section": "Sitzung 1 ",
    "text": "Sitzung 1 \n\nThemen\n\nEinführung, Ablauf, Leistungsanforderungen, Formalia\nDefinition und Grundlagen Inhaltsanalyse\nmanuelle vs. LLM-basierte Codierung\n\n\n\nLiteratur\nBenoit et al. (2009); Rössler (2017, Kapitel 1, 2)\n\n\nAufgabe zur nächsten Sitzung\nZero-Shot-Codierung in R mit Hausaufgabe"
  },
  {
    "objectID": "inhaltsanalyse/index.html#2",
    "href": "inhaltsanalyse/index.html#2",
    "title": "BA Inhaltsanalyse",
    "section": "Sitzung 2 ",
    "text": "Sitzung 2 \n\nThemen\n\nTextcodierung mit Large Language Models\nBildcodierung mit multimodalen Modellen\nPrompting-Strategien für Zero- und Few-Shot-Codierung\npraktische Tipps mit für die Batch-Codierung mit R und {tidyllm}\n\n\n\nLiteratur\nTörnberg (2023); Weber & Reichardt (2024)\n\n\nAufgabe zur nächsten Sitzung\nGruppenbildung und Ideen für Themen und Forschungsfragen"
  },
  {
    "objectID": "inhaltsanalyse/index.html#3",
    "href": "inhaltsanalyse/index.html#3",
    "title": "BA Inhaltsanalyse",
    "section": "Sitzung 3 ",
    "text": "Sitzung 3 \n\nThemen\n\nVorstellung von Themenideen\nHerleitung von Forschungsfragen und Hypothesen\nBegriffsarbeit (semantische und dimensionale Analyse)\n\n\n\nLiteratur\nRössler (2017, Kapitel 3)\n\n\nAufgabe zur nächsten Sitzung\n\nForschungsfragen und Hypothesen formulieren sowie zentrale Begriffe definieren\nGruppen und Verantwortlichkeiten melden"
  },
  {
    "objectID": "inhaltsanalyse/index.html#4",
    "href": "inhaltsanalyse/index.html#4",
    "title": "BA Inhaltsanalyse",
    "section": "Sitzung 4 ",
    "text": "Sitzung 4 \n\nThemen\n\nVorstellung der Forschungsfragen und Hypothesen\nStudiendesign bei Inhaltsanalysen\nStichproben und Untersuchungseinheiten\n\n\n\nLiteratur\nRössler (2017, Kapitel 4)\n\n\nAufgabe zur nächsten Sitzung\nDatenerhebung in R mit Hausaufgaben 1 und 2"
  },
  {
    "objectID": "inhaltsanalyse/index.html#5",
    "href": "inhaltsanalyse/index.html#5",
    "title": "BA Inhaltsanalyse",
    "section": "Sitzung 5 ",
    "text": "Sitzung 5 \n\nThemen\n\nErhebung von Online-Inhalten in R\nNutzung von CLI-Tools für Datenerhebung und -verarbeitung\n\n\n\nLiteratur\nHaim (2023, Kapitel 5 und 6)"
  },
  {
    "objectID": "inhaltsanalyse/index.html#6",
    "href": "inhaltsanalyse/index.html#6",
    "title": "BA Inhaltsanalyse",
    "section": "Sitzung 6 ",
    "text": "Sitzung 6 \n\nThemen\n\nCodebuchentwicklung und Kategorienbildung\nDateneingabe und Probecodierung\n\n\n\nLiteratur\nRössler (2017, Kapitel 6–9)\n\n\nAufgabe zur nächsten Sitzung\n\nFinalisierung Design und Stichprobe\nerste Codebuch-Fassung\nProbecodierung"
  },
  {
    "objectID": "inhaltsanalyse/index.html#7",
    "href": "inhaltsanalyse/index.html#7",
    "title": "BA Inhaltsanalyse",
    "section": "Sitzung 7 ",
    "text": "Sitzung 7 \n\nThemen\n\nCodebuchentwicklung\nReliabilität und Validität\n\n\n\nLiteratur\nRössler (2017, Kapitel 12)\n\n\nAufgabe zur nächsten Sitzung\n\nFinalisierung Codebuch\nReliabilitätstest\nDatenerhebung"
  },
  {
    "objectID": "inhaltsanalyse/index.html#10",
    "href": "inhaltsanalyse/index.html#10",
    "title": "BA Inhaltsanalyse",
    "section": "Sitzung 10 ",
    "text": "Sitzung 10 \n\nThemen\n\nDatenaufbereitung\nDatenanalyse\n\n\n\nLiteratur\nhttps://stats.ifp.uni-mainz.de/ba-datenanalyse\n\n\nAufgabe zur nächsten Sitzung\n\nFinalisierung Codierung\nAufbereitung der finalen Daten\nErstellung Analyseplan und Auswertung"
  },
  {
    "objectID": "inhaltsanalyse/index.html#11",
    "href": "inhaltsanalyse/index.html#11",
    "title": "BA Inhaltsanalyse",
    "section": "Sitzung 11 ",
    "text": "Sitzung 11 \n\nThemen\n\nStrukturierte Zero-Shot Klassifikation mit tidyllm\nErstellen eigener Prompts und JSON-Schemata"
  },
  {
    "objectID": "inhaltsanalyse/index.html#12",
    "href": "inhaltsanalyse/index.html#12",
    "title": "BA Inhaltsanalyse",
    "section": "Sitzung 12 ",
    "text": "Sitzung 12 \n\nThemen\n\nDatenaufbereitung und Datenanalyse mit R\n\n\n\nLiteratur\nhttps://stats.ifp.uni-mainz.de/ba-datenanalyse\n\n\nAufgabe zur nächsten Sitzung\n\nDaten auswerten\nErgebnispräsentation vorbereiten (max. 10 min)"
  },
  {
    "objectID": "inhaltsanalyse/index.html#13",
    "href": "inhaltsanalyse/index.html#13",
    "title": "BA Inhaltsanalyse",
    "section": "Sitzung 13 ",
    "text": "Sitzung 13 \n\nThemen\n\nAbschlusspräsentationen\nProjektberichte\nEvaluation"
  },
  {
    "objectID": "inhaltsanalyse/index.html#literatur-9",
    "href": "inhaltsanalyse/index.html#literatur-9",
    "title": "BA Inhaltsanalyse",
    "section": "Literatur",
    "text": "Literatur\n\n\nBenoit, K., Laver, M., & Mikhaylov, S. (2009). Treating Words as Data with Error: Uncertainty in Text Statements of Policy Positions. American Journal of Political Science, 53(2), 495–513. https://doi.org/10.1111/j.1540-5907.2009.00383.x\n\n\nHaim, M. (2023). Computational Communication Science. Springer Fachmedien Wiesbaden. https://doi.org/10.1007/978-3-658-40171-9\n\n\nRössler, P. (2017). Inhaltsanalyse, 3. Auflage. UTB. https://doi.org/10.36198/9783838547060\n\n\nTörnberg, P. (2023). How to use LLMs for text analysis. https://arxiv.org/pdf/2307.13106\n\n\nWeber, M., & Reichardt, M. (2024). Evaluation is all you need. Prompting Generative Large Language Models for Annotation Tasks in the Social Sciences. A Primer using Open Models. https://arxiv.org/pdf/2401.00284"
  },
  {
    "objectID": "analyseverfahren/index.html#beschreibung",
    "href": "analyseverfahren/index.html#beschreibung",
    "title": "BA Anwendungsorientierte Analyseverfahren",
    "section": "Beschreibung",
    "text": "Beschreibung\nIn dieser Vorlesung werden am Beispiel von kommunikationswissenschaftlichen Studien und praktischen Beispielen anwendungsorientiert vor allem das GLM und Regressionsmodelle behandelt. Neben der konzeptionellen Diskussion der Verfahren steht die praktische Umsetzung in R im Vordergrund."
  },
  {
    "objectID": "analyseverfahren/index.html#vorlesungsplan",
    "href": "analyseverfahren/index.html#vorlesungsplan",
    "title": "BA Anwendungsorientierte Analyseverfahren",
    "section": "Vorlesungsplan",
    "text": "Vorlesungsplan\n\n\n\n\n\n\nSitzung\nDatum\nThema\n\n\n\n\n1\n23.04.2025\nEinführung\n\n\n2\n30.04.2025\nGLM Grundlagen\n\n\n3\n07.05.2025\nLineare Regression\n\n\n4\n21.05.2025\nMittelwertvergleiche\n\n\n5\n28.05.2025\nMultiple Regression\n\n\n6\n04.06.2025\nModellannahmen\n\n\n7\n11.06.2025\nModellvorhersagen\n\n\n8\n18.06.2025\nModerationsanalyse I\n\n\n9\n25.06.2025\nModerationsanalyse II\n\n\n10\n02.07.2025\nLogistische Regression\n\n\n11\n09.07.2025\nMultilevel-Regression\n\n\n12\n16.07.2025\nAbschluss"
  },
  {
    "objectID": "analyseverfahren/index.html#materialien",
    "href": "analyseverfahren/index.html#materialien",
    "title": "BA Anwendungsorientierte Analyseverfahren",
    "section": "Materialien",
    "text": "Materialien\nKurs-Website mit R-Code, Daten und Hausaufgaben"
  },
  {
    "objectID": "analyseverfahren/index.html#1",
    "href": "analyseverfahren/index.html#1",
    "title": "BA Anwendungsorientierte Analyseverfahren",
    "section": "Sitzung 1 ",
    "text": "Sitzung 1 \n\nThemen\n\nEinführung, Ablauf, Leistungsanforderungen, Formalia\nRefresher Inferenzstatistik\n\n\n\nLiteratur\nEid et al. (2015)"
  },
  {
    "objectID": "analyseverfahren/index.html#2",
    "href": "analyseverfahren/index.html#2",
    "title": "BA Anwendungsorientierte Analyseverfahren",
    "section": "Sitzung 2 ",
    "text": "Sitzung 2 \n\nThemen\n\nGrundlagen statistischer Modelle\nGLM\n\n\n\nLiteratur\nAuty & Lewis (2004)"
  },
  {
    "objectID": "analyseverfahren/index.html#3",
    "href": "analyseverfahren/index.html#3",
    "title": "BA Anwendungsorientierte Analyseverfahren",
    "section": "Sitzung 3 ",
    "text": "Sitzung 3 \n\nThemen\n\nGrundlagen Korrelation und lineare Regression\nZentrierung und Standardisierung\n\n\n\nLiteratur\nJohannes et al. (2022)"
  },
  {
    "objectID": "analyseverfahren/index.html#4",
    "href": "analyseverfahren/index.html#4",
    "title": "BA Anwendungsorientierte Analyseverfahren",
    "section": "Sitzung 4 ",
    "text": "Sitzung 4 \n\nThemen\n\nMittelvergleiche\nDummy-Codierung und Kontraste\n\n\n\nLiteratur\nKümpel (2019)"
  },
  {
    "objectID": "analyseverfahren/index.html#5",
    "href": "analyseverfahren/index.html#5",
    "title": "BA Anwendungsorientierte Analyseverfahren",
    "section": "Sitzung 5 ",
    "text": "Sitzung 5 \n\nThemen\n\nMultiple Regression\n\\(R^2\\) und Modellvergleich\n\n\n\nLiteratur\nVan Erkel & Van Aelst (2021)"
  },
  {
    "objectID": "analyseverfahren/index.html#6",
    "href": "analyseverfahren/index.html#6",
    "title": "BA Anwendungsorientierte Analyseverfahren",
    "section": "Sitzung 6 ",
    "text": "Sitzung 6 \n\nThemen\n\nRegressionsannahmen\nKausalität und Drittvariablen\n\n\n\nLiteratur\nVan Erkel & Van Aelst (2021)"
  },
  {
    "objectID": "analyseverfahren/index.html#7",
    "href": "analyseverfahren/index.html#7",
    "title": "BA Anwendungsorientierte Analyseverfahren",
    "section": "Sitzung 7 ",
    "text": "Sitzung 7 \n\nThemen\n\nModellvorhersagen\nVisualisierung von Vorhersagen"
  },
  {
    "objectID": "analyseverfahren/index.html#8",
    "href": "analyseverfahren/index.html#8",
    "title": "BA Anwendungsorientierte Analyseverfahren",
    "section": "Sitzung 8 ",
    "text": "Sitzung 8 \n\nThemen\n\nGrundlagen Moderation\nKategorielle Moderatoren\n\n\n\nLiteratur\nVögele & Bachl (2017)"
  },
  {
    "objectID": "analyseverfahren/index.html#9",
    "href": "analyseverfahren/index.html#9",
    "title": "BA Anwendungsorientierte Analyseverfahren",
    "section": "Sitzung 9 ",
    "text": "Sitzung 9 \n\nThemen\n\nmetrische Moderatoren\n\n\n\nLiteratur\nVögele & Bachl (2017)"
  },
  {
    "objectID": "analyseverfahren/index.html#10",
    "href": "analyseverfahren/index.html#10",
    "title": "BA Anwendungsorientierte Analyseverfahren",
    "section": "Sitzung 10 ",
    "text": "Sitzung 10 \n\nThemen\n\nlogistische Regression\n\n\n\nLiteratur\nFestl et al. (2013)\n\n\nLiteratur\nVögele & Bachl (2017)"
  },
  {
    "objectID": "analyseverfahren/index.html#11",
    "href": "analyseverfahren/index.html#11",
    "title": "BA Anwendungsorientierte Analyseverfahren",
    "section": "Sitzung 11 ",
    "text": "Sitzung 11 \n\nThemen\n\nMultilevel-Regression\n\n\n\nLiteratur\nFähnrich et al. (2020)"
  },
  {
    "objectID": "analyseverfahren/slides.html#warum-noch-eine-vorlesung-zur-statistik",
    "href": "analyseverfahren/slides.html#warum-noch-eine-vorlesung-zur-statistik",
    "title": "Anwendungsorientierte Analyseverfahren",
    "section": "Warum (noch) eine Vorlesung zur Statistik?",
    "text": "Warum (noch) eine Vorlesung zur Statistik?\n\nLiteracy: Wenn man aktuelle Forschung lesen möchte (oder muss), führt kein Weg an etwas komplexeren Analysen vorbei.\nSelbstwirksamkeit: Wer einmal eine Analyse durchgeführt hat, kann in Seminar- und Abschlussarbeiten besser Daten auswerten.\nJobaussichten: Viele AbsolventInnen berichten rückblickend, dass gerade die Methodenskills am besten verwertbar waren bei der Jobsuche und im Beruf."
  },
  {
    "objectID": "analyseverfahren/slides.html#ziele-der-vorlesung",
    "href": "analyseverfahren/slides.html#ziele-der-vorlesung",
    "title": "Anwendungsorientierte Analyseverfahren",
    "section": "Ziele der Vorlesung",
    "text": "Ziele der Vorlesung\n\nStudierende werden dazu befähigt, die Anwendung ausgewählter Analyseverfahren nachzuvollziehen sowie entsprechende Forschungsergebnisse und Interpretationen zu verstehen.\nStudierende sind in der Lage, für ausgewählte Analyseverfahren anhand vorgegebener Daten Ergebnisse aus der Forschungsliteratur mittels Statistiksoftware zu reproduzieren.\nStudierende verfügen über die die Kompetenz, Angemessenheit und Güte von methodischen Vorgehensweisen zu beurteilen.\n(Studierende finden Statistik weniger schlimm und langweilig)."
  },
  {
    "objectID": "analyseverfahren/slides.html#was-die-vorlesung-nicht-ist",
    "href": "analyseverfahren/slides.html#was-die-vorlesung-nicht-ist",
    "title": "Anwendungsorientierte Analyseverfahren",
    "section": "Was die Vorlesung (nicht) ist",
    "text": "Was die Vorlesung (nicht) ist\n\nkeine Wiederholung der VL Statistik oder der Datenanalyse-Übungen\nFokus auf das Verständnis für und die Anwendung von statistischen Verfahren, weniger die Mathematik dahinter\ndas Allgemeine Lineare Modell (GLM) als grundlegendes Verfahren\nkein reines Ablesen von p-Werten und Signifikanz-Sternchen\nemanzipierter Umgang mit statistischen Verfahren statt Rezepte abarbeiten"
  },
  {
    "objectID": "analyseverfahren/slides.html#vorlesungsplan",
    "href": "analyseverfahren/slides.html#vorlesungsplan",
    "title": "Anwendungsorientierte Analyseverfahren",
    "section": "Vorlesungsplan",
    "text": "Vorlesungsplan\n\n\n\n\n\n\nSitzung\nDatum\nThema\n\n\n\n\n1\n23.04.2025\nEinführung\n\n\n2\n30.04.2025\nGLM Grundlagen\n\n\n3\n07.05.2025\nLineare Regression\n\n\n4\n21.05.2025\nMittelwertvergleiche\n\n\n5\n28.05.2025\nMultiple Regression\n\n\n6\n04.06.2025\nModellannahmen\n\n\n\n\n\n\n\n\nSitzung\nDatum\nThema\n\n\n\n\n7\n11.06.2025\nModellvorhersagen\n\n\n8\n18.06.2025\nModerationsanalyse I\n\n\n9\n25.06.2025\nModerationsanalyse II\n\n\n10\n02.07.2025\nLogistische Regression\n\n\n11\n09.07.2025\nMultilevel-Regression\n\n\n12\n16.07.2025\nAbschluss"
  },
  {
    "objectID": "analyseverfahren/slides.html#ablauf-der-sitzungen-und-anwesenheit",
    "href": "analyseverfahren/slides.html#ablauf-der-sitzungen-und-anwesenheit",
    "title": "Anwendungsorientierte Analyseverfahren",
    "section": "Ablauf der Sitzungen und Anwesenheit",
    "text": "Ablauf der Sitzungen und Anwesenheit\nAblauf\n\nBesprechung der praktischen Übungen/Hausaufgabe (max. 15 min)\nVorlesungsteil (max. 60 min)\nFragen und Antworten zur Vorlesung und praktischen Übung\n\nAnwesenheit\n\nkeine Anwesenheitspflicht, aber auch keine Nachhilfepflicht meinerseits\neigenständige Nachbereitung der praktischen Übungen"
  },
  {
    "objectID": "analyseverfahren/slides.html#e-learning-und-studienleistung",
    "href": "analyseverfahren/slides.html#e-learning-und-studienleistung",
    "title": "Anwendungsorientierte Analyseverfahren",
    "section": "E-Learning und Studienleistung",
    "text": "E-Learning und Studienleistung\nMaterial\n\nFolien und Übungsmaterialien samt Daten und R-Code auf  https://stats.ifp.uni-mainz.de/ba-aa-vl\n\nStudienleistung\n\nwährend der Vorlesungszeit 3 Teil-Studienleistungen (je ca. 15 min)\nsowohl Interpretations- als auch praktische Analyseaufgaben\nDeadline jeweils 2 Wochen nach Aufgabenstellung, Mi 12h\nBenotung jeweils Pass/Fail, 3x Pass nötig (ggf. Zusatzaufgabe)"
  },
  {
    "objectID": "analyseverfahren/slides.html#praktische-übungen",
    "href": "analyseverfahren/slides.html#praktische-übungen",
    "title": "Anwendungsorientierte Analyseverfahren",
    "section": "Praktische Übungen",
    "text": "Praktische Übungen\n\nzu jeder Sitzung eine praktische Übung auf Basis einer publizierten Studie\nkurze Besprechung in der Vorlesung, meist mit einer exemplarischen Analyse\nR-Code zum Replizieren der Analysen zuhause oder während der Vorlesung\npraktische Anwendung als integraler Teil der Vorlesung und der Studienleistung\nCopy & Paste/Anpassung von bestehendem Code ist ok!"
  },
  {
    "objectID": "analyseverfahren/slides.html#software",
    "href": "analyseverfahren/slides.html#software",
    "title": "Anwendungsorientierte Analyseverfahren",
    "section": "Software",
    "text": "Software\n\nin der VL vorgestellten Analysen lassen sich mit praktisch jeder Statistiksoftware reproduzieren\njede Statistiksoftware ist nur ein Werkzeug\nLektürekompetenz heißt auch, man kann sowohl SPSS als auch Stata oder R-Output lesen\nwegen Verfügbarkeit und Zukunftsfähigkeit verwende ich R\n\nFür die Studienleistung ist irrelevant, welche Software Sie verwenden!"
  },
  {
    "objectID": "analyseverfahren/slides.html#warum-muss-ich-jetzt-auch-noch-r-lernen",
    "href": "analyseverfahren/slides.html#warum-muss-ich-jetzt-auch-noch-r-lernen",
    "title": "Anwendungsorientierte Analyseverfahren",
    "section": "Warum muss ich jetzt auch noch R lernen?",
    "text": "Warum muss ich jetzt auch noch R lernen?\n\nSie müssen nicht!\nR ist freie Software und durch viele tausend Pakete (packages) erweiterbar, u.a. für\n\nDatenerhebung: Web-Scraping, APIs (z.B. für TikTok oder Spotify), Textdaten\nAuswertung: Statistik, Textanalyse, Audiodaten, Psychophysiologie, etc.\nDatenpräsentation und -visualisierung: Grafiken, Berichte, Folien (z.B. diese)\n\ngrundlegende Programmierkenntnisse, die auch ohne Statistik nützlich sein können\ndas IfP hat auf R umgestellt, siehe Kurz-Websites https://stats.ifp.uni-mainz.de/"
  },
  {
    "objectID": "analyseverfahren/slides.html#kleines-r-beispiel-breaking-bad-deaths",
    "href": "analyseverfahren/slides.html#kleines-r-beispiel-breaking-bad-deaths",
    "title": "Anwendungsorientierte Analyseverfahren",
    "section": "Kleines R-Beispiel: Breaking Bad Deaths",
    "text": "Kleines R-Beispiel: Breaking Bad Deaths\nWas macht dieser Code?\n\nlibrary(tidyverse)\nread_csv('https://wegweisr.haim.it/Daten/breaking_bad_deaths.csv') |&gt;  \n  count(method, sort = TRUE) |&gt; \n  head(n = 5)"
  },
  {
    "objectID": "analyseverfahren/slides.html#kleines-r-beispiel-breaking-bad-deaths-1",
    "href": "analyseverfahren/slides.html#kleines-r-beispiel-breaking-bad-deaths-1",
    "title": "Anwendungsorientierte Analyseverfahren",
    "section": "Kleines R-Beispiel: Breaking Bad Deaths",
    "text": "Kleines R-Beispiel: Breaking Bad Deaths\nWas macht dieser Code?\n\nlibrary(tidyverse)\nread_csv('https://wegweisr.haim.it/Daten/breaking_bad_deaths.csv') |&gt;  \n  count(method, sort = TRUE) |&gt; \n  head(n = 5)\n\n\n\n\n\nmethod\n\n\nn\n\n\n\n\n\n\naccidental death\n\n\n172\n\n\n\n\nshot\n\n\n59\n\n\n\n\npoisoned\n\n\n14\n\n\n\n\nstabbed\n\n\n13\n\n\n\n\nbombed\n\n\n4"
  },
  {
    "objectID": "analyseverfahren/slides.html#literaturempfehlungen",
    "href": "analyseverfahren/slides.html#literaturempfehlungen",
    "title": "Anwendungsorientierte Analyseverfahren",
    "section": "Literaturempfehlungen",
    "text": "Literaturempfehlungen\nField, A., Miles, J., & Field, Z. (2012). Discovering statistics using R. London: Sage.\nMiles, J., & Shevlin, M. (2001). Applying regression and correlation: A guide for students and researchers. London: Sage.\nDarlington, R. B., & Hayes, A. F. (2016). Regression analysis and linear models: Concepts, applications, and implementation. Guilford Publications.\nMcElreath, R. (2020). Statistical rethinking: A Bayesian course with examples in R and Stan. CRC press. (für Interessierte)"
  },
  {
    "objectID": "analyseverfahren/slides.html#self-assessment",
    "href": "analyseverfahren/slides.html#self-assessment",
    "title": "Anwendungsorientierte Analyseverfahren",
    "section": "Self-Assessment",
    "text": "Self-Assessment\nInterpretieren Sie die folgenden Analysen:\n\nSie vergleichen mit einem T-Test die Körpergröße zwischen Männern und Frauen. Der berechnete T-Wert: t(100) = 3.45\nSie vergleichen die Hausarbeitsnoten über alle 6 Parallelkurse Inhaltsanalyse mittels Varianzanalyse: p = .074\nSie berechnen die Korrelation zwischen Anwesenheit und Punkten in der Klausur: r = .41 95%-CI (.24;.58)"
  },
  {
    "objectID": "analyseverfahren/slides.html#was-ist-inferenzstatistik",
    "href": "analyseverfahren/slides.html#was-ist-inferenzstatistik",
    "title": "Anwendungsorientierte Analyseverfahren",
    "section": "Was ist Inferenzstatistik?",
    "text": "Was ist Inferenzstatistik?\n\n“Die Inferenzstatistik (d.h. schließende Statistik) beschäftigt sich mit der Frage, wie man aufgrund von Stichprobendaten auf Sachverhalte in einer zugrundeliegenden Population schließen kann.” (Eid et al., 2010, p. 191)\n\n\nUns interessieren Verfahren für die statistische Punkt- und Intervallschätzung.\nDie Verfahren basieren auf bestimmten Annahmen über die Stichprobe und Variable(n).\nKlassische (asymptotische) Inferenzstatistik basiert auf ausreichend großen Zufallsstichproben.\nAlternative Ansätze, wie z.B. Bootstrapping, kommen mit weniger strengen Annahmen aus, sind dafür aber weniger mathematisch abgesichert und elegant."
  },
  {
    "objectID": "analyseverfahren/slides.html#ein-simuliertes-beispiel",
    "href": "analyseverfahren/slides.html#ein-simuliertes-beispiel",
    "title": "Anwendungsorientierte Analyseverfahren",
    "section": "Ein simuliertes Beispiel",
    "text": "Ein simuliertes Beispiel\n\n\nSimulation\n\nWir simulieren die Körpergröße in der Grundgesamtheit von N = 1200 Studentinnen und Studenten am IfP.\nDadurch können wir prüfen, wie gut unsere Schätzung der Körpergröße durch eine einzelne Stichprobe gelingt.\n\n\n\n\nGrundgesamtheit\n\n\n\n\n\n\n\n\n\n\nGrundgesamtheit: M = 170, SD = 10"
  },
  {
    "objectID": "analyseverfahren/slides.html#stichprobenziehung-und--kennwerte",
    "href": "analyseverfahren/slides.html#stichprobenziehung-und--kennwerte",
    "title": "Anwendungsorientierte Analyseverfahren",
    "section": "Stichprobenziehung und -kennwerte",
    "text": "Stichprobenziehung und -kennwerte\n\n\nEine einzelne Stichprobe\n\nWir ziehen eine Zufallsstichprobe von n = 30 Studierenden und erheben deren Körpergröße.\nIn dieser Stichprobe beträgt die mittlere Körpergröße M = 172 (SD = 11).\n\n\n\n\nStichprobenkennwerte"
  },
  {
    "objectID": "analyseverfahren/slides.html#wiederholte-stichproben",
    "href": "analyseverfahren/slides.html#wiederholte-stichproben",
    "title": "Anwendungsorientierte Analyseverfahren",
    "section": "Wiederholte Stichproben",
    "text": "Wiederholte Stichproben\n\n\n\nAsymptotische Inferenz basiert auf der Annahme, dass die Mittelwerte vieler Stichproben derselben Grundgesamtheit normalverteilt sind.\nwir ziehen 1000 Stichproben mit jeweils n = 30\nBlau: Mittelwert in der Grundgesamtheit, Rot: Mittelwert in der einzelnen Stichprobe"
  },
  {
    "objectID": "analyseverfahren/slides.html#stichprobenmittelwerte-und-se",
    "href": "analyseverfahren/slides.html#stichprobenmittelwerte-und-se",
    "title": "Anwendungsorientierte Analyseverfahren",
    "section": "Stichprobenmittelwerte und SE",
    "text": "Stichprobenmittelwerte und SE\n\n\n\nDie Mittelwerte der einzelnen Stichproben streuen um den wahren Populationsmittelwert von 170 = Standardfehler (SE).\nSE = \\(SD(x)/\\sqrt(n-1)\\), den wir anhand einer Stichprobe berechnen können, als Schätzer für die Streuung der Stichprobenmittelwerte.\nSE auf Basis unserer ersten Stichprobe: SE = \\(11/\\sqrt(29)\\) = 2.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBei unseren 1000 simulierten Stichproben ist der Mittelwert der Mittelwerte M = 169.9.\nDie Standardabweichung der Mittelwerte ist SE = 1.7."
  },
  {
    "objectID": "analyseverfahren/slides.html#stichprobentheorie-und--empirie",
    "href": "analyseverfahren/slides.html#stichprobentheorie-und--empirie",
    "title": "Anwendungsorientierte Analyseverfahren",
    "section": "Stichprobentheorie und -empirie",
    "text": "Stichprobentheorie und -empirie\n\n\n\nStichprobentheorie sagt uns wie bestimmte Kennwerte (z.B. Mittelwerte) in unendlich wiederholten Stichproben verteilt sind.\nDiese Information können wir mit den Schätzern aus einer Stichprobe kombinieren.\nDarauf basieren die Intervallschätzung und Hypothesentests.\n\n\n\n\n\n\n\n\n\n\n\n\n\nRot: Normalverteilungskurve mit Mittelwert und Standardfehler aus der ersten Stichprobe."
  },
  {
    "objectID": "analyseverfahren/slides.html#konfidenzintervalle",
    "href": "analyseverfahren/slides.html#konfidenzintervalle",
    "title": "Anwendungsorientierte Analyseverfahren",
    "section": "Konfidenzintervalle",
    "text": "Konfidenzintervalle\n\n\n\nbasieren auf der Annahme, dass ein Schätzer einer bestimmten Verteilung folgt.\nBei einer Standardnormalverteilung (M = 0, SD = 1) liegen 95% aller Werte zwischen -1,96 und 1,96.\nWenn wir M und SE einsetzen, bekommen wir ein 95%-CI für den Mittelwert, d.h. M - 1.96xSE und M + 1.96xSE.\n\n\n\n\n\n\n\n\n\n\n\n\n\n95%-Konfidenzintervall auf Basis unserer ersten Stichprobe (M und SE): 167.8 - 175.8"
  },
  {
    "objectID": "analyseverfahren/slides.html#interpretation-eines-konfidenzintervalls",
    "href": "analyseverfahren/slides.html#interpretation-eines-konfidenzintervalls",
    "title": "Anwendungsorientierte Analyseverfahren",
    "section": "Interpretation eines Konfidenzintervalls",
    "text": "Interpretation eines Konfidenzintervalls\n\nEin 95%-Konfidenzintervall bedeutet: in 95 Prozent aller denkbaren Stichproben würde das Konfidenzintervall den wahren Populationswert enthalten.\nDie Wahrscheinlichkeit, den wahren Wert zu enthalten, bezieht sich auf die Konstruktion von Konfidenzintervallen, nicht auf ein einzelnes Intervall.\nWir wissen aber bei einer einzigen, konkreten Stichprobe nicht, ob unser Konfidenzintervall den wahren Wert enthält.\nAber wir sind zuversichtlich (“confident”), dass unsere Stichprobe zu den 95% “Treffern” gehört, nicht zu den 5% Abweichlern.\nWenn der Wert unter der Nullhypothese nicht im Konfidenzintervall liegt, bezeichnen wir das Ergebnis als statistisch signifikant."
  },
  {
    "objectID": "analyseverfahren/slides.html#abdeckung-der-konfidenzintervalle",
    "href": "analyseverfahren/slides.html#abdeckung-der-konfidenzintervalle",
    "title": "Anwendungsorientierte Analyseverfahren",
    "section": "Abdeckung der Konfidenzintervalle",
    "text": "Abdeckung der Konfidenzintervalle\nJe größer die Stichprobe (n), desto kleiner der Standardfehler (SE), d.h. desto enger das Konfidenzintervall. Es gilt aber immer, bei 95%-CI enthalten langfristig 5 von 100 Intervallen nicht den Populationswert."
  },
  {
    "objectID": "analyseverfahren/slides.html#die-welt-der-nullhypothese",
    "href": "analyseverfahren/slides.html#die-welt-der-nullhypothese",
    "title": "Anwendungsorientierte Analyseverfahren",
    "section": "Die Welt der Nullhypothese?",
    "text": "Die Welt der Nullhypothese?\n\nIm Gegensatz zu den unendlich vielen Alternativhypothesen, die man haben kann, gibt es immer nur eine Nullhypothese.\n\nEs besteht kein Unterschied/Abhängigekeit zwischen Gruppen oder Variablen.\n\nVon fast allen Verfahren (T-Test, Korrelation, Chi-Quadrat-Test, etc.) wissen wir, wie die “Welt der Nullhypothese aussieht.\nWir prüfen Stichprobenkennwerte daraufhin, wie häufig oder wahrscheinlich sie in der Welt der Nullhypothese sind.\nDiese Wahrscheinlichkeit ist der p-Wert."
  },
  {
    "objectID": "analyseverfahren/slides.html#was-bedeutet-der-p-wert",
    "href": "analyseverfahren/slides.html#was-bedeutet-der-p-wert",
    "title": "Anwendungsorientierte Analyseverfahren",
    "section": "Was bedeutet der p-Wert?",
    "text": "Was bedeutet der p-Wert?\np(Daten|H0)\n\nDer p-Wert ist die bedingte Wahrscheinlichkeit, die empirischen Daten (z.B. eine Mittelwertdifferenz zwischen zwei Gruppen) zu beobachten, wenn die Nullhypothese in der Grundgesamtheit gilt.\nBeispiel bei einem t-Test für eine Mittelwertdifferenz erhalten wir einen p-Wert von p = .08. Das bedeutet, wir würden in 8 von 100 Fällen eine mindestens gleich große Differenz beobachten, auch wenn in der Grundgesamtheit gar kein Unterschied ist."
  },
  {
    "objectID": "analyseverfahren/slides.html#was-bedeutet-der-p-wert-nicht",
    "href": "analyseverfahren/slides.html#was-bedeutet-der-p-wert-nicht",
    "title": "Anwendungsorientierte Analyseverfahren",
    "section": "Was bedeutet der p-Wert nicht?",
    "text": "Was bedeutet der p-Wert nicht?\n\np(Daten|H1): Die Wahrscheinlichkeit, die empirischen Daten zu beoachten, wenn die Alternativhypothese gilt.\np(H0|Daten): Die Wahrscheinlichkeit für die Richtigkeit der Nullhypothese im Lichte der Daten.\np(H1|Daten): Die Wahrscheinlichkeit für die Richtigkeit der Alternativhypothese im Licht der Daten.\nDer p-Wert sagt also nichts über die Wahrscheinlichkeit der Null- oder Alternativhypothese!\n\naußerdem:\n\nDas Ablehnen der Nullhypothese sagt nichts über die Alternativhypothese!\nDie meisten von uns interessieren sich nicht für die Frage, die der p-Wert beantwortet!"
  },
  {
    "objectID": "analyseverfahren/slides.html#was-bedeutet-dann-statistische-signifikanz",
    "href": "analyseverfahren/slides.html#was-bedeutet-dann-statistische-signifikanz",
    "title": "Anwendungsorientierte Analyseverfahren",
    "section": "Was bedeutet dann statistische Signifikanz?",
    "text": "Was bedeutet dann statistische Signifikanz?\n\nWir nennen ein Ergebnis statistisch signifikant, wenn \\(p &lt; \\alpha\\), wobei \\(\\alpha\\) das zuvor angenommene Signifikanzniveau ist.\nZwei mögliche Ursachen:\n\nDie Nullhypothese gilt, aber wir beobachten zufällig ein sehr seltenes Ereignis oder\nDie Nullhypothese gilt nicht. (Das heißt nicht, die Alternativhypothese gilt.)\n\nWenn \\(p &lt; .05\\), sind wir zuversichtlich, dass unsere Stichprobe nicht zu den 5% Abweichlern in der Welt der Nullhypothese gehört, sondern einfach die Nullhypothese nicht stimmt."
  },
  {
    "objectID": "analyseverfahren/slides.html#alpha--und-beta-fehler",
    "href": "analyseverfahren/slides.html#alpha--und-beta-fehler",
    "title": "Anwendungsorientierte Analyseverfahren",
    "section": "Alpha- und Beta-Fehler",
    "text": "Alpha- und Beta-Fehler\n\nQuelle: https://www.statisticssolutions.com"
  },
  {
    "objectID": "analyseverfahren/slides.html#alpha-fehler",
    "href": "analyseverfahren/slides.html#alpha-fehler",
    "title": "Anwendungsorientierte Analyseverfahren",
    "section": "Alpha-Fehler",
    "text": "Alpha-Fehler\n\n\n\nEin \\(\\alpha = .05\\) bedeutet, dass wir in 5 von 100 Fällen ein signifikantes Ergebnis bekommen, obwohl die Nullhypothese gilt.\nMit unseren 1000 Stichproben und \\(\\mu_0 = 170\\) sollten wir beim T-Test grob 50 fälschlich signifikante Ergebnisse bekommen.\nFehler ist abhängig von \\(\\alpha\\), aber unabhängig von den Daten und der konkreten \\(H_0\\).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nProblem: Wir wissen (wie immer!) nicht, ob unsere Stichprobe zu den grauen oder roten Stichproben gehört."
  },
  {
    "objectID": "analyseverfahren/slides.html#beta-fehler-und-statistische-power",
    "href": "analyseverfahren/slides.html#beta-fehler-und-statistische-power",
    "title": "Anwendungsorientierte Analyseverfahren",
    "section": "Beta-Fehler und statistische Power",
    "text": "Beta-Fehler und statistische Power\n\nUm Beta-Fehler (H0 wird fälschlich angenommen) zu verringern, brauchen wir statistische Power bzw. Präzision (vgl. Konfidenzintervalle).\nUm die Power/Präzision eines Tests/einer Schätzung zu erhöhen, muss man zumeist die Stichprobengröße erhöhen.\nPer Umstellung der SE-Formel kann man die nötige Stichprobengröße für erwartete Schätzer berechnen."
  },
  {
    "objectID": "analyseverfahren/slides.html#take-home-message",
    "href": "analyseverfahren/slides.html#take-home-message",
    "title": "Anwendungsorientierte Analyseverfahren",
    "section": "Take home message",
    "text": "Take home message\nInferenzstatistik ‚funktioniert’, weil…\n\nwir die Form der Verteilung von Kennwerten bei wiederholter Durchführung von Zufallsstichproben kennen (zentrales Grenzwerttheorem) und\nwir die Parameter der Verteilung aus den Daten unserer Stichprobe schätzen können.\nAber: wir kennen nur die Welt der Nullhypothese (egal für welchen Test und welchen Schätzer), d.h. alle Aussagen der NHST beziehen sich auf diese Welt.\nDie Präzision unserer Schätzung bzw. Power unseres Tests hängt ab von der Streuung des Merkmals und der Größe der Stichprobe (je größer, desto präziser). Entsprechend sollten Untersuchungen geplant werden.\nEs gibt immer Alpha- und Beta-Fehler, und für eine Stichprobe können wir nie exakt wissen, wo wir stehen."
  },
  {
    "objectID": "analyseverfahren/slides.html#hauptsache-signifikant",
    "href": "analyseverfahren/slides.html#hauptsache-signifikant",
    "title": "Anwendungsorientierte Analyseverfahren",
    "section": "Hauptsache signifikant?",
    "text": "Hauptsache signifikant?\n\nHypothesentests als stumpfe Rituale mit dem Ziel, p &lt; .05 zu erhalten.\nvon Konvention zum reinen Selbstzweck (Signifikanz = gut, keine = schlecht).\nDas sog. p-Hacking bedeutet, die Daten und Analysen so zu frisieren, bis ein stat. signifikantes Ergebnis erscheint.\nSignifikanz sagt nichts über substanzielle Bedeutung!\nBitte in Zukunft beachten:\n\nNicht p-hacken, nicht im Nachhinein am Alpha-Niveau schrauben!\nKein Bedauern nicht-signifikanter Ergebnisse (“leider knapp nicht signifikant”)!"
  },
  {
    "objectID": "analyseverfahren/slides.html#datenanalyse-als-rezeptsammlung",
    "href": "analyseverfahren/slides.html#datenanalyse-als-rezeptsammlung",
    "title": "Anwendungsorientierte Analyseverfahren",
    "section": "Datenanalyse als Rezeptsammlung",
    "text": "Datenanalyse als Rezeptsammlung\n\nIn der klassischen Statistikausbildung (auch bei uns) als Rezeptesammlung:\n\nMittelwerte in (genau) zwei Gruppen vergleichen - T-Test\nMittelwerte in mehr als zwei Gruppen vergleichen - Varianzanalyse (ANOVA)\nZusammenhänge von kategoriellen Variablen testen - \\(\\chi^2\\)-Test\n…\n\nFokus auf Unterschieden und Spezifika statt auf Gemeinsamkeiten\nViele Verfahren sind aber mindestens funktional, oft auch mathematisch äquivalent!"
  },
  {
    "objectID": "analyseverfahren/slides.html#beispielstudie-auty2004",
    "href": "analyseverfahren/slides.html#beispielstudie-auty2004",
    "title": "Anwendungsorientierte Analyseverfahren",
    "section": "Beispielstudie: Auty & Lewis (2004)",
    "text": "Beispielstudie: Auty & Lewis (2004)\n\nThere has been little attempt to understand the influence on children of branded products that appear in television programs and movies. A study exposed children of two different age groups (6–7 and 11–12) in classrooms to a brief film clip. Half of each class was shown a scene from Home Alone that shows Pepsi Cola being spilled during a meal. The other half was shown a similar clip from Home Alone but without branded products. All children were invited to help themselves from a choice of Pepsi or Coke at the outset of the individual interviews."
  },
  {
    "objectID": "analyseverfahren/slides.html#beispielstudie-daten",
    "href": "analyseverfahren/slides.html#beispielstudie-daten",
    "title": "Anwendungsorientierte Analyseverfahren",
    "section": "Beispielstudie: Daten",
    "text": "Beispielstudie: Daten\n\n\n\n\n\n\nid\n\n\npepsi_placement\n\n\npepsi_chosen\n\n\n\n\n\n\n49\n\n\n1\n\n\n0\n\n\n\n\n54\n\n\n1\n\n\n0\n\n\n\n\n19\n\n\n1\n\n\n1\n\n\n\n\n6\n\n\n1\n\n\n1\n\n\n\n\n52\n\n\n1\n\n\n0"
  },
  {
    "objectID": "analyseverfahren/slides.html#beispielstudie-chi-quadrat-test",
    "href": "analyseverfahren/slides.html#beispielstudie-chi-quadrat-test",
    "title": "Anwendungsorientierte Analyseverfahren",
    "section": "Beispielstudie: Chi-Quadrat Test",
    "text": "Beispielstudie: Chi-Quadrat Test\nKreuztabelle (Spaltenprozente)\n\n\n\n\n\n\npepsi_chosen\n\n\nno_placement\n\n\nplacement\n\n\n\n\n\n\n0\n\n\n57\n\n\n37\n\n\n\n\n1\n\n\n43\n\n\n63\n\n\n\n\n\n\n\n\nChi-Quadrat Test\n\n\n\n\n\nChi2(1)\np\nCramer’s V (adj.)\nCramers_v_adjusted CI\n\n\n\n\n4.14\n0.042\n0.17\n(0.00, 1.00)"
  },
  {
    "objectID": "analyseverfahren/slides.html#beispielstudie-bivariate-korrelation",
    "href": "analyseverfahren/slides.html#beispielstudie-bivariate-korrelation",
    "title": "Anwendungsorientierte Analyseverfahren",
    "section": "Beispielstudie: Bivariate Korrelation",
    "text": "Beispielstudie: Bivariate Korrelation\nPearson Korrelation\n\n\n\n\n\nParameter1\nParameter2\nr\n95% CI\np\n\n\n\n\npepsi_placement\npepsi_chosen\n0.20\n(0.01, 0.38)\n0.042\n\n\n\nAlternative hypothesis: true correlation is not equal to 0\n\n\n\n\nKendall Korrelation\n\n\n\n\n\nParameter1\nParameter2\ntau\nz\np\n\n\n\n\npepsi_placement\npepsi_chosen\n0.20\n2.03\n0.043\n\n\n\nAlternative hypothesis: true tau is not equal to 0"
  },
  {
    "objectID": "analyseverfahren/slides.html#beispielstudie-mittelwertvergleiche",
    "href": "analyseverfahren/slides.html#beispielstudie-mittelwertvergleiche",
    "title": "Anwendungsorientierte Analyseverfahren",
    "section": "Beispielstudie: Mittelwertvergleiche",
    "text": "Beispielstudie: Mittelwertvergleiche\nt-Test\n\n\n\n\n\nDifference\n95% CI\nt(103)\np\nd\n\n\n\n\n-0.20\n(-0.39, -0.01)\n-2.06\n0.042\n-0.41\n\n\n\n\n\n\n\nANOVA\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nSum_Squares\ndf\nMean_Square\nF\np\nEta2\n\n\n\n\npepsi_placement\n1.03\n1\n1.03\n4.23\n0.042\n0.04\n\n\nResiduals\n25.10\n103\n0.24"
  },
  {
    "objectID": "analyseverfahren/slides.html#gemeinsamkeiten-und-unterschiede",
    "href": "analyseverfahren/slides.html#gemeinsamkeiten-und-unterschiede",
    "title": "Anwendungsorientierte Analyseverfahren",
    "section": "Gemeinsamkeiten und Unterschiede",
    "text": "Gemeinsamkeiten und Unterschiede\n\ndieselbe Testentscheidung (signifikanter Unterschied zwischen den Gruppen bzw. signifikanter Zusammenhang zwischen Placement und Produktwahl).\nbei 3 Verfahren exakt gleicher p-Wert (d.h. Berechnung ist identisch), beim Chi-Quadrat-Test einen (leicht) abweichenden (d.h. Berechnung ist nicht identisch).\ndie Verfahren unterscheiden sich vor allem im Modelloutput\nmanchmal nur globale Teststatistiken (Chi-Quadrat, F-, t-Wert), manchmal auch Konfidenzintervalle oder Effektgrößen\nauch wenn es z.T. substanziell-statistische Unterschiede gibt, unterscheiden sich vor allem die Konventionen des Berichtens"
  },
  {
    "objectID": "analyseverfahren/slides.html#datenanalyse-als-statistische-modellierung",
    "href": "analyseverfahren/slides.html#datenanalyse-als-statistische-modellierung",
    "title": "Anwendungsorientierte Analyseverfahren",
    "section": "Datenanalyse als statistische Modellierung",
    "text": "Datenanalyse als statistische Modellierung\n\nDatenanalyse als Anwendung und Test bestimmter statistischer Modelle\nein statistisches Modell ist eine vereinfachte Vorstellung, wie die beobachteten Daten zustande kommen (könnten)\nwir wenden diese Modell an und prüfen, wie gut die empirischen Daten dazu passen\n\n\\[\noutcome_i = Model_i + error_i\n\\]\n\nbeobachtete Daten (Outcome) als Summe von modellierten und nicht-modellierten Zusammenhängen"
  },
  {
    "objectID": "analyseverfahren/slides.html#das-nullmodell",
    "href": "analyseverfahren/slides.html#das-nullmodell",
    "title": "Anwendungsorientierte Analyseverfahren",
    "section": "Das Nullmodell",
    "text": "Das Nullmodell\nFrage: Wenn wir nur einen Schätzwert \\(a\\) für \\(Y\\) haben, welcher ist der beste Schätzer?\n\\[\nY_i = a + \\epsilon_i\n\\]\n\ndas beste \\(a\\) ist dasjenige, das den Fehler \\(\\epsilon\\) minimiert (\\(\\epsilon_i = Y_i - a\\))\nbester Schätzer = kleinste Summe quadrierter Abweichungen \\(\\epsilon_i\\) von \\(y\\)\nKriterium der least squares -&gt; Ordinary Least Squares (OLS)\n\nAntwort: Mittelwert \\(\\bar{x}\\) als der beste Modellkoeffizient im Nullmodell\nProblem: damit erklärt das Modell aber nichts, es fehlt eine Prädiktorvariable \\(X\\)"
  },
  {
    "objectID": "analyseverfahren/slides.html#modellformel-für-das-glm-bivariat",
    "href": "analyseverfahren/slides.html#modellformel-für-das-glm-bivariat",
    "title": "Anwendungsorientierte Analyseverfahren",
    "section": "Modellformel für das GLM (bivariat)",
    "text": "Modellformel für das GLM (bivariat)\n\\[\nY_i = b_0 + b_1 X_i + \\epsilon_i\n\\]\n\nGrundidee, eine Variable \\(Y\\) (abhängige Variable, Outcome) durch ein statistisches Modell mit einem oder mehr Parametern \\(b\\) vorhersagen zu lassen\nAnnahme: linearer Zusammenhang, d.h. \\(Y\\) hängt nur von \\(b_0\\) und der durch \\(b_1\\) gewichteten (unabhängige) Prädiktorvariable \\(X\\) ab\n\\(b_0\\) = Intercept = Achsenabschnitt = vorhergesagter Wert von \\(Y\\), wenn \\(X = 0\\)\ngrundlegende Interpretation:\n\n“je mehr X, desto mehr Y”, wenn \\(b_1 &gt; 0\\), und\n“je mehr X, desto weniger Y”, wenn \\(b_1&lt;0\\).\n\nes bleibt ein Vorhersage- bzw. Residualfehler \\(\\epsilon\\) (der minimiert wird)"
  },
  {
    "objectID": "analyseverfahren/slides.html#modellformel-für-das-glm-multivariat",
    "href": "analyseverfahren/slides.html#modellformel-für-das-glm-multivariat",
    "title": "Anwendungsorientierte Analyseverfahren",
    "section": "Modellformel für das GLM (multivariat)",
    "text": "Modellformel für das GLM (multivariat)\n\\[\nY_i = b_0 + b_1 X_1 + + b_2 X_2 + b_3 X_3 + ... + \\epsilon_i\n\\]\n\nweil der Modell eine lineare Gleichung ist, können wir problemlos mehrere Prädikorvariablen \\(X\\) hinzufügen\nOutcome \\(Y\\) als eine (gewichtete) Linearkombination der Prädiktorvariablen \\(X_1\\) … \\(X_k\\)\nParameter \\(b_1\\), \\(b_2\\), \\(b3\\) … sind die Gewichte, mit denen die Prädiktoren \\(X\\) zur Vorhersage von \\(Y\\) beitragen\nInterpretation von jedem \\(b\\) ist dieselbe wie im bivariaten Fall\nIntercept \\(b_0\\) ist der vorhergesagte Wert von \\(Y\\), wenn alle \\(X_1 = X_2 = X_3 = 0\\)."
  },
  {
    "objectID": "analyseverfahren/slides.html#anwendungsfälle-des-glm",
    "href": "analyseverfahren/slides.html#anwendungsfälle-des-glm",
    "title": "Anwendungsorientierte Analyseverfahren",
    "section": "Anwendungsfälle des GLM",
    "text": "Anwendungsfälle des GLM\n\nWenn die Prädiktorvariablen \\(X\\) kategoriell sind, entspricht das GLM dem T-Test bzw. der Varianzanalyse.\nWenn die Prädiktorvariablen \\(X\\) metrisch sind, entspricht das GLM der linearen Regression bzw. Korrelation.\nMan kann problemlos beliebig viele kategorielle und metrische Prädiktoren mischen.\nDie Interpretation ist immer dieselbe, d.h. man muss nur eine Interpretationsregel lernen."
  },
  {
    "objectID": "analyseverfahren/slides.html#annahmen-und-erweiterungen",
    "href": "analyseverfahren/slides.html#annahmen-und-erweiterungen",
    "title": "Anwendungsorientierte Analyseverfahren",
    "section": "Annahmen und Erweiterungen",
    "text": "Annahmen und Erweiterungen\n\nAnnahme: Zusammenhang zwischen \\(X\\) und \\(Y\\) ist linear\n\nwenn die Annahme nicht gerechtfertigt ist, kann man auch andere funktionale Zusammenhänge modellieren, siehe Sitzung zur logistischen Regression\n\nAnnahme: Untersuchungseinheiten sind unabhängig voneinander\n\nwenn die Annahme verletzt ist, kann man Abhängigkeiten zwischen Fällen modellieren,  siehe Sitzung zu Multilevel-Modellen"
  },
  {
    "objectID": "analyseverfahren/slides.html#welche-kennziffern-sind-relevant",
    "href": "analyseverfahren/slides.html#welche-kennziffern-sind-relevant",
    "title": "Anwendungsorientierte Analyseverfahren",
    "section": "Welche Kennziffern sind relevant?",
    "text": "Welche Kennziffern sind relevant?\n\nModellparameter bzw. Regressionskoeffizienten \\(b\\) geben die geschätzten Zusammenhänge bzw. Unterschiede wieder\nKoeffizienten haben einen Punktschätzer und einen Standardfehler bzw. ein Konfidenzintervall (Inferenzstatistik)\n(Null-)Hypothesentests der Koeffizienten = testen, ob die beobachteten Daten zur Nullhypothese \\(b=0\\) passen\nModellgütemaße wie \\(R^2\\) quantifizieren, wie gut das statistische Modell insgesamt die Werte von \\(Y\\) vorhersagen kann (Verhältnis von vorhergesagter und Residualvarianz)"
  },
  {
    "objectID": "analyseverfahren/slides.html#modellvorhersagen",
    "href": "analyseverfahren/slides.html#modellvorhersagen",
    "title": "Anwendungsorientierte Analyseverfahren",
    "section": "Modellvorhersagen",
    "text": "Modellvorhersagen\n\nRegressionsmodelle sind Vorhersageinstrumente\nmit Hilfe der Regressionskoeffizienten kann man für jede Kombination von Prädiktoren \\(X\\) das Outcome \\(Y\\) vorhersagen\nVorhersagen für einzelne Individuen oder spezifische Gruppen (siehe Sitzung Modellvorhersagen)\nvorhergesagte Werte für die Visualisierung von Unterschieden und Zusammenhängen verwenden\nVorhersagen oft intuitiver zu verstehen als einzelne Parameterschätzungen"
  },
  {
    "objectID": "analyseverfahren/slides.html#wie-ist-nun-unser-glm-rezept",
    "href": "analyseverfahren/slides.html#wie-ist-nun-unser-glm-rezept",
    "title": "Anwendungsorientierte Analyseverfahren",
    "section": "Wie ist nun unser GLM-Rezept?",
    "text": "Wie ist nun unser GLM-Rezept?\n\nDaten einlesen und Outcome \\(Y\\) deskriptiv auswerten\nGLM spezifizieren (d.h. welches sind unsere Prädiktorvariablen?) und schätzen\nRegressionskoeffizienten interpretieren (Vorzeichen, Größe, Konfidenzintervall, stat. Signifikanz)\nModellgüte und ggf. globale Teststatistik interpretieren\ndurch das Modell vorhergesagte Werte schätzen, vergleichen, visualisieren"
  },
  {
    "objectID": "analyseverfahren/slides.html#beispielstudie-glm",
    "href": "analyseverfahren/slides.html#beispielstudie-glm",
    "title": "Anwendungsorientierte Analyseverfahren",
    "section": "Beispielstudie: GLM",
    "text": "Beispielstudie: GLM\nModelloutput (Regressionstabelle)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nCoefficient\n95% CI\nt(103)\np\nStd. Coef.\nFit\n\n\n\n\n(Intercept)\n0.43\n(0.29, 0.57)\n6.24\n&lt; .001\n0.00\n\n\n\npepsi placement\n0.20\n(0.01, 0.39)\n2.06\n0.042\n0.20\n\n\n\n\n\n\n\n\n\n\n\n\nAICc\n\n\n\n\n\n153.96\n\n\nR2\n\n\n\n\n\n0.04\n\n\nR2 (adj.)\n\n\n\n\n\n0.03\n\n\nSigma\n\n\n\n\n\n0.49"
  },
  {
    "objectID": "analyseverfahren/slides.html#interpretation",
    "href": "analyseverfahren/slides.html#interpretation",
    "title": "Anwendungsorientierte Analyseverfahren",
    "section": "Interpretation",
    "text": "Interpretation\n\nIntercept \\(b_0\\): in der Kontrollgruppe (kein Placement, \\(X = 0\\)) vorhergesagte Wahrscheinlichkeit von .43 für Pepsi\nRegressionskoeffizient \\(b_1\\): bei Placement (\\(X = 1\\)) ist die vorhergesagte Wahrscheinlichkeit für Pepsi .20 höher als ohne Placement\nder Regressionskoeffizient \\(b_1\\) ist stat. signifikant (p &lt; .05), d.h. er deckt sich nicht mit der Nullhypothese, dass es keinen Unterschied gibt\nModellvorhersage bei Pepsi-Placement: \\(0.43 + 0.20 * 1 = .63\\) in der Placement-Bedingung\n\\(R^2\\): das Modell kann 4% der Varianz im Outcome \\(Y\\) erklären, der Rest bleibt unerklärt."
  },
  {
    "objectID": "analyseverfahren/slides.html#was-sind-die-nachteile-der-glm-perspektive",
    "href": "analyseverfahren/slides.html#was-sind-die-nachteile-der-glm-perspektive",
    "title": "Anwendungsorientierte Analyseverfahren",
    "section": "Was sind die Nachteile der GLM-Perspektive?",
    "text": "Was sind die Nachteile der GLM-Perspektive?\n\nviele SozialwissenschaftlerInnen haben es anders gelernt und verinnerlicht (“Warum machst du nicht T-Test statt Regression?”).\nFachzeitschriften und Reviewer haben bestimmte Erwartungen und Vorgaben, AutorInnen präsentieren daher t-Test, ANOVA, etc.\nfür Lektürekompetenz müssen wir (leider!) weiterhin auch die anderen Verfahren interpretieren können"
  },
  {
    "objectID": "analyseverfahren/slides.html#korrelation-regression-und-glm",
    "href": "analyseverfahren/slides.html#korrelation-regression-und-glm",
    "title": "Anwendungsorientierte Analyseverfahren",
    "section": "Korrelation, Regression und GLM",
    "text": "Korrelation, Regression und GLM\n\nhistorisch zwei unterschiedliche Ansätze, den Zusammenhang zweier metrischer Variablen zu analysieren: Korrelation und Regression\nKorrelation basiert auf der Idee der Kovarianz, d.h. dem “gemeinsamen Variieren” zweier Variablen\nbivariate Regression als GLM, bei dem ein metrisches Outcome \\(Y\\) durch eine metrische Prädiktorvariable \\(X\\) vorhergesagt werden soll"
  },
  {
    "objectID": "analyseverfahren/slides.html#form-des-zusammenhangs",
    "href": "analyseverfahren/slides.html#form-des-zusammenhangs",
    "title": "Anwendungsorientierte Analyseverfahren",
    "section": "Form des Zusammenhangs",
    "text": "Form des Zusammenhangs"
  },
  {
    "objectID": "analyseverfahren/slides.html#regressions--vs.-korrelationskoeffizienten",
    "href": "analyseverfahren/slides.html#regressions--vs.-korrelationskoeffizienten",
    "title": "Anwendungsorientierte Analyseverfahren",
    "section": "Regressions- vs. Korrelationskoeffizienten",
    "text": "Regressions- vs. Korrelationskoeffizienten\n\nunstandardisierter Regressionskoeffizient \\(B\\) als Anstieg, d.h. zunächst Richtung des Zusammenhangs\nKorrelationskoeffizient \\(r\\) als Effektstärke, d.h. wie nahe die Werte von \\(Y\\) der Regressionsgeraden sind\nstarker Zusammenhang = wenig Residualvarianz = hohe Korrelation \\(r\\) = hohe Varianzaufklärung \\(R^2\\)"
  },
  {
    "objectID": "analyseverfahren/slides.html#unterschiedlich-starke-zusammenhänge",
    "href": "analyseverfahren/slides.html#unterschiedlich-starke-zusammenhänge",
    "title": "Anwendungsorientierte Analyseverfahren",
    "section": "Unterschiedlich starke Zusammenhänge",
    "text": "Unterschiedlich starke Zusammenhänge"
  },
  {
    "objectID": "analyseverfahren/slides.html#korrelationsmatrizen",
    "href": "analyseverfahren/slides.html#korrelationsmatrizen",
    "title": "Anwendungsorientierte Analyseverfahren",
    "section": "Korrelationsmatrizen",
    "text": "Korrelationsmatrizen\n\nQuelle: Scharkow, Festl, Vogelgesang & Quandt, 2013"
  },
  {
    "objectID": "analyseverfahren/slides.html#mal-wieder-korrelation-und-kausalität",
    "href": "analyseverfahren/slides.html#mal-wieder-korrelation-und-kausalität",
    "title": "Anwendungsorientierte Analyseverfahren",
    "section": "Mal wieder: Korrelation und Kausalität",
    "text": "Mal wieder: Korrelation und Kausalität\n\nQuelle: https://www.cjr.org/tow_center_reports/the_curious_journalists_guide_to_data.php"
  },
  {
    "objectID": "analyseverfahren/slides.html#bivariate-regression",
    "href": "analyseverfahren/slides.html#bivariate-regression",
    "title": "Anwendungsorientierte Analyseverfahren",
    "section": "Bivariate Regression",
    "text": "Bivariate Regression\n\nlinearer Zusammenhang zwischen \\(X\\) und \\(Y\\) wieder, wobei wir definieren, was Prädiktor \\(X\\) und was Outcome \\(Y\\) ist\ndie Modellformel wie immer: \\[ Y_i = b_0 + b_1 X_i + \\epsilon_i \\]\n\\(b_0\\) ist der vorhergesagte Wert von \\(Y\\), wenn \\(x=0\\)\n\\(b_1\\) ist der vorhergesagte Anstieg von \\(Y\\), wenn \\(X\\) um eine Einheit steigt (d.h. der Ansteig in Originalmetrik)\nändert sich die Metrik von \\(X\\) oder \\(Y\\), ändert sich die Interpretation von \\(b_1\\)"
  },
  {
    "objectID": "analyseverfahren/slides.html#intercepts-und-zentrierung",
    "href": "analyseverfahren/slides.html#intercepts-und-zentrierung",
    "title": "Anwendungsorientierte Analyseverfahren",
    "section": "Intercepts und Zentrierung",
    "text": "Intercepts und Zentrierung\n\nIntercept bzw. Konstante als vorausgesagte Wert von \\(Y\\), wenn \\(X=0\\)\nnur sinnvoll zu interpretieren, wenn \\(X\\) auch die Ausprägung 0 haben kann\nman kann \\(X\\) zentrieren, z.B. von allen Werten \\(x_i\\) eine Konstante \\(c\\) subtrahieren, dann ist Intercept der vorausgesagte Wert für \\(x = c\\)\nhäufigste Zentrierung ist die Mittelwertzentrierung, d.h. \\(c = \\bar{x}\\), der Intercept bezieht sich auf den durchschnittlichen Wert von \\(X\\)\nZentrierung ändert nichts an den Regressionskoeffizienten oder am Globalfit, sondern nur am Intercept"
  },
  {
    "objectID": "analyseverfahren/slides.html#effektgrößen-und-modellgüte",
    "href": "analyseverfahren/slides.html#effektgrößen-und-modellgüte",
    "title": "Anwendungsorientierte Analyseverfahren",
    "section": "Effektgrößen und Modellgüte",
    "text": "Effektgrößen und Modellgüte\n\njeder Koeffizient \\(B\\) hat einen Standardfehler SE(B) und ein Konfindenzintervall\nmit beiden lässt sich \\(H_0\\) prüfen können, dass kein linearer Zusammenhang existiert - bzw. ob die Daten sich mit \\(B=0\\) decken\n\\(B\\) lässt sich substantiell in der Metrik von \\(Y\\) interpretieren (eine Einheit mehr/weniger \\(X\\) entspricht \\(B\\) Einheiten mehr/weniger \\(Y\\)), er sagt aber nichts über die Stärke des Zusammenhangs oder Modellgüte\nwie gut das lineare Modell (im Vergleich zum Nullmodell ohne Prädiktoren) vorhersagt, kann man am \\(R^2\\) erkennen\nim bivariaten Fall entspricht das exakt dem quadrierten Korrelationskoeffizienten \\(r_{XY}\\)"
  },
  {
    "objectID": "analyseverfahren/slides.html#unstandardisierte-b-vs.-standardisierte-beta",
    "href": "analyseverfahren/slides.html#unstandardisierte-b-vs.-standardisierte-beta",
    "title": "Anwendungsorientierte Analyseverfahren",
    "section": "Unstandardisierte B vs. standardisierte Beta",
    "text": "Unstandardisierte B vs. standardisierte Beta\n\nInterpretation von unstandardisiertem \\(B\\) setzt voraus, dass wir die Metriken von \\(X\\) und vor allem \\(Y\\) kennen\noft wird (z.B. für Vergleiche oder Meta-Analysen) ein standardisiertes Maß gewünscht, das unabhängig von \\(X\\) und \\(Y\\) ist\nwir können Regressionskoeffizienten standardisieren, in dem wir\n\nentweder die Daten \\(X\\) und \\(Y\\) vor der Analyse z-standardisieren (M = 0, SD = 1)\noder den Koeffizienten selbst standardisieren, durch \\(\\beta = b \\frac{s_x}{s_y}\\)\n\nim bivariaten Fall (nur dort!) entspricht \\(\\beta\\) dem Korrelationskoeffizienten \\(r\\)"
  },
  {
    "objectID": "analyseverfahren/slides.html#korrelation-vs.-bivariate-regressionglm",
    "href": "analyseverfahren/slides.html#korrelation-vs.-bivariate-regressionglm",
    "title": "Anwendungsorientierte Analyseverfahren",
    "section": "Korrelation vs. bivariate Regression/GLM",
    "text": "Korrelation vs. bivariate Regression/GLM\n\n\\(r\\) als standardisierte Größe, d.h. auch ohne Kenntnis der Skalen von \\(X\\) und \\(Y\\) interpretierbar\nKorrelationsanalyse verführt ggf. weniger zu kausalen (Fehl-)Interpretationen als ein GLM mit unabhängiger und abhängiger Variable\nbei Korrelationen sind alternative Verfahren für nicht-metrische Daten (z.B. Spearmans Rangkorrelation) verbreitet\nbeim GLM bekommt mehr Informationen: unstandardisierte Effektgrößen (inkl. Intercept)\nbeide Verfahren liefern dieselben Schätzer und dieselben Testentscheidungen, basieren auf denselben Annahmen"
  },
  {
    "objectID": "analyseverfahren/slides.html#beispielstudie-johannes2022",
    "href": "analyseverfahren/slides.html#beispielstudie-johannes2022",
    "title": "Anwendungsorientierte Analyseverfahren",
    "section": "Beispielstudie Johannes et al. (2022):",
    "text": "Beispielstudie Johannes et al. (2022):"
  },
  {
    "objectID": "analyseverfahren/slides.html#daten",
    "href": "analyseverfahren/slides.html#daten",
    "title": "Anwendungsorientierte Analyseverfahren",
    "section": "Daten",
    "text": "Daten\n\n\n\n\n\n\n\n\ntv_time\n\n\nage\n\n\ngames_time\n\n\nmusic_time\n\n\n\n\n\n\n0.0\n\n\n22\n\n\n0\n\n\n4.00\n\n\n\n\n0.0\n\n\n43\n\n\n0\n\n\n2.50\n\n\n\n\n2.0\n\n\n38\n\n\n0\n\n\n0.17\n\n\n\n\n5.0\n\n\n30\n\n\n0\n\n\n2.00\n\n\n\n\n1.5\n\n\n29\n\n\n1\n\n\n0.75\n\n\n\n\n2.0\n\n\n57\n\n\n0\n\n\n0.00\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVariable\n\n\nSummary\n\n\n\n\n\n\nMean tv_time (SD)\n\n\n2.73 (3.67)\n\n\n\n\nMean age (SD)\n\n\n46.95 (14.67)\n\n\n\n\nMean games_time (SD)\n\n\n0.93 (2.41)\n\n\n\n\nMean music_time (SD)\n\n\n2.14 (2.75)"
  },
  {
    "objectID": "analyseverfahren/slides.html#outcome-variable",
    "href": "analyseverfahren/slides.html#outcome-variable",
    "title": "Anwendungsorientierte Analyseverfahren",
    "section": "Outcome-Variable",
    "text": "Outcome-Variable"
  },
  {
    "objectID": "analyseverfahren/slides.html#scatterplot",
    "href": "analyseverfahren/slides.html#scatterplot",
    "title": "Anwendungsorientierte Analyseverfahren",
    "section": "Scatterplot",
    "text": "Scatterplot"
  },
  {
    "objectID": "analyseverfahren/slides.html#korrelation-samt-hypothesentest",
    "href": "analyseverfahren/slides.html#korrelation-samt-hypothesentest",
    "title": "Anwendungsorientierte Analyseverfahren",
    "section": "Korrelation samt Hypothesentest",
    "text": "Korrelation samt Hypothesentest\n\n\n\n\n\nParameter1\nParameter2\nr\n95% CI\np\n\n\n\n\nage\nmusic_time\n-0.22\n(-0.26, -0.17)\n&lt; .001\n\n\n\nAlternative hypothesis: true correlation is not equal to 0"
  },
  {
    "objectID": "analyseverfahren/slides.html#bivariate-lineare-regression",
    "href": "analyseverfahren/slides.html#bivariate-lineare-regression",
    "title": "Anwendungsorientierte Analyseverfahren",
    "section": "Bivariate lineare Regression",
    "text": "Bivariate lineare Regression\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nCoefficient\n95% CI\nt(2101)\np\nStd. Coef.\nFit\n\n\n\n\n(Intercept)\n4.04\n(3.65, 4.42)\n20.53\n&lt; .001\n0.00\n\n\n\nage\n-0.04\n(-0.05, -0.03)\n-10.14\n&lt; .001\n-0.22\n\n\n\n\n\n\n\n\n\n\n\n\nAICc\n\n\n\n\n\n10125.19\n\n\nR2\n\n\n\n\n\n0.05\n\n\nR2 (adj.)\n\n\n\n\n\n0.05\n\n\nSigma\n\n\n\n\n\n2.68\n\n\n\n\n\n\n\nReminder: t-Wert = \\(B/SE(B)\\)\nInterpretation: stat. signifikant, wenn t &lt; -1.96 oder &gt; 1.96 (kritischer Wert der Normalverteilung)"
  },
  {
    "objectID": "analyseverfahren/slides.html#zentrierung-alter-18",
    "href": "analyseverfahren/slides.html#zentrierung-alter-18",
    "title": "Anwendungsorientierte Analyseverfahren",
    "section": "Zentrierung Alter = 18",
    "text": "Zentrierung Alter = 18\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nCoefficient\n95% CI\nt(2101)\np\nStd. Coef.\nFit\n\n\n\n\n(Intercept)\n3.31\n(3.06, 3.57)\n25.49\n&lt; .001\n0.00\n\n\n\nage18\n-0.04\n(-0.05, -0.03)\n-10.14\n&lt; .001\n-0.22\n\n\n\n\n\n\n\n\n\n\n\n\nAICc\n\n\n\n\n\n10125.19\n\n\nR2\n\n\n\n\n\n0.05\n\n\nR2 (adj.)\n\n\n\n\n\n0.05\n\n\nSigma\n\n\n\n\n\n2.68"
  },
  {
    "objectID": "analyseverfahren/slides.html#mittelwertzentrierung",
    "href": "analyseverfahren/slides.html#mittelwertzentrierung",
    "title": "Anwendungsorientierte Analyseverfahren",
    "section": "Mittelwertzentrierung",
    "text": "Mittelwertzentrierung\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nCoefficient\n95% CI\nt(2101)\np\nStd. Coef.\nFit\n\n\n\n\n(Intercept)\n2.14\n(2.03, 2.25)\n36.56\n&lt; .001\n0.00\n\n\n\nage centered\n-0.04\n(-0.05, -0.03)\n-10.14\n&lt; .001\n-0.22\n\n\n\n\n\n\n\n\n\n\n\n\nAICc\n\n\n\n\n\n10125.19\n\n\nR2\n\n\n\n\n\n0.05\n\n\nR2 (adj.)\n\n\n\n\n\n0.05\n\n\nSigma\n\n\n\n\n\n2.68"
  },
  {
    "objectID": "analyseverfahren/slides.html#transformierte-y-variable-minuten",
    "href": "analyseverfahren/slides.html#transformierte-y-variable-minuten",
    "title": "Anwendungsorientierte Analyseverfahren",
    "section": "Transformierte Y-Variable (Minuten)",
    "text": "Transformierte Y-Variable (Minuten)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nCoefficient\n95% CI\nt(2101)\np\nStd. Coef.\nFit\n\n\n\n\n(Intercept)\n128.40\n(121.51, 135.28)\n36.56\n&lt; .001\n0.00\n\n\n\nage centered\n-2.43\n(-2.90, -1.96)\n-10.14\n&lt; .001\n-0.22\n\n\n\n\n\n\n\n\n\n\n\n\nAICc\n\n\n\n\n\n27346.01\n\n\nR2\n\n\n\n\n\n0.05\n\n\nR2 (adj.)\n\n\n\n\n\n0.05\n\n\nSigma\n\n\n\n\n\n161.06"
  },
  {
    "objectID": "analyseverfahren/slides.html#z-standardisierte-variablen",
    "href": "analyseverfahren/slides.html#z-standardisierte-variablen",
    "title": "Anwendungsorientierte Analyseverfahren",
    "section": "Z-standardisierte Variablen",
    "text": "Z-standardisierte Variablen\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nCoefficient\n95% CI\nt(2101)\np\nStd. Coef.\nFit\n\n\n\n\n(Intercept)\n0.00\n(-0.04, 0.04)\n0.08\n0.936\n0.00\n\n\n\nage zstd\n-0.22\n(-0.26, -0.17)\n-10.14\n&lt; .001\n-0.22\n\n\n\n\n\n\n\n\n\n\n\n\nAICc\n\n\n\n\n\n5872.65\n\n\nR2\n\n\n\n\n\n0.05\n\n\nR2 (adj.)\n\n\n\n\n\n0.05\n\n\nSigma\n\n\n\n\n\n0.98"
  },
  {
    "objectID": "analyseverfahren/slides.html#wiederholung-tv-time-htag",
    "href": "analyseverfahren/slides.html#wiederholung-tv-time-htag",
    "title": "Anwendungsorientierte Analyseverfahren",
    "section": "Wiederholung: TV Time (h/Tag)",
    "text": "Wiederholung: TV Time (h/Tag)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nCoefficient\n95% CI\nt(2101)\np\nStd. Coef.\nFit\n\n\n\n\n(Intercept)\n3.91\n(3.39, 4.43)\n14.63\n&lt; .001\n0.00\n\n\n\nage\n-0.03\n(-0.04, -0.01)\n-4.62\n&lt; .001\n-0.10\n\n\n\n\n\n\n\n\n\n\n\n\nAICc\n\n\n\n\n\n11414.93\n\n\nR2\n\n\n\n\n\n0.01\n\n\nR2 (adj.)\n\n\n\n\n\n0.01\n\n\nSigma\n\n\n\n\n\n3.65\n\n\n\n\n\n\n\nDaten: Johannes et al., 2022"
  },
  {
    "objectID": "analyseverfahren/slides.html#mittelwerte-vergleichen",
    "href": "analyseverfahren/slides.html#mittelwerte-vergleichen",
    "title": "Anwendungsorientierte Analyseverfahren",
    "section": "Mittelwerte vergleichen",
    "text": "Mittelwerte vergleichen\n\nin Experimenten werden oft Mittelwerte einer oder mehrerer Outcome-Variablen \\(Y\\) zwischen verschiedenen Versuchsbedingungen verglichen.\nauch in nicht-experimentellen Analysen sind Mittelwertvergleiche häufig\nNullhypothese, dass zwischen den Gruppen kein Unterschied besteht, d.h. die Mittelwerte sich nicht unterscheiden\nmeistverwendet: t-Test oder einfaktorielle Varianzanalyse"
  },
  {
    "objectID": "analyseverfahren/slides.html#dichotome-prädiktoren",
    "href": "analyseverfahren/slides.html#dichotome-prädiktoren",
    "title": "Anwendungsorientierte Analyseverfahren",
    "section": "Dichotome Prädiktoren",
    "text": "Dichotome Prädiktoren\n\nGruppierungsvariable wird in eine Dummy-Variablen recodiert (0 = Merkmal nicht vorhanden, 1 = Merkmal vorhanden)\nDummy-Variable wird in das Regressionsmodell aufgenommen: \\(Y_i = b_0 + b_1 X_i + \\epsilon_i\\)\nReferenzgruppe (\\(X = 0\\)), ergibt \\(Y = b_0\\) (Intercept = Mittelwert der Kontrollgruppe)\n\\(b_1\\) als Differenz zwischen der Gruppe 1 und der Referenzgruppe\nt-Wert (B/SE(B) des Regressionskoeffizienten exakt wie beim t-Test"
  },
  {
    "objectID": "analyseverfahren/slides.html#alternative-codierung-für-x",
    "href": "analyseverfahren/slides.html#alternative-codierung-für-x",
    "title": "Anwendungsorientierte Analyseverfahren",
    "section": "Alternative Codierung für X",
    "text": "Alternative Codierung für X\n\nDummy-Codierung als meistverbreitete, aber nicht einzige Art, kategorielle Variablen abzubilden\nwichtig ist nur, dass\n\nunterschiedliche Gruppen unterschiedliche Zahlenwerte erhalten\nklar ist, was ein Unterschied von 1 bedeutet (Interpretation Regressionskoeffizient)\nder Intercept sinnvoll interpretierbar ist\n\nBeispiel: simple coding mit -0.5 und 0.5 bei zwei Gruppen (vgl. Zentrierung) -  \\(b_0\\) ist der Gesamtmittelwert, \\(b_1\\) wieder der Unterschied zwischen den Gruppen\n\n\n\nBeispiele: https://stats.oarc.ucla.edu/r/library/r-library-contrast-coding-systems-for-categorical-variables/"
  },
  {
    "objectID": "analyseverfahren/slides.html#mehr-als-zwei-mittelwerte-vergleichen",
    "href": "analyseverfahren/slides.html#mehr-als-zwei-mittelwerte-vergleichen",
    "title": "Anwendungsorientierte Analyseverfahren",
    "section": "Mehr als zwei Mittelwerte vergleichen",
    "text": "Mehr als zwei Mittelwerte vergleichen\n\ntraditionell die einfaktorielle Varianzanalyse (ANOVA) als Standardauswertung\nF-Test der Varianzanalyse prüft die Nullhypothese, dass alle Mittelwerte gleich sind (keine Unterschiede zwischen den Gruppen)\nAlternativhypothese (“Irgendwelche Gruppen unterscheiden sich in \\(Y\\)”) oft theoretisch sehr unbefriedigend\nweil der F-Test nicht sagt, welche Gruppen sich im Mittelwert von \\(Y\\) signifikant unterscheiden, ist oft ein zweiter Analyseschritt nötig\nPost-hoc-Tests oder Kontraste, d.h. (ausgewählte oder alle) paarweisen Vergleiche zwischen zwei Gruppen"
  },
  {
    "objectID": "analyseverfahren/slides.html#glm-mit-mehr-als-zwei-gruppen",
    "href": "analyseverfahren/slides.html#glm-mit-mehr-als-zwei-gruppen",
    "title": "Anwendungsorientierte Analyseverfahren",
    "section": "GLM mit mehr als zwei Gruppen",
    "text": "GLM mit mehr als zwei Gruppen\n\num \\(k\\) Gruppen zu vergleichen, werden \\(k-1\\) Prädiktor-Variablen erstellt (vor oder automatisch während der Analyse)\ndie \\(k-1\\) Variablen werden in das Regressionsmodell aufgenommen: \\(Y_i = b_0 + b_1 X_1 + b_2 X_2 + ... + b_{k-1} X_{k-1} + \\epsilon_i\\).\nin der Referenzgruppe (alle \\(X_1 = X_2 = ... = 0\\)) ergibt sich \\(Y = b_0\\) (Intercept = Mittelwert der Referenzgruppe)\n\\(b_1\\) gibt (bei Dummy-Codierung) die Differenz zwischen der Gruppe 1 und der Referenzgruppe wider, \\(b_2\\) die Differenz zwischen der Gruppe 2 und der Referenzgruppe, etc.\nman kann mehrere, aber nicht alle paarweisen Vergleiche gleichzeitig modellieren"
  },
  {
    "objectID": "analyseverfahren/slides.html#dummy-codierung-4-gruppen",
    "href": "analyseverfahren/slides.html#dummy-codierung-4-gruppen",
    "title": "Anwendungsorientierte Analyseverfahren",
    "section": "Dummy-Codierung 4 Gruppen",
    "text": "Dummy-Codierung 4 Gruppen\n\n\n\nGruppe A als Referenz\n\n\n\n\n\n\nZugehörigkeit\n\n\nGruppe B\n\n\nGruppe C\n\n\nGruppe D\n\n\n\n\n\n\nGruppe A\n\n\n0\n\n\n0\n\n\n0\n\n\n\n\nGruppe B\n\n\n1\n\n\n0\n\n\n0\n\n\n\n\nGruppe C\n\n\n0\n\n\n1\n\n\n0\n\n\n\n\nGruppe D\n\n\n0\n\n\n0\n\n\n1\n\n\n\n\n\n\n\nGruppe D als Referenz\n\n\n\n\n\n\nZugehörigkeit\n\n\nGruppe A\n\n\nGruppe B\n\n\nGruppe C\n\n\n\n\n\n\nGruppe D\n\n\n0\n\n\n0\n\n\n0\n\n\n\n\nGruppe A\n\n\n1\n\n\n0\n\n\n0\n\n\n\n\nGruppe B\n\n\n0\n\n\n1\n\n\n0\n\n\n\n\nGruppe C\n\n\n0\n\n\n0\n\n\n1"
  },
  {
    "objectID": "analyseverfahren/slides.html#kontraste-durch-gezielte-codierung",
    "href": "analyseverfahren/slides.html#kontraste-durch-gezielte-codierung",
    "title": "Anwendungsorientierte Analyseverfahren",
    "section": "Kontraste durch gezielte Codierung",
    "text": "Kontraste durch gezielte Codierung\n\nspezifische Kontraste durch verschiedene Codierungen für die Prädiktorvariablen (vgl. Davis, 2010)\neinfache Alternative: Referenzgruppe ändern, Modell neu schätzen\nzahlreiche z.T. komplexe Codierungsverfahren, um z.B. ordinale Gruppenvariablen abzubilden\nBeispiel: Helmert coding , bei dem eine Gruppe mit jeweils allen nachfolgenden Gruppen verglichen werden,\n\nKontrollgruppe mit allen Treatments\nTreatment 1 mit Treatment 2, etc.\n\n\n\n\nBeispiele: https://stats.oarc.ucla.edu/r/library/r-library-contrast-coding-systems-for-categorical-variables/"
  },
  {
    "objectID": "analyseverfahren/slides.html#post-hoc-tests",
    "href": "analyseverfahren/slides.html#post-hoc-tests",
    "title": "Anwendungsorientierte Analyseverfahren",
    "section": "Post-hoc-Tests",
    "text": "Post-hoc-Tests\n\nfür kategorielle Prädiktoren kann man anhand des geschätzten Modells alle Mittelwerte paarweise vergleichen\nentspricht separaten T-Tests mit je zwei Gruppen\naufgrund der Vielzahl einzelner Tests erhöht sich die Gefahr von Alpha-Fehlern (d.h. irrtümlich signifikante Ergebnisse)\np-Werte (manchmal auch die CI) sollten daher korrigiert werden sollten (vgl. Bender & Lange, 2001)\nverschiedenste Korrekturverfahren möglich (Bonferroni, Hochberg), eines sollte gewählt werden"
  },
  {
    "objectID": "analyseverfahren/slides.html#glm-vs.-t-testanova",
    "href": "analyseverfahren/slides.html#glm-vs.-t-testanova",
    "title": "Anwendungsorientierte Analyseverfahren",
    "section": "GLM vs. t-Test/ANOVA",
    "text": "GLM vs. t-Test/ANOVA\nVorteile\n\nkeine unterschiedliche Nomenklatur und Testverfahren, egal ob 2 oder mehr Gruppen\n\\(b\\)-Koeffizienten sind direkt als Mittelwertdifferenzen zwischen Gruppen interpretierbar, d.h. oft sind Post-Hoc-Tests unnötig\nbeliebig erweiterbar durch weitere kategorielle und metrische Prädiktoren\noft wird der globale F-Test sowie das \\(R^2\\) als Effektstärkemaß zusätzlich ausgegeben\n\nNachteile\n\nKonvention und Fachgeschichte, d.h. GutachterInnen erwarten ANOVA oder t-Test\nDummy-Codierung (oder andere Effekt-Codierungen) machen ggf. Zusatzaufwand"
  },
  {
    "objectID": "analyseverfahren/slides.html#beispielstudie-kümpel2019",
    "href": "analyseverfahren/slides.html#beispielstudie-kümpel2019",
    "title": "Anwendungsorientierte Analyseverfahren",
    "section": "Beispielstudie: Kümpel (2019)",
    "text": "Beispielstudie: Kümpel (2019)\n\nComing across news on social network sites (SNS) largely depends on news-related activities in one’s network. Although there are many different ways to stumble upon news, limited research has been conducted on how distinct news curation practices influence users’ intention to consume encountered content. In this mixed-methods investigation, using Facebook as an example, we first examine the results of an experiment (study 1, n = 524), showing that getting tagged in comments to news posts promotes news consumption the most."
  },
  {
    "objectID": "analyseverfahren/slides.html#daten-1",
    "href": "analyseverfahren/slides.html#daten-1",
    "title": "Anwendungsorientierte Analyseverfahren",
    "section": "Daten",
    "text": "Daten\n\n\n\n\n\n\n\n\nmodus\n\n\nrw\n\n\nmodus_tag\n\n\n\n\n\n\nTag\n\n\n5\n\n\n1\n\n\n\n\nChronik\n\n\n2\n\n\n0\n\n\n\n\nPost\n\n\n3\n\n\n0\n\n\n\n\nDM\n\n\n1\n\n\n0\n\n\n\n\nChronik\n\n\n1\n\n\n0\n\n\n\n\nChronik\n\n\n2\n\n\n0\n\n\n\n\n\n\n\n\n\nOutcome-Variable\n\n\n\n\n\n\nVariable\n\n\nSummary\n\n\n\n\n\n\nMean rw (SD)\n\n\n3.04 (1.30)\n\n\n\n\n\n\n\n\nGruppenmittelwerte\n\n\n\n\n\n\nmodus\n\n\nn\n\n\nM\n\n\nSD\n\n\n\n\n\n\nChronik\n\n\n141\n\n\n2.88\n\n\n1.20\n\n\n\n\nPost\n\n\n97\n\n\n2.79\n\n\n1.25\n\n\n\n\nTag\n\n\n152\n\n\n3.51\n\n\n1.33\n\n\n\n\nDM\n\n\n134\n\n\n2.84\n\n\n1.28"
  },
  {
    "objectID": "analyseverfahren/slides.html#outcome-variable-2",
    "href": "analyseverfahren/slides.html#outcome-variable-2",
    "title": "Anwendungsorientierte Analyseverfahren",
    "section": "Outcome-Variable",
    "text": "Outcome-Variable"
  },
  {
    "objectID": "analyseverfahren/slides.html#t-test-1",
    "href": "analyseverfahren/slides.html#t-test-1",
    "title": "Anwendungsorientierte Analyseverfahren",
    "section": "t-Test",
    "text": "t-Test\n\n\n\n\n\nDifference\n95% CI\nt(522)\np\nd\n\n\n\n\n-0.67\n(-0.91, -0.43)\n-5.51\n&lt; .001\n-0.48"
  },
  {
    "objectID": "analyseverfahren/slides.html#glm-mit-zwei-gruppen",
    "href": "analyseverfahren/slides.html#glm-mit-zwei-gruppen",
    "title": "Anwendungsorientierte Analyseverfahren",
    "section": "GLM mit zwei Gruppen",
    "text": "GLM mit zwei Gruppen\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nCoefficient\n95% CI\nt(522)\np\nStd. Coef.\nFit\n\n\n\n\n(Intercept)\n2.84\n(2.71, 2.97)\n43.26\n&lt; .001\n0.00\n\n\n\nmodus tag\n0.67\n(0.43, 0.91)\n5.51\n&lt; .001\n0.23\n\n\n\n\n\n\n\n\n\n\n\n\nAICc\n\n\n\n\n\n1738.89\n\n\nR2\n\n\n\n\n\n0.05\n\n\nR2 (adj.)\n\n\n\n\n\n0.05\n\n\nSigma\n\n\n\n\n\n1.27"
  },
  {
    "objectID": "analyseverfahren/slides.html#anova-mit-vier-gruppen",
    "href": "analyseverfahren/slides.html#anova-mit-vier-gruppen",
    "title": "Anwendungsorientierte Analyseverfahren",
    "section": "ANOVA mit vier Gruppen",
    "text": "ANOVA mit vier Gruppen\n\n\n\n\n\nParameter\nSum_Squares\ndf\nMean_Square\nF\np\nEta2\n\n\n\n\nmodus\n49.12\n3\n16.37\n10.17\n&lt; .001\n0.06\n\n\nResiduals\n837.19\n520\n1.61"
  },
  {
    "objectID": "analyseverfahren/slides.html#glm-mit-vier-gruppen",
    "href": "analyseverfahren/slides.html#glm-mit-vier-gruppen",
    "title": "Anwendungsorientierte Analyseverfahren",
    "section": "GLM mit vier Gruppen",
    "text": "GLM mit vier Gruppen\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nCoefficient\n95% CI\nt(520)\np\nStd. Coef.\nFit\n\n\n\n\n(Intercept)\n2.88\n(2.67, 3.09)\n26.95\n&lt; .001\n-0.12\n\n\n\nmodus (Post)\n-0.09\n(-0.41, 0.24)\n-0.51\n0.609\n-0.07\n\n\n\nmodus (Tag)\n0.63\n(0.34, 0.93)\n4.27\n&lt; .001\n0.49\n\n\n\nmodus (DM)\n-0.04\n(-0.34, 0.26)\n-0.28\n0.776\n-0.03\n\n\n\n\n\n\n\n\n\n\n\n\nAICc\n\n\n\n\n\n1742.69\n\n\nR2\n\n\n\n\n\n0.06\n\n\nR2 (adj.)\n\n\n\n\n\n0.05\n\n\nSigma\n\n\n\n\n\n1.27"
  },
  {
    "objectID": "analyseverfahren/slides.html#referenzkategorie-ändern",
    "href": "analyseverfahren/slides.html#referenzkategorie-ändern",
    "title": "Anwendungsorientierte Analyseverfahren",
    "section": "Referenzkategorie ändern",
    "text": "Referenzkategorie ändern\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nCoefficient\n95% CI\nt(520)\np\nStd. Coef.\nFit\n\n\n\n\n(Intercept)\n2.84\n(2.62, 3.05)\n25.87\n&lt; .001\n-0.15\n\n\n\nmodus dm (Chronik)\n0.04\n(-0.26, 0.34)\n0.28\n0.776\n0.03\n\n\n\nmodus dm (Post)\n-0.04\n(-0.37, 0.29)\n-0.25\n0.804\n-0.03\n\n\n\nmodus dm (Tag)\n0.68\n(0.38, 0.97)\n4.50\n&lt; .001\n0.52\n\n\n\n\n\n\n\n\n\n\n\n\nAICc\n\n\n\n\n\n1742.69\n\n\nR2\n\n\n\n\n\n0.06\n\n\nR2 (adj.)\n\n\n\n\n\n0.05\n\n\nSigma\n\n\n\n\n\n1.27"
  },
  {
    "objectID": "analyseverfahren/slides.html#post-hockontraste",
    "href": "analyseverfahren/slides.html#post-hockontraste",
    "title": "Anwendungsorientierte Analyseverfahren",
    "section": "Post-hoc/Kontraste",
    "text": "Post-hoc/Kontraste\n\n\n\n\n\n\nterm\n\n\ncontrast\n\n\nestimate\n\n\nstd.error\n\n\nstatistic\n\n\np.value\n\n\nconf.low\n\n\nconf.high\n\n\np_adjusted\n\n\n\n\n\n\nmodus\n\n\nDM - Chronik\n\n\n-0.04\n\n\n0.15\n\n\n-0.28\n\n\n0.78\n\n\n-0.34\n\n\n0.26\n\n\n1\n\n\n\n\nmodus\n\n\nDM - Post\n\n\n0.04\n\n\n0.17\n\n\n0.25\n\n\n0.80\n\n\n-0.29\n\n\n0.37\n\n\n1\n\n\n\n\nmodus\n\n\nDM - Tag\n\n\n-0.68\n\n\n0.15\n\n\n-4.50\n\n\n0.00\n\n\n-0.97\n\n\n-0.38\n\n\n0\n\n\n\n\nmodus\n\n\nPost - Chronik\n\n\n-0.09\n\n\n0.17\n\n\n-0.51\n\n\n0.61\n\n\n-0.41\n\n\n0.24\n\n\n1\n\n\n\n\nmodus\n\n\nTag - Chronik\n\n\n0.63\n\n\n0.15\n\n\n4.27\n\n\n0.00\n\n\n0.34\n\n\n0.92\n\n\n0\n\n\n\n\nmodus\n\n\nTag - Post\n\n\n0.72\n\n\n0.16\n\n\n4.36\n\n\n0.00\n\n\n0.40\n\n\n1.04\n\n\n0\n\n\n\n\n\n\n\n\np-Werte (adjusted) mit Bonferroni-Korrektur"
  },
  {
    "objectID": "analyseverfahren/slides.html#vorhergesagte-mittelwerte",
    "href": "analyseverfahren/slides.html#vorhergesagte-mittelwerte",
    "title": "Anwendungsorientierte Analyseverfahren",
    "section": "Vorhergesagte Mittelwerte",
    "text": "Vorhergesagte Mittelwerte\n\n\n\n\n\n\nmodus\n\n\nestimate\n\n\nstd.error\n\n\nstatistic\n\n\np.value\n\n\nconf.low\n\n\nconf.high\n\n\ndf\n\n\n\n\n\n\nChronik\n\n\n2.88\n\n\n0.11\n\n\n26.95\n\n\n0\n\n\n2.67\n\n\n3.09\n\n\nInf\n\n\n\n\nPost\n\n\n2.79\n\n\n0.13\n\n\n21.69\n\n\n0\n\n\n2.54\n\n\n3.05\n\n\nInf\n\n\n\n\nTag\n\n\n3.51\n\n\n0.10\n\n\n34.14\n\n\n0\n\n\n3.31\n\n\n3.71\n\n\nInf\n\n\n\n\nDM\n\n\n2.84\n\n\n0.11\n\n\n25.87\n\n\n0\n\n\n2.62\n\n\n3.05\n\n\nInf"
  },
  {
    "objectID": "analyseverfahren/slides.html#visualisierungsvorschlag",
    "href": "analyseverfahren/slides.html#visualisierungsvorschlag",
    "title": "Anwendungsorientierte Analyseverfahren",
    "section": "Visualisierungsvorschlag",
    "text": "Visualisierungsvorschlag"
  },
  {
    "objectID": "analyseverfahren/slides.html#literatur",
    "href": "analyseverfahren/slides.html#literatur",
    "title": "Anwendungsorientierte Analyseverfahren",
    "section": "Literatur",
    "text": "Literatur\nBender, R., & Lange, S. (2001). Adjusting for multiple testing—when and how?. Journal of clinical epidemiology, 54(4), 343-349.\nDavis, M. J. (2010). Contrast coding in multiple regression analysis: Strengths, weaknesses, and utility of popular coding structures. Journal of data science, 8(1), 61-73.\nKümpel, A. S. (2019). Getting tagged, getting involved with news? A mixed-methods investigation of the effects and motives of news-related tagging activities on social network sites. Journal of Communication, 69(4), 373-395."
  },
  {
    "objectID": "analyseverfahren/slides.html#take-home-aufgabe-1",
    "href": "analyseverfahren/slides.html#take-home-aufgabe-1",
    "title": "Anwendungsorientierte Analyseverfahren",
    "section": "Take-home Aufgabe #1",
    "text": "Take-home Aufgabe #1\nWir vergleichen die Tanzbarkeit (danceability) und musikalische Stimmung (valence) der Top 10-Hits über 4 Dekaden (1990er bis 2020er) auf Basis von Billboard und Spotify-Daten.\nBeide Variablen sind von 0 (niedrig) - 100 (hoch) skaliert. Die Mittelwerte und Fallzahlen pro Dekade sind wie folgt:\n\n\n\n\n\n\n\n\ndecade\n\n\ndanceability\n\n\nvalence\n\n\nn\n\n\n\n\n\n\n1990s\n\n\n64.72\n\n\n56.09\n\n\n588\n\n\n\n\n2000s\n\n\n67.34\n\n\n57.98\n\n\n558\n\n\n\n\n2010s\n\n\n67.31\n\n\n51.93\n\n\n499\n\n\n\n\n2020s\n\n\n66.10\n\n\n51.38\n\n\n69"
  },
  {
    "objectID": "analyseverfahren/slides.html#studienleistung-teil-1",
    "href": "analyseverfahren/slides.html#studienleistung-teil-1",
    "title": "Anwendungsorientierte Analyseverfahren",
    "section": "Studienleistung, Teil 1",
    "text": "Studienleistung, Teil 1\n\nInterpretieren sie die Ergebnisse der beiden linearen Modelle, in denen die Mittelwertunterschiede getestet werden, Zeile für Zeile.\nWelche Dekaden werden nicht miteinander verglichen, d.h. für diese bräuchten wir Post-Hoc Vergleiche?\n\nLösung bitte bis 04.06.2025, 10 Uhr in Moodle eintragen.\n\n\n\n\n\n\n\n\n\n \ndanceability\n\n\nPredictors\nCoefficient (B)\nSE (B)\np\n\n\n(Intercept)\n64.72\n0.59\n&lt;0.001\n\n\ndecade [2000s]\n2.62\n0.85\n0.002\n\n\ndecade [2010s]\n2.59\n0.88\n0.003\n\n\ndecade [2020s]\n1.38\n1.83\n0.452\n\n\n\n\n\n\n\n\n\n\n\n\n\n \nvalence\n\n\nPredictors\nCoefficient (B)\n95% CI (B)\n\n\n(Intercept)\n51.38\n45.97 – 56.79\n\n\ndecade [1990s]\n4.71\n-1.01 – 10.43\n\n\ndecade [2000s]\n6.60\n0.87 – 12.34\n\n\ndecade [2010s]\n0.56\n-5.22 – 6.33"
  },
  {
    "objectID": "analyseverfahren/slides.html#wiederholung-facebook-news",
    "href": "analyseverfahren/slides.html#wiederholung-facebook-news",
    "title": "Anwendungsorientierte Analyseverfahren",
    "section": "Wiederholung: Facebook-News",
    "text": "Wiederholung: Facebook-News\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nCoefficient\n95% CI\nt(520)\np\nStd. Coef.\nFit\n\n\n\n\n(Intercept)\n3.51\n(3.31, 3.72)\n34.14\n&lt; .001\n0.37\n\n\n\nmodus (Post)\n-0.72\n(-1.04, -0.40)\n-4.36\n&lt; .001\n-0.55\n\n\n\nmodus (Chronik)\n-0.63\n(-0.93, -0.34)\n-4.27\n&lt; .001\n-0.49\n\n\n\nmodus (DM)\n-0.68\n(-0.97, -0.38)\n-4.50\n&lt; .001\n-0.52\n\n\n\n\n\n\n\n\n\n\n\n\nAICc\n\n\n\n\n\n1742.69\n\n\nR2\n\n\n\n\n\n0.06\n\n\nR2 (adj.)\n\n\n\n\n\n0.05\n\n\nSigma\n\n\n\n\n\n1.27\n\n\n\n\n\n\n\nOutcome: Rezeptionswahrscheinlichkeit, Referenzkategorie: Tagging, Daten: Kümpel, 2019"
  },
  {
    "objectID": "analyseverfahren/slides.html#multiple-regression-und-das-glm",
    "href": "analyseverfahren/slides.html#multiple-regression-und-das-glm",
    "title": "Anwendungsorientierte Analyseverfahren",
    "section": "Multiple Regression und das GLM",
    "text": "Multiple Regression und das GLM\n\nim GLM können mehrere Prädiktorvariablen in einem Modell kombiniert werden\ndie Regressionskoeffizienten \\(B\\) sind wie sonst auch zu interpretieren, mit der Annahme, dass die anderen Prädiktoren sich nicht ändern (“ceteris paribus”)\nder Intercept \\(B_0\\) ist der erwartete Wert von \\(Y\\), wenn alle Prädiktoren \\(X=0\\) sind\ndas \\(R^2\\) ist die durch alle Prädiktoren erklärte Varianz in \\(Y\\), d.h. nicht mehr nur die quadrierte Korrelation von \\(X\\) und \\(Y\\)\nder F-Test ist nun ein Omnibustest, d.h. er prüft, ob irgendeine Variable \\(X\\) einen signifikanten Zusammenhang mit \\(Y\\) hat"
  },
  {
    "objectID": "analyseverfahren/slides.html#multiple-vs.-viele-bivariate-regressionen",
    "href": "analyseverfahren/slides.html#multiple-vs.-viele-bivariate-regressionen",
    "title": "Anwendungsorientierte Analyseverfahren",
    "section": "Multiple vs. viele bivariate Regressionen",
    "text": "Multiple vs. viele bivariate Regressionen\n\nin klassischen Befragungsstudien haben wir oft mehrere plausible Prädiktoren\neine multiple Regression vermeidete unnötig viele Einzeltests\ntechnisch ist es trivial, mehrere Prädiktoren ins Modell zu nehmen\ndie Zusammenhänge zwischen Prädiktoren und Outcome werden unter Berücksichtigung der anderen Variablen im Modell geschätzt (Drittvariablenkontrolle)\nein Modell mit mehreren Prädiktoren kann besser \\(Y\\) voraussagen als ein Modell mit weniger Prädiktoren"
  },
  {
    "objectID": "analyseverfahren/slides.html#regressionskoeffizienten",
    "href": "analyseverfahren/slides.html#regressionskoeffizienten",
    "title": "Anwendungsorientierte Analyseverfahren",
    "section": "Regressionskoeffizienten",
    "text": "Regressionskoeffizienten\n\nbei multiplen Regressionen sollten standardisierte und unstandardisierte Regressionskoeffizienten berichtet werden\nunstandardisierte Koeffizienten lassen sich\n\nin der Originalmetrik von \\(X\\) und \\(Y\\) interpretieren und\nsind beim Vergleich von Modellen mit verschiedenen \\(Y\\), aber denselben \\(X\\) sinnvoll\n\nstandardisierte Koeffizienten sind sinnvoll, um\n\ngenerell die Größe der Effekte abschätzen und\ninnerhalb desselben Modells den relativen Einfluss verschiedener Variablen vergleichen zu können"
  },
  {
    "objectID": "analyseverfahren/slides.html#drittvariablen-multikollinearität",
    "href": "analyseverfahren/slides.html#drittvariablen-multikollinearität",
    "title": "Anwendungsorientierte Analyseverfahren",
    "section": "Drittvariablen & Multikollinearität",
    "text": "Drittvariablen & Multikollinearität\n\ndurch Hinzunahme einer weiteren \\(X_2\\) Prädiktorvariable wird deren gemeinsamer Einfluss auf \\(X_1\\) und \\(Y\\) in der Schätzung berücksichtigt\neine statistische Berücksichtigung ist jedoch keinesfalls mit einer kausalen Berücksichtigung oder Konstanthaltung zu verwechseln\nwenn \\(X_1\\) und \\(X_2\\) untereinander korrelieren, sprechen wir von Multikollinearität\nobwohl die Schätzer \\(B_1\\) und \\(B_2\\) unverzerrt sind, wird die Präzision bei Multikollinearität geringer, d.h. die Standardfehler größer\nMultikollinearität ist kein statistisches Problem und kann daher auch nicht statistisch (z.B. durch Zentrierung) gelöst werden, sondern nur durch Änderungen in der Messung oder Variablenauswahl"
  },
  {
    "objectID": "analyseverfahren/slides.html#modellgüte-r2-und-f-test",
    "href": "analyseverfahren/slides.html#modellgüte-r2-und-f-test",
    "title": "Anwendungsorientierte Analyseverfahren",
    "section": "Modellgüte: \\(R^2\\) und F-Test",
    "text": "Modellgüte: \\(R^2\\) und F-Test\n\nim bivariaten Fall entspricht das \\(R^2\\) dem Determinationskoeffizienten \\(r^2\\), also der quadrierten Korrelation\nalternative Herleitung als Verhältnis von erklärter (modellierter) und nicht erklärter (Residual-) Varianz\nBeispiel Nullmodell: keine Erklärungskraft, d.h. Residualvarianz \\(var(\\epsilon) = var(Y)\\), also Gesamtvarianz von \\(Y\\)\n\\(R2 = 1 - var(\\epsilon)/var(Y)\\), d.h. Anteil erklärter Varianz, den alle Prädiktoren zusammen ermöglichen\nF-Test: ist der Anteil erklärter Varianz signifikant von 0 verschieden"
  },
  {
    "objectID": "analyseverfahren/slides.html#korrigiertes-r2",
    "href": "analyseverfahren/slides.html#korrigiertes-r2",
    "title": "Anwendungsorientierte Analyseverfahren",
    "section": "Korrigiertes \\(R^2\\)",
    "text": "Korrigiertes \\(R^2\\)\n\nein lineares Regressionsmodell wird durch Hinzunahme einer zusätzlichen Prädiktorvariable nie schlechter\nd.h. das naive \\(R^2\\) kann durch zusätzliche Prädiktoren nur ansteigen oder sich schlimmstenfalls nicht (sichtbar) ändern, aber nie sinken\nwürde man nun verschiedene Modelle miteinander vergleichen, würde das komplexere (= mehr Prädiktoren) Modell besser abschneiden, obwohl wir erkenntnistheoretisch eher an Modellsparsamkeit interessiert sind\ndaher betrachten wir bei multiplen Regressionen immer ein (durch die Anzahl Prädiktoren \\(k\\)) korrigiertes \\(\\bar R^2 = 1-(1-R^2){n-1 \\over n-k-1}\\)"
  },
  {
    "objectID": "analyseverfahren/slides.html#schrittweise-oder-hierarchische-regression",
    "href": "analyseverfahren/slides.html#schrittweise-oder-hierarchische-regression",
    "title": "Anwendungsorientierte Analyseverfahren",
    "section": "Schrittweise oder hierarchische Regression",
    "text": "Schrittweise oder hierarchische Regression\n\nmanchmal werden Regressionsmodelle schrittweise geschätzt, d.h. einzelne Prädiktoren (oder Prädiktorenblöcke) nacheinander in das Modell eingeführt\nDifferenz \\(\\Delta\\) im \\(R^2\\) und/oder ein sog. partieller F-Test durchgeführt, der prüft, ob die Hinzunahme der Prädiktoren das Modell signifikant verbessert hat\nin der Schätzung der Regression gibt es keine Reihenfolge-Effekte, d.h. das finale Modell ist immer dasselbe, egal, ob man mit \\(X_1\\) oder \\(X_2\\) startet\ngrundsätzlich nur die Regressionskoeffizienten aus dem finalen Modell interpretieren, das alle theoretisch postulierten Variablen enthält\nVorteil schrittweise Testung: Übersichtlichkeit der Darstellung, Nachteil: unnötig viele Zwischenschritte, voreilige Interpretationen"
  },
  {
    "objectID": "analyseverfahren/slides.html#beispiel-kümpel2019",
    "href": "analyseverfahren/slides.html#beispiel-kümpel2019",
    "title": "Anwendungsorientierte Analyseverfahren",
    "section": "Beispiel Kümpel (2019)",
    "text": "Beispiel Kümpel (2019)"
  },
  {
    "objectID": "analyseverfahren/slides.html#partieller-f-test",
    "href": "analyseverfahren/slides.html#partieller-f-test",
    "title": "Anwendungsorientierte Analyseverfahren",
    "section": "Partieller F-Test",
    "text": "Partieller F-Test\n\nglobaler F-Test als Modellvergleich: Residualvarianz mein Modell vs. Nullmodell\npartieller F-Test: Modell 1 vs. Modell 2 (wobei Modell 2 auch alle Prädiktoren von 1 enthalten muss)\nInterpretation, wenn der F-Test signifikant ist: Modell 2 kann sig. mehr Varianz in \\(Y\\) erklären als Modell 1\nModell 2 ist damit auch signifikant besser darin, \\(Y\\) vorauszusagen"
  },
  {
    "objectID": "analyseverfahren/slides.html#kitchen-sink-regression",
    "href": "analyseverfahren/slides.html#kitchen-sink-regression",
    "title": "Anwendungsorientierte Analyseverfahren",
    "section": "Kitchen-sink regression",
    "text": "Kitchen-sink regression\n\noft ist es verführerisch, einfach möglichst viele (plausible) Prädiktoren ins Modell aufzunehmen\nProblem 1: Gefahr von Multikollinearität steigt, weil viele Variablen untereinander korrelieren\nProblem 2: durch falsche Einbeziehung von sog. Collider-Variablen, die von \\(X\\) und \\(Y\\) beeinflusst werden, werden die Schätzungen verzerrt (vgl. Sitzung zu Annahmen)\nProblem 3: sehr umfangreiche Regressionstabellen, die gelesen werden müssen"
  },
  {
    "objectID": "analyseverfahren/slides.html#beispiel-vanerkel2021",
    "href": "analyseverfahren/slides.html#beispiel-vanerkel2021",
    "title": "Anwendungsorientierte Analyseverfahren",
    "section": "Beispiel: Van Erkel & Van Aelst (2021)",
    "text": "Beispiel: Van Erkel & Van Aelst (2021)\n\nDoes exposure to news affect what people know about politics? This old question attracted new scholarly interest as the political informa- tion environment is changing rapidly. In particular, since citizens have new channels at their disposal, such as Twitter and Facebook, which increasingly complement or even replace traditional channels of information. This study investigates to what extent citizens have knowledge about daily politics and to what extent news on social media can provide this knowledge. It does so by means of a large online survey in Belgium (Flanders), in which we measured what people know about current political events, their so-called general surveillance knowledge. Our findings demonstrate that unlike following news via traditional media channels, citizens do not gain more political knowledge from following news on social media. We even find a negative association between following the news on Facebook and political knowledge."
  },
  {
    "objectID": "analyseverfahren/slides.html#daten-2",
    "href": "analyseverfahren/slides.html#daten-2",
    "title": "Anwendungsorientierte Analyseverfahren",
    "section": "Daten",
    "text": "Daten\n\n\n\n\n\n\nAge\n\n\nGender\n\n\nEducation\n\n\nTV\n\n\nNewspaper\n\n\nWebsites\n\n\nFacebook\n\n\nPK\n\n\n\n\n\n\n21\n\n\nfemale\n\n\nHigh\n\n\n3\n\n\n3\n\n\n5\n\n\n6\n\n\n1\n\n\n\n\n21\n\n\nmale\n\n\nMiddle\n\n\n4\n\n\n5\n\n\n5\n\n\n5\n\n\n3\n\n\n\n\n67\n\n\nmale\n\n\nHigh\n\n\n5\n\n\n4\n\n\n5\n\n\n4\n\n\n3\n\n\n\n\n63\n\n\nfemale\n\n\nMiddle\n\n\n3\n\n\n1\n\n\n1\n\n\n1\n\n\n2\n\n\n\n\n61\n\n\nmale\n\n\nHigh\n\n\n5\n\n\n5\n\n\n5\n\n\n5\n\n\n5"
  },
  {
    "objectID": "analyseverfahren/slides.html#deskriptivstatistik",
    "href": "analyseverfahren/slides.html#deskriptivstatistik",
    "title": "Anwendungsorientierte Analyseverfahren",
    "section": "Deskriptivstatistik",
    "text": "Deskriptivstatistik\n\n\n\n\n\n\nVariable\n\n\nSummary\n\n\n\n\n\n\nMean Age (SD)\n\n\n52.98 (13.96)\n\n\n\n\nGender [female], %\n\n\n47.7\n\n\n\n\nEducation [Lower], %\n\n\n13.7\n\n\n\n\nEducation [Middle], %\n\n\n40.7\n\n\n\n\nEducation [High], %\n\n\n45.6\n\n\n\n\nMean TV (SD)\n\n\n4.43 (1.33)\n\n\n\n\nMean Newspaper (SD)\n\n\n3.52 (1.69)\n\n\n\n\nMean Websites (SD)\n\n\n3.44 (1.72)\n\n\n\n\nMean Facebook (SD)\n\n\n2.69 (1.95)\n\n\n\n\nMean PK (SD)\n\n\n3.04 (1.36)"
  },
  {
    "objectID": "analyseverfahren/slides.html#outcome-variable-3",
    "href": "analyseverfahren/slides.html#outcome-variable-3",
    "title": "Anwendungsorientierte Analyseverfahren",
    "section": "Outcome-Variable",
    "text": "Outcome-Variable"
  },
  {
    "objectID": "analyseverfahren/slides.html#regressionsmodell-i-nur-soziodemographie",
    "href": "analyseverfahren/slides.html#regressionsmodell-i-nur-soziodemographie",
    "title": "Anwendungsorientierte Analyseverfahren",
    "section": "Regressionsmodell I (nur Soziodemographie)",
    "text": "Regressionsmodell I (nur Soziodemographie)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nCoefficient\n95% CI\nt(988)\np\nStd. Coef.\nFit\n\n\n\n\n(Intercept)\n1.35\n(0.96, 1.74)\n6.81\n&lt; .001\n-0.20\n\n\n\nGender (female)\n-0.73\n(-0.89, -0.58)\n-9.23\n&lt; .001\n-0.54\n\n\n\nAge\n0.03\n(0.02, 0.03)\n9.46\n&lt; .001\n0.28\n\n\n\nEducation (Middle)\n0.51\n(0.27, 0.75)\n4.23\n&lt; .001\n0.38\n\n\n\nEducation (High)\n0.89\n(0.66, 1.13)\n7.43\n&lt; .001\n0.66\n\n\n\n\n\n\n\n\n\n\n\n\nAICc\n\n\n\n\n\n3217.50\n\n\nR2\n\n\n\n\n\n0.20\n\n\nR2 (adj.)\n\n\n\n\n\n0.20\n\n\nSigma\n\n\n\n\n\n1.22"
  },
  {
    "objectID": "analyseverfahren/slides.html#regressionsmodell-ii-mediennutzung",
    "href": "analyseverfahren/slides.html#regressionsmodell-ii-mediennutzung",
    "title": "Anwendungsorientierte Analyseverfahren",
    "section": "Regressionsmodell II (Mediennutzung)",
    "text": "Regressionsmodell II (Mediennutzung)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nCoefficient\n95% CI\nt(983)\np\nStd. Coef.\nFit\n\n\n\n\n(Intercept)\n0.74\n(0.28, 1.20)\n3.18\n0.002\n-0.12\n\n\n\nGender (female)\n-0.63\n(-0.78, -0.48)\n-8.21\n&lt; .001\n-0.46\n\n\n\nAge\n0.02\n(0.01, 0.02)\n6.23\n&lt; .001\n0.19\n\n\n\nEducation (Middle)\n0.39\n(0.16, 0.61)\n3.33\n&lt; .001\n0.28\n\n\n\nEducation (High)\n0.67\n(0.44, 0.90)\n5.69\n&lt; .001\n0.49\n\n\n\nTV\n0.14\n(0.08, 0.20)\n4.46\n&lt; .001\n0.14\n\n\n\nNewspaper\n0.12\n(0.07, 0.17)\n4.91\n&lt; .001\n0.15\n\n\n\nWebsites\n0.12\n(0.07, 0.16)\n4.77\n&lt; .001\n0.15\n\n\n\nFacebook\n-0.07\n(-0.11, -0.03)\n-3.29\n0.001\n-0.10\n\n\n\nTwitter\n-0.07\n(-0.15, 0.01)\n-1.81\n0.070\n-0.05\n\n\n\n\n\n\n\n\n\n\n\n\nAICc\n\n\n\n\n\n3114.32\n\n\nR2\n\n\n\n\n\n0.29\n\n\nR2 (adj.)\n\n\n\n\n\n0.28\n\n\nSigma\n\n\n\n\n\n1.15"
  },
  {
    "objectID": "analyseverfahren/slides.html#partieller-f-test-modellverbesserung",
    "href": "analyseverfahren/slides.html#partieller-f-test-modellverbesserung",
    "title": "Anwendungsorientierte Analyseverfahren",
    "section": "Partieller F-Test (Modellverbesserung)",
    "text": "Partieller F-Test (Modellverbesserung)\n\n\n\n\n\n\nModell\n\n\nRes.Df\n\n\nRSS\n\n\nDf\n\n\nSum of Sq\n\n\nF\n\n\nPr(&gt;F)\n\n\n\n\n\n\n1\n\n\n988\n\n\n1466.83\n\n\nNA\n\n\nNA\n\n\nNA\n\n\nNA\n\n\n\n\n2\n\n\n983\n\n\n1308.59\n\n\n5\n\n\n158.24\n\n\n23.77\n\n\n0"
  },
  {
    "objectID": "analyseverfahren/slides.html#bonus-visualisierung-der-ergebnisse",
    "href": "analyseverfahren/slides.html#bonus-visualisierung-der-ergebnisse",
    "title": "Anwendungsorientierte Analyseverfahren",
    "section": "Bonus: Visualisierung der Ergebnisse",
    "text": "Bonus: Visualisierung der Ergebnisse"
  },
  {
    "objectID": "analyseverfahren/slides.html#annahmen-des-glm",
    "href": "analyseverfahren/slides.html#annahmen-des-glm",
    "title": "Anwendungsorientierte Analyseverfahren",
    "section": "Annahmen des GLM",
    "text": "Annahmen des GLM\nStatistische Annahmen\n\nLinearität und Additivität der Zusammenhänge\nNormalverteilung und Homoskedastizität der Residuen\nUnabhängigkeit der Residuen\nkeine einflussreichen Ausreißer\nkeine Multikollinearität\n\nKausalannahmen\n\nkorrekt spezifiziertes Modell, d.h. keine fehlenden oder überflüssigen Kovariaten"
  },
  {
    "objectID": "analyseverfahren/slides.html#linearität-additivität",
    "href": "analyseverfahren/slides.html#linearität-additivität",
    "title": "Anwendungsorientierte Analyseverfahren",
    "section": "Linearität & Additivität",
    "text": "Linearität & Additivität\n\nAnnahme: der Zusammenhang zwischen \\(X\\) und \\(Y\\) ist linear und unabhängig von \\(Z\\)\nDiagnose: Inspektion des Scatterplots bzw. des Fitted/Residual-Plots\nVerletzung: nichtlineare Zusammenhänge (quadratisch, exponentiell, etc.)\nKonsequenz der Verletzung: verzerrte Regressionskoeffizienten\nLösung: Transformation von \\(X\\) oder \\(Y\\), nichtlineares Regressionsmodell, Moderationsanalyse mit \\(Z\\)"
  },
  {
    "objectID": "analyseverfahren/slides.html#homoskedastizizät-der-residuen",
    "href": "analyseverfahren/slides.html#homoskedastizizät-der-residuen",
    "title": "Anwendungsorientierte Analyseverfahren",
    "section": "Homoskedastizizät der Residuen",
    "text": "Homoskedastizizät der Residuen\n\nAnnahme: Residualvarianz ist für alle Werte von \\(X\\) gleich\nDiagnose: Fitted/Residual-Plots\nVerletzung: Residuen streuen in Abhängigkeit von \\(X\\)\nKonsequenz der Verletzung: falsche Standardfehler, ineffiziente Schätzung\nLösung: alternative Standardfehler, Datentransformationen, alternatives Modell"
  },
  {
    "objectID": "analyseverfahren/slides.html#unabhängigkeit-der-residuen",
    "href": "analyseverfahren/slides.html#unabhängigkeit-der-residuen",
    "title": "Anwendungsorientierte Analyseverfahren",
    "section": "Unabhängigkeit der Residuen",
    "text": "Unabhängigkeit der Residuen\n\nAnnahme: Residuen korrelieren weder miteinander noch mit den Prädiktoren\nDiagnose: Nachdenken über datengenerierenden Prozess, Test auf serielle Korrelation\nVerletzung: Residuen (und oft Variablen) sind geclustert (zeitlich, Stichprobe)\nKonsequenz der Verletzung: falsche Standardfehler, ineffiziente Schätzung\nLösung: Multilevel-Modell, Modell mit Autokorrelationen"
  },
  {
    "objectID": "analyseverfahren/slides.html#keine-einflussreichen-ausreißer",
    "href": "analyseverfahren/slides.html#keine-einflussreichen-ausreißer",
    "title": "Anwendungsorientierte Analyseverfahren",
    "section": "keine einflussreichen Ausreißer",
    "text": "keine einflussreichen Ausreißer\n\nAnnahme: alle Fälle tragen gleich zur Schätzung bei\nDiagnose: Scatterplot, Leverage-Plot\nVerletzung: einzelne Fälle beeinflussen die Höhe der Regressionsgeraden\nKonsequenz der Verletzung: verzerrte Regressionskoeffizienten\nLösung: Ausschluss von Ausreißern (mit klar definierten Regeln!)"
  },
  {
    "objectID": "analyseverfahren/slides.html#keine-multikollinearität",
    "href": "analyseverfahren/slides.html#keine-multikollinearität",
    "title": "Anwendungsorientierte Analyseverfahren",
    "section": "keine Multikollinearität",
    "text": "keine Multikollinearität\n\nAnnahme: Prädiktorvariablen \\(X\\) korrelieren nicht zu stark miteinander\nDiagnose: Korrelationsmatrix der Prädiktoren, VIF-Analyse (Variance Inflation Factor)\nVerletzung: Prädiktorvariablen korrelieren stark miteinander\nKonsequenz der Verletzung: falsche Standardfehler, ineffiziente Schätzung\nLösung: Ausschluss von Prädiktorvariablen"
  },
  {
    "objectID": "analyseverfahren/slides.html#beispiel-van-erkel-van-aelst-2021",
    "href": "analyseverfahren/slides.html#beispiel-van-erkel-van-aelst-2021",
    "title": "Anwendungsorientierte Analyseverfahren",
    "section": "Beispiel: van Erkel & van Aelst, 2021",
    "text": "Beispiel: van Erkel & van Aelst, 2021"
  },
  {
    "objectID": "analyseverfahren/slides.html#linearität-und-homoskedastizität",
    "href": "analyseverfahren/slides.html#linearität-und-homoskedastizität",
    "title": "Anwendungsorientierte Analyseverfahren",
    "section": "Linearität und Homoskedastizität",
    "text": "Linearität und Homoskedastizität"
  },
  {
    "objectID": "analyseverfahren/slides.html#multikollinearität",
    "href": "analyseverfahren/slides.html#multikollinearität",
    "title": "Anwendungsorientierte Analyseverfahren",
    "section": "Multikollinearität",
    "text": "Multikollinearität\n\n\n\n\n\n\n\n\nParameter\n\n\nPolitical_interest\n\n\nAge\n\n\n\n\n\n\nPK\n\n\n0.49\n\n\n0.3\n\n\n\n\nAge\n\n\n0.14\n\n\nNA\n\n\n\n\n\n\n\n\n\n\n\n$VIF"
  },
  {
    "objectID": "analyseverfahren/slides.html#kausalannahmen-confounders-colliders",
    "href": "analyseverfahren/slides.html#kausalannahmen-confounders-colliders",
    "title": "Anwendungsorientierte Analyseverfahren",
    "section": "Kausalannahmen, Confounders, Colliders",
    "text": "Kausalannahmen, Confounders, Colliders\n\nQuelle: https://catalogofbias.org"
  },
  {
    "objectID": "analyseverfahren/slides.html#confounder--oder-ommitted-variable-bias",
    "href": "analyseverfahren/slides.html#confounder--oder-ommitted-variable-bias",
    "title": "Anwendungsorientierte Analyseverfahren",
    "section": "Confounder- oder Ommitted-Variable-Bias",
    "text": "Confounder- oder Ommitted-Variable-Bias\n\nNicht-Berücksichtigung einer relevanten Kovariate, die \\(X\\) und \\(Y\\) beeinflusst, verzerrt den geschätzen Zusammenhang zwischen \\(X\\) und \\(Y\\)."
  },
  {
    "objectID": "analyseverfahren/slides.html#collider-bias",
    "href": "analyseverfahren/slides.html#collider-bias",
    "title": "Anwendungsorientierte Analyseverfahren",
    "section": "Collider-Bias",
    "text": "Collider-Bias\n\nBerücksichtigung einer Kovariate, die von \\(X\\) und \\(Y\\) beeinflusst wird, verzerrt den geschätzen Zusammenhang zwischen \\(X\\) und \\(Y\\)."
  },
  {
    "objectID": "analyseverfahren/slides.html#kausale-pfadmodelle",
    "href": "analyseverfahren/slides.html#kausale-pfadmodelle",
    "title": "Anwendungsorientierte Analyseverfahren",
    "section": "(Kausale) Pfadmodelle",
    "text": "(Kausale) Pfadmodelle\n\nQuelle: https://www.andrewheiss.com/blog/2020/02/25/closing-backdoors-dags/"
  },
  {
    "objectID": "analyseverfahren/slides.html#verletzung-der-modellannahmen---und-nun",
    "href": "analyseverfahren/slides.html#verletzung-der-modellannahmen---und-nun",
    "title": "Anwendungsorientierte Analyseverfahren",
    "section": "Verletzung der Modellannahmen - und nun?",
    "text": "Verletzung der Modellannahmen - und nun?\n\nKeine Panik! Modellannahmen sind praktisch immer verletzt (z.B. Normalverteilung der Residuen)\nviele Annahmen beziehen sich auf die Residuen, nicht auf \\(X\\) oder \\(Y\\)\nwichtig ist, einschätzen zu können, welche Konsequenzen eine Verletzung der Modellannahme haben kann\n\nverzerrte Schätzer (zu hoch, zu niedrig)\nfalsche Standardfehler (Alpha- und Beta-Fehler)\nfalsche Kausalschlüsse (Rohrer, 2018; Coenen, 2022)\n\nvorsichtig formulieren, Robustheit der Ergebnisse prüfen"
  },
  {
    "objectID": "analyseverfahren/slides.html#modellvorhersagen-1",
    "href": "analyseverfahren/slides.html#modellvorhersagen-1",
    "title": "Anwendungsorientierte Analyseverfahren",
    "section": "Modellvorhersagen",
    "text": "Modellvorhersagen\n\nModellvorhersagen helfen, komplexe Modelle besser verstehen zu können\ndurch Einsetzen von Werten für die Prädiktoren in die Regressionsgleichung können wir Werte für \\(Y\\) vorhersagen, d.h. \\(\\hat{Y}\\)\nes können real existierende oder fiktive Daten eingesetzt werden\nauf Grund der statistischen Unsicherheit in den Regressionskoeffizienten sind auch die Vorhersagen mit Unsicherheit behaftet\ndaher erhalten wir Punktschätzer und Konfidenz bzw. Vorhersageintervalle für \\(\\hat{Y}\\)"
  },
  {
    "objectID": "analyseverfahren/slides.html#welche-daten-vorhersagen",
    "href": "analyseverfahren/slides.html#welche-daten-vorhersagen",
    "title": "Anwendungsorientierte Analyseverfahren",
    "section": "Welche Daten vorhersagen?",
    "text": "Welche Daten vorhersagen?\n\nempirische Daten, d.h. alle oder ausgewählte Fälle des Datensatzes, auf dem das Modell basiert\nidealtypische Daten, d.h. Beispieldaten, die auf (Kombinationen von) für uns relevanten Variablen basieren\ncounterfactual Daten, d.h. nicht beobachtete Daten, die das Gegenteil der beobachteten in einer oder mehreren Variablen sind\n\n \n\nbei kategoriellen Prädiktoren werden die einzelnen Ausprägungen verwendet\nbei metrischen Prädiktoren werden typische Fälle (Min, Max, Median, Quartile) oder gezielte Einzelwerte eingesetzt"
  },
  {
    "objectID": "analyseverfahren/slides.html#aggregation",
    "href": "analyseverfahren/slides.html#aggregation",
    "title": "Anwendungsorientierte Analyseverfahren",
    "section": "Aggregation",
    "text": "Aggregation\n\noft sind neben einzelnen Vorhersagen auch aggregierte Vorhersagen für spezifische Gruppen von Interesse\nentweder (a) empirisch vorkommende Gruppen im Datensatz oder (b) kontrafaktische Gruppen\nAnalysestrategie:\n\nfür jede Gruppe je einen Datensatz auswählen (a) oder (b) generieren\nVorhersagen für alle Fälle pro Datensatz berechnen\nVorhersagen aggregieren, z.B. durch Berechnen des Mittelwertes für \\(\\hat{Y}\\)"
  },
  {
    "objectID": "analyseverfahren/slides.html#intervalle",
    "href": "analyseverfahren/slides.html#intervalle",
    "title": "Anwendungsorientierte Analyseverfahren",
    "section": "Intervalle",
    "text": "Intervalle\n\nbei Modellvorhersagen unterscheidet man zwischen confidence und prediction intervals für \\(\\hat{Y}\\)\nin die Berechnung der Konfidenzintervalle fließt nur die Unsicherheit in den Regressionskoeffizienten ein\nin die Berechnung der Vorhersageintervalle fließt zusätzlich noch die Residualvarianz ein\nVorhersageintervalle sind daher immer breiter (je nach \\(R^2\\)) als die Konfidenzintervalle der Vorhersagen\nVorhersageintervalle werden meist nur für einzelne vorhergesagte Werte angegeben, ansonsten verwenden wir nur CI"
  },
  {
    "objectID": "analyseverfahren/slides.html#beispiel-van-erkel-van-aelst-2021-1",
    "href": "analyseverfahren/slides.html#beispiel-van-erkel-van-aelst-2021-1",
    "title": "Anwendungsorientierte Analyseverfahren",
    "section": "Beispiel: van Erkel & van Aelst, 2021",
    "text": "Beispiel: van Erkel & van Aelst, 2021\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nCoefficient\n95% CI\nt(987)\np\nStd. Coef.\nFit\n\n\n\n\n(Intercept)\n0.46\n(0.09, 0.83)\n2.45\n0.014\n-0.13\n\n\n\nGender (female)\n-0.51\n(-0.65, -0.37)\n-6.96\n&lt; .001\n-0.37\n\n\n\nAge\n0.02\n(0.02, 0.03)\n8.48\n&lt; .001\n0.23\n\n\n\nEducation (Middle)\n0.35\n(0.13, 0.56)\n3.15\n0.002\n0.26\n\n\n\nEducation (High)\n0.60\n(0.38, 0.82)\n5.42\n&lt; .001\n0.44\n\n\n\nPolitical interest\n0.20\n(0.18, 0.23)\n14.76\n&lt; .001\n0.40\n\n\n\n\n\n\n\n\n\n\n\n\nAICc\n\n\n\n\n\n3021.49\n\n\nR2\n\n\n\n\n\n0.35\n\n\nR2 (adj.)\n\n\n\n\n\n0.34\n\n\nSigma\n\n\n\n\n\n1.10"
  },
  {
    "objectID": "analyseverfahren/slides.html#modellvorhersagen-für-die-stichprobe",
    "href": "analyseverfahren/slides.html#modellvorhersagen-für-die-stichprobe",
    "title": "Anwendungsorientierte Analyseverfahren",
    "section": "Modellvorhersagen für die Stichprobe",
    "text": "Modellvorhersagen für die Stichprobe\n\n\n\n\n\n\nGender\n\n\nAge\n\n\nEducation\n\n\nPolitical_interest\n\n\nPK\n\n\nPredicted_PK\n\n\n\n\n\n\nmale\n\n\n66\n\n\nMiddle\n\n\n8\n\n\n5\n\n\n3.90\n\n\n\n\nfemale\n\n\n68\n\n\nLower\n\n\n6\n\n\n3\n\n\n2.68\n\n\n\n\nmale\n\n\n34\n\n\nMiddle\n\n\n10\n\n\n3\n\n\n3.61\n\n\n\n\nfemale\n\n\n57\n\n\nHigh\n\n\n8\n\n\n3\n\n\n3.45\n\n\n\n\nfemale\n\n\n24\n\n\nHigh\n\n\n5\n\n\n4\n\n\n2.11"
  },
  {
    "objectID": "analyseverfahren/slides.html#vorhergesagte-verteilung",
    "href": "analyseverfahren/slides.html#vorhergesagte-verteilung",
    "title": "Anwendungsorientierte Analyseverfahren",
    "section": "Vorhergesagte Verteilung",
    "text": "Vorhergesagte Verteilung"
  },
  {
    "objectID": "analyseverfahren/slides.html#confidence-vs.-prediction-intervals",
    "href": "analyseverfahren/slides.html#confidence-vs.-prediction-intervals",
    "title": "Anwendungsorientierte Analyseverfahren",
    "section": "Confidence vs. prediction intervals",
    "text": "Confidence vs. prediction intervals\nConfidence intervals\n\n\n\n\n\n\nGender\n\n\nAge\n\n\nEducation\n\n\nPolitical_interest\n\n\nPK\n\n\nfit\n\n\nlwr\n\n\nupr\n\n\n\n\n\n\nfemale\n\n\n45\n\n\nMiddle\n\n\n3\n\n\n2\n\n\n1.91\n\n\n1.76\n\n\n2.05\n\n\n\n\nfemale\n\n\n59\n\n\nHigh\n\n\n7\n\n\n4\n\n\n3.29\n\n\n3.15\n\n\n3.42\n\n\n\n\nfemale\n\n\n52\n\n\nHigh\n\n\n7\n\n\n4\n\n\n3.13\n\n\n3.01\n\n\n3.26\n\n\n\n\n\n\n \nPrediction intervals\n\n\n\n\n\n\nGender\n\n\nAge\n\n\nEducation\n\n\nPolitical_interest\n\n\nPK\n\n\nfit\n\n\nlwr\n\n\nupr\n\n\n\n\n\n\nfemale\n\n\n45\n\n\nMiddle\n\n\n3\n\n\n2\n\n\n1.91\n\n\n-0.26\n\n\n4.08\n\n\n\n\nfemale\n\n\n59\n\n\nHigh\n\n\n7\n\n\n4\n\n\n3.29\n\n\n1.12\n\n\n5.46\n\n\n\n\nfemale\n\n\n52\n\n\nHigh\n\n\n7\n\n\n4\n\n\n3.13\n\n\n0.96\n\n\n5.30"
  },
  {
    "objectID": "analyseverfahren/slides.html#kategorielle-prädiktoren-geschlecht",
    "href": "analyseverfahren/slides.html#kategorielle-prädiktoren-geschlecht",
    "title": "Anwendungsorientierte Analyseverfahren",
    "section": "Kategorielle Prädiktoren: Geschlecht",
    "text": "Kategorielle Prädiktoren: Geschlecht\n\nfür jeden Fall im Datensatz wird jeweils jede Ausprägung von Geschlecht einmal eingesetzt (counterfactuals)\nalle anderen Prädiktoren bleiben, wie sie waren\n\n \n\n\n\n\n\n\nid\n\n\nAge\n\n\nGender\n\n\nPolitical_interest\n\n\nPK\n\n\nPredicted_PK\n\n\n\n\n\n\n1\n\n\n45\n\n\nfemale\n\n\n3\n\n\n2\n\n\n1.91\n\n\n\n\n1\n\n\n45\n\n\nmale\n\n\n3\n\n\n2\n\n\n2.42\n\n\n\n\n2\n\n\n59\n\n\nfemale\n\n\n7\n\n\n4\n\n\n3.29\n\n\n\n\n2\n\n\n59\n\n\nmale\n\n\n7\n\n\n4\n\n\n3.80\n\n\n\n\n3\n\n\n52\n\n\nfemale\n\n\n7\n\n\n4\n\n\n3.13\n\n\n\n\n3\n\n\n52\n\n\nmale\n\n\n7\n\n\n4\n\n\n3.64"
  },
  {
    "objectID": "analyseverfahren/slides.html#aggregierte-vorhersagen-nach-geschlecht",
    "href": "analyseverfahren/slides.html#aggregierte-vorhersagen-nach-geschlecht",
    "title": "Anwendungsorientierte Analyseverfahren",
    "section": "Aggregierte Vorhersagen nach Geschlecht",
    "text": "Aggregierte Vorhersagen nach Geschlecht\n\nder neu generierte Datensatz mit den counterfactuals wird nach Geschlecht geteilt\npro Teildatensatz wird der Mittelwert sowie das CI von \\(\\hat{Y}\\) berechnet\nErgebnis sind die vorhergesagten Mittelwerte des politischen Wissens nach Geschlecht\n\n\n\n\n\n\n\n\n\nGender\n\n\nestimate\n\n\nstd.error\n\n\nconf.low\n\n\nconf.high\n\n\ndf\n\n\n\n\n\n\nmale\n\n\n3.29\n\n\n0.05\n\n\n3.19\n\n\n3.38\n\n\nInf\n\n\n\n\nfemale\n\n\n2.78\n\n\n0.05\n\n\n2.68\n\n\n2.88\n\n\nInf"
  },
  {
    "objectID": "analyseverfahren/slides.html#visualisierung-der-vorhersagen",
    "href": "analyseverfahren/slides.html#visualisierung-der-vorhersagen",
    "title": "Anwendungsorientierte Analyseverfahren",
    "section": "Visualisierung der Vorhersagen",
    "text": "Visualisierung der Vorhersagen"
  },
  {
    "objectID": "analyseverfahren/slides.html#vorhersagen-nach-geschlecht-und-bildung",
    "href": "analyseverfahren/slides.html#vorhersagen-nach-geschlecht-und-bildung",
    "title": "Anwendungsorientierte Analyseverfahren",
    "section": "Vorhersagen nach Geschlecht und Bildung",
    "text": "Vorhersagen nach Geschlecht und Bildung"
  },
  {
    "objectID": "analyseverfahren/slides.html#metrische-prädiktoren-alter",
    "href": "analyseverfahren/slides.html#metrische-prädiktoren-alter",
    "title": "Anwendungsorientierte Analyseverfahren",
    "section": "Metrische Prädiktoren: Alter",
    "text": "Metrische Prädiktoren: Alter\n\nwir wählen spezifische Werte (z.B. 18, 40, 65) der Altersvariable\nfür jeden Fall wird jeder Alterswert einmal eingesetzt (counterfactuals)\nalle anderen Prädiktoren bleiben, wie sie waren\n\n \n\n\n\n\n\n\nid\n\n\nAge\n\n\nGender\n\n\nPolitical_interest\n\n\nPK\n\n\nPredicted_PK\n\n\n\n\n\n\n1\n\n\n18\n\n\nfemale\n\n\n3\n\n\n2\n\n\n1.31\n\n\n\n\n1\n\n\n40\n\n\nfemale\n\n\n3\n\n\n2\n\n\n1.80\n\n\n\n\n1\n\n\n65\n\n\nfemale\n\n\n3\n\n\n2\n\n\n2.35\n\n\n\n\n2\n\n\n18\n\n\nfemale\n\n\n7\n\n\n4\n\n\n2.38\n\n\n\n\n2\n\n\n40\n\n\nfemale\n\n\n7\n\n\n4\n\n\n2.87\n\n\n\n\n2\n\n\n65\n\n\nfemale\n\n\n7\n\n\n4\n\n\n3.42"
  },
  {
    "objectID": "analyseverfahren/slides.html#fallweise-vorhersagen-typische-werte",
    "href": "analyseverfahren/slides.html#fallweise-vorhersagen-typische-werte",
    "title": "Anwendungsorientierte Analyseverfahren",
    "section": "Fallweise Vorhersagen (typische Werte)",
    "text": "Fallweise Vorhersagen (typische Werte)\n\nstatt spezifisch ausgewählten Werten verwenden wir Kennwerte\nFive Numbers: Minimum, 1. Quartil, Median, 3. Quartil, Maximum\n\n\n\n\n\n\n\n\n\nid\n\n\nAge\n\n\nGender\n\n\nPolitical_interest\n\n\nPK\n\n\nPredicted_PK\n\n\n\n\n\n\n1\n\n\n19\n\n\nfemale\n\n\n3\n\n\n2\n\n\n1.33\n\n\n\n\n1\n\n\n44\n\n\nfemale\n\n\n3\n\n\n2\n\n\n1.89\n\n\n\n\n1\n\n\n56\n\n\nfemale\n\n\n3\n\n\n2\n\n\n2.15\n\n\n\n\n1\n\n\n65\n\n\nfemale\n\n\n3\n\n\n2\n\n\n2.35\n\n\n\n\n1\n\n\n71\n\n\nfemale\n\n\n3\n\n\n2\n\n\n2.48\n\n\n\n\n2\n\n\n19\n\n\nfemale\n\n\n7\n\n\n4\n\n\n2.40\n\n\n\n\n2\n\n\n44\n\n\nfemale\n\n\n7\n\n\n4\n\n\n2.96\n\n\n\n\n2\n\n\n56\n\n\nfemale\n\n\n7\n\n\n4\n\n\n3.22"
  },
  {
    "objectID": "analyseverfahren/slides.html#aggregierte-vorhersagen-nach-alter",
    "href": "analyseverfahren/slides.html#aggregierte-vorhersagen-nach-alter",
    "title": "Anwendungsorientierte Analyseverfahren",
    "section": "Aggregierte Vorhersagen nach Alter",
    "text": "Aggregierte Vorhersagen nach Alter\n\n\n\n\n\n\nAge\n\n\nestimate\n\n\nstd.error\n\n\nconf.low\n\n\nconf.high\n\n\ndf\n\n\n\n\n\n\n19\n\n\n2.29\n\n\n0.10\n\n\n2.11\n\n\n2.48\n\n\nInf\n\n\n\n\n44\n\n\n2.85\n\n\n0.04\n\n\n2.76\n\n\n2.93\n\n\nInf\n\n\n\n\n56\n\n\n3.11\n\n\n0.04\n\n\n3.04\n\n\n3.18\n\n\nInf\n\n\n\n\n65\n\n\n3.31\n\n\n0.05\n\n\n3.22\n\n\n3.40\n\n\nInf\n\n\n\n\n71\n\n\n3.44\n\n\n0.06\n\n\n3.33\n\n\n3.56\n\n\nInf\n\n\n\n\n\n\n\n\nVorhersagen für Minimum, 1. Quartil, Median, 3. Quartil, Maximum"
  },
  {
    "objectID": "analyseverfahren/slides.html#visualisierung-der-vorhersagen-1",
    "href": "analyseverfahren/slides.html#visualisierung-der-vorhersagen-1",
    "title": "Anwendungsorientierte Analyseverfahren",
    "section": "Visualisierung der Vorhersagen",
    "text": "Visualisierung der Vorhersagen"
  },
  {
    "objectID": "analyseverfahren/slides.html#vorhersagen-nach-alter-und-geschlecht",
    "href": "analyseverfahren/slides.html#vorhersagen-nach-alter-und-geschlecht",
    "title": "Anwendungsorientierte Analyseverfahren",
    "section": "Vorhersagen nach Alter und Geschlecht",
    "text": "Vorhersagen nach Alter und Geschlecht\n\n\n\n\n\n\nAge\n\n\nGender\n\n\nestimate\n\n\nstd.error\n\n\nconf.low\n\n\nconf.high\n\n\ndf\n\n\n\n\n\n\n19\n\n\nmale\n\n\n2.54\n\n\n0.11\n\n\n2.33\n\n\n2.75\n\n\nInf\n\n\n\n\n19\n\n\nfemale\n\n\n2.03\n\n\n0.10\n\n\n1.84\n\n\n2.22\n\n\nInf\n\n\n\n\n44\n\n\nmale\n\n\n3.09\n\n\n0.06\n\n\n2.98\n\n\n3.20\n\n\nInf\n\n\n\n\n44\n\n\nfemale\n\n\n2.58\n\n\n0.05\n\n\n2.47\n\n\n2.69\n\n\nInf\n\n\n\n\n56\n\n\nmale\n\n\n3.35\n\n\n0.05\n\n\n3.26\n\n\n3.45\n\n\nInf\n\n\n\n\n56\n\n\nfemale\n\n\n2.84\n\n\n0.05\n\n\n2.74\n\n\n2.95\n\n\nInf\n\n\n\n\n65\n\n\nmale\n\n\n3.55\n\n\n0.06\n\n\n3.44\n\n\n3.66\n\n\nInf\n\n\n\n\n65\n\n\nfemale\n\n\n3.04\n\n\n0.06\n\n\n2.92\n\n\n3.17\n\n\nInf\n\n\n\n\n71\n\n\nmale\n\n\n3.69\n\n\n0.06\n\n\n3.56\n\n\n3.81\n\n\nInf\n\n\n\n\n71\n\n\nfemale\n\n\n3.18\n\n\n0.07\n\n\n3.03\n\n\n3.32\n\n\nInf"
  },
  {
    "objectID": "analyseverfahren/slides.html#visualisierung-der-vorhersagen-2",
    "href": "analyseverfahren/slides.html#visualisierung-der-vorhersagen-2",
    "title": "Anwendungsorientierte Analyseverfahren",
    "section": "Visualisierung der Vorhersagen",
    "text": "Visualisierung der Vorhersagen"
  },
  {
    "objectID": "analyseverfahren/slides.html#fazit",
    "href": "analyseverfahren/slides.html#fazit",
    "title": "Anwendungsorientierte Analyseverfahren",
    "section": "Fazit",
    "text": "Fazit\n\nmit Modellvorhersagen lassen sich vielfältige Fragen auf Basis desselben Modells beantworten\nfür komplexe, nichtlineare Modelle intuitive(re) Grafiken statt schwer interpretierbarer Koeffizienten\nWahl der passenden Prädiktorkombinationen nicht trivial (counterfactual, empirisch, typisch)\nsubtile Unterschiede in der Interpretation und uneinheitliche Begrifflichkeiten (marginal, conditional, adjusted predictions)\nin der Kommunikationswissenschaft (leider) selten anzutreffen, außer in der Moderationsanalyse"
  },
  {
    "objectID": "analyseverfahren/slides.html#take-home-2",
    "href": "analyseverfahren/slides.html#take-home-2",
    "title": "Anwendungsorientierte Analyseverfahren",
    "section": "Take Home #2",
    "text": "Take Home #2\nReplizieren sie eine Regressionsanalyse aus van Erkel & van Aelst (2021) mit R oder SPSS oder anderer Software\n\nStudierende mit gerader Matrikelnummer: Tabelle 5\nStudierende mit ungerader Matrikelnummer: Tabelle 6\nDer Datensatz ist in data/VanErkel_vanAelst2021.sav und enthält alle nötigen Variablen.\nMachen sie einen Screenshot der Regressionstabelle als PNG oder JPG und laden Sie diesen in Moodle hoch.\nDeadline: 25.06.2025, 10h"
  },
  {
    "objectID": "analyseverfahren/slides.html#wiederholung-information-overload-vanerkel2021",
    "href": "analyseverfahren/slides.html#wiederholung-information-overload-vanerkel2021",
    "title": "Anwendungsorientierte Analyseverfahren",
    "section": "Wiederholung: Information Overload (Van Erkel & Van Aelst, 2021)",
    "text": "Wiederholung: Information Overload (Van Erkel & Van Aelst, 2021)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nCoefficient\n95% CI\nt(983)\np\nStd. Coef.\nFit\n\n\n\n\n(Intercept)\n6.93\n(5.89, 7.97)\n13.09\n&lt; .001\n0.03\n\n\n\nGender (female)\n0.72\n(0.32, 1.12)\n3.51\n&lt; .001\n0.23\n\n\n\nAge\n0.02\n(0.00, 0.03)\n2.06\n0.039\n0.07\n\n\n\nEducation (Middle)\n-0.40\n(-1.01, 0.21)\n-1.29\n0.198\n-0.13\n\n\n\nEducation (High)\n-0.62\n(-1.23, -0.01)\n-1.98\n0.048\n-0.20\n\n\n\nOutlets Used\n0.10\n(0.06, 0.13)\n4.97\n&lt; .001\n0.16\n\n\n\n\n\n\n\n\n\n\n\n\nAICc\n\n\n\n\n\n5062.21\n\n\nR2\n\n\n\n\n\n0.04\n\n\nR2 (adj.)\n\n\n\n\n\n0.03\n\n\nSigma\n\n\n\n\n\n3.11"
  },
  {
    "objectID": "analyseverfahren/slides.html#moderationsanalyse",
    "href": "analyseverfahren/slides.html#moderationsanalyse",
    "title": "Anwendungsorientierte Analyseverfahren",
    "section": "Moderationsanalyse",
    "text": "Moderationsanalyse\n\nDiagnose: Effektheterogenität, d.h. der Zusammenhang von X und Y ist nicht für alle gleich\nder Effekt von X auf Y hängt von Moderatorvariable Z ab (“wird von Z moderiert”)\ndie Größe und die Richtung des Regressionskoeffizienten ist davon abhängig, welche Ausprägung Z hat\nBeispiele:\n\nExperimente mit min. 2 Faktoren, die sich gegenseitig beeiflussen\nEffektheterogenität in verschiedenen Subgruppen der Stichprobe\n\nEffektheterogenität aktuell en vogue (person-specific media effects, Valkenburg et al., 2021), aber theoretisch und empirisch ggf. problematisch (Healy, 2017; Vuorre et al., 2022)"
  },
  {
    "objectID": "analyseverfahren/slides.html#woran-erkennen-wir-effektheterogenität",
    "href": "analyseverfahren/slides.html#woran-erkennen-wir-effektheterogenität",
    "title": "Anwendungsorientierte Analyseverfahren",
    "section": "Woran erkennen wir Effektheterogenität?",
    "text": "Woran erkennen wir Effektheterogenität?"
  },
  {
    "objectID": "analyseverfahren/slides.html#analysemöglichkeiten",
    "href": "analyseverfahren/slides.html#analysemöglichkeiten",
    "title": "Anwendungsorientierte Analyseverfahren",
    "section": "Analysemöglichkeiten",
    "text": "Analysemöglichkeiten\n(a) separate Regressionsmodelle pro Subgruppe schätzen\n\nkein direkter Test der Moderationshypothese\nweniger statistische Power wg. kleinerer Subsamples\nalle Regressionskoeffizienten werden unterschiedlich geschätzt\nbei metrischen Moderatoren Dichotomisierung o.ä. nötig\n\n(b) Moderationsanalyse mit Interaktionstermen\n\ngezielt für spezifische Prädiktoren möglich\nstatistische Power bleibt erhalten\nmetrische Moderatoren problemlos integrierbar"
  },
  {
    "objectID": "analyseverfahren/slides.html#beispiel-getrennte-analysen",
    "href": "analyseverfahren/slides.html#beispiel-getrennte-analysen",
    "title": "Anwendungsorientierte Analyseverfahren",
    "section": "Beispiel getrennte Analysen",
    "text": "Beispiel getrennte Analysen\n\n\n\n\n\n \nOverload (female)\nOverload (male)\n\n\nPredictors\nEstimates\nCI\np\nEstimates\nCI\np\n\n\n(Intercept)\n7.79\n6.47 – 9.11\n&lt;0.001\n7.97\n6.53 – 9.40\n&lt;0.001\n\n\nAge\n0.02\n-0.00 – 0.04\n0.090\n0.01\n-0.01 – 0.04\n0.186\n\n\nEducation: Middle\n0.08\n-0.83 – 1.00\n0.858\n-0.59\n-1.43 – 0.25\n0.171\n\n\nEducation: High\n0.12\n-0.79 – 1.02\n0.799\n-0.72\n-1.56 – 0.11\n0.089\n\n\nObservations\n474\n519\n\n\nR2 / R2 adjusted\n0.006 / -0.000\n0.009 / 0.004"
  },
  {
    "objectID": "analyseverfahren/slides.html#regressionsformel-für-moderation",
    "href": "analyseverfahren/slides.html#regressionsformel-für-moderation",
    "title": "Anwendungsorientierte Analyseverfahren",
    "section": "Regressionsformel für Moderation",
    "text": "Regressionsformel für Moderation\n\nBei der Moderationsanalyse gehen wir davon aus, dass der Effekt X auf Y eine Funktion von Z ist  \\(Y = b_0 + f(Z)X + b_2Z + \\epsilon\\)\nDie Funktion f(Z) sei definiert als lineare Funktion \\(f(Z) = b_1 + b_3Z\\)  \\(Y = b_0 + (b_1 + b_3Z)X + b_2Z + \\epsilon\\)\nDurch Ausmultiplizieren erhalten wir einen Interaktionsterm \\(XZ\\), der einfach das Produkt von \\(X\\) und \\(Z\\) ist  \\(Y = b_0 + b_1X + b_2Z + b_3XZ + \\epsilon\\)"
  },
  {
    "objectID": "analyseverfahren/slides.html#was-bedeuten-die-koeffizienten",
    "href": "analyseverfahren/slides.html#was-bedeuten-die-koeffizienten",
    "title": "Anwendungsorientierte Analyseverfahren",
    "section": "Was bedeuten die Koeffizienten?",
    "text": "Was bedeuten die Koeffizienten?\n\nRegressionsformel \\(Y = b_0 + b_1X + b_2Z + b_3XZ + \\epsilon\\)\n\\(b_0\\) (Intercept) ist der erwartete Wert von \\(Y\\), wenn \\(X = 0\\) und \\(Z = 0\\)\n\\(b_1\\) ist der (konditionale) Effekt von \\(X\\), wenn \\(Z = 0\\)\n\\(b_2\\) ist der (konditionale) Effekt von \\(Z\\), wenn \\(X = 0\\)\n\\(b_3\\) ist der eigentliche Interaktionseffekt, d.h. die Differenz in \\(b_1\\), wenn \\(Z\\) sich um eine Einheit ändert"
  },
  {
    "objectID": "analyseverfahren/slides.html#interpretation-konditionaler-effekte",
    "href": "analyseverfahren/slides.html#interpretation-konditionaler-effekte",
    "title": "Anwendungsorientierte Analyseverfahren",
    "section": "Interpretation konditionaler Effekte",
    "text": "Interpretation konditionaler Effekte\n\nbei Moderationsanalysen wird oft nur auf die Signifikanz des Interaktionsterms geschaut.\nman kann und sollte aber auch die substanziellen Effekte betrachten, z.B. durch\n\nSchätzung der konditionalen Regressionskoeffizienten für (typische) Werte von \\(Z\\)\nVisualisierung der Modellvorhersagen für \\(Y\\) für (typische) Werte von \\(Z\\)\n\n\nWichtig: Bei Regressionsmodellen mit Interaktionseffekten \\(XZ\\) sind die Koeffizienten von \\(X\\) und \\(Z\\) nicht mehr unabhängig voneinander interpretierbar, d.h. die Effekte sind nicht mehr unkonditional für alle Fälle \\(n\\) gültig!\nWichtig: Damit die konditionalen Effekte überhaupt interpretierbar sind, sollten wir metrische Variablen zentrieren und kategorielle Variablen dummy- oder effektcodieren!"
  },
  {
    "objectID": "analyseverfahren/slides.html#interaktionsterme",
    "href": "analyseverfahren/slides.html#interaktionsterme",
    "title": "Anwendungsorientierte Analyseverfahren",
    "section": "Interaktionsterme",
    "text": "Interaktionsterme\n\nin R kann man Interaktionsterme direkt in die Modellformel für lm() aufnehmen: y ~ x + z + x:z oder einfacher y ~ x * z\nalternativ werden Interaktionsterme manuell erstellt:\n\nvor der Schätzung die beiden Variablen \\(X\\) und \\(Z\\) miteinander zu einer neuen Variable \\(XZ\\) multiplizieren\ndieser Interaktionsterm \\(XZ\\) wird dann als zusätzliche Prädiktorvariable ins Modell aufgenommen\n\nfür leichtere Interpretierbarkeit immer darauf achten, dass \\(X\\) und \\(Z\\) einen sinnvollen Wert für 0 haben"
  },
  {
    "objectID": "analyseverfahren/slides.html#beispielstudie-vögele2017",
    "href": "analyseverfahren/slides.html#beispielstudie-vögele2017",
    "title": "Anwendungsorientierte Analyseverfahren",
    "section": "Beispielstudie: Vögele & Bachl (2017)",
    "text": "Beispielstudie: Vögele & Bachl (2017)"
  },
  {
    "objectID": "analyseverfahren/slides.html#daten-3",
    "href": "analyseverfahren/slides.html#daten-3",
    "title": "Anwendungsorientierte Analyseverfahren",
    "section": "Daten",
    "text": "Daten\n\n\n\nschwab: Experimentalbedingung Dialekt schwäbisch 0 (nein), 1 (ja)\natol: Attitude toward other language = Einstellung zum Schwäbischen (1-5)\ngesamt: Gesamtbewertung des Politikers (Outcome-Variable, 1-5)   Your browser does not support the audio element.    Your browser does not support the audio element. \n\n\n\n\n\n\n\n\nschwab\n\n\ngeschlecht_w\n\n\natol\n\n\ngesamt\n\n\n\n\n\n\n1\n\n\n0\n\n\n3.4\n\n\n4\n\n\n\n\n1\n\n\n0\n\n\n3.0\n\n\n3\n\n\n\n\n0\n\n\n0\n\n\n2.8\n\n\n5\n\n\n\n\n1\n\n\n1\n\n\n4.8\n\n\n4\n\n\n\n\n1\n\n\n1\n\n\n3.4\n\n\n3"
  },
  {
    "objectID": "analyseverfahren/slides.html#bivariates-modell-nur-versuchsbedingung",
    "href": "analyseverfahren/slides.html#bivariates-modell-nur-versuchsbedingung",
    "title": "Anwendungsorientierte Analyseverfahren",
    "section": "Bivariates Modell (nur Versuchsbedingung)",
    "text": "Bivariates Modell (nur Versuchsbedingung)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nCoefficient\n95% CI\nt(361)\np\nStd. Coef.\nFit\n\n\n\n\n(Intercept)\n3.81\n(3.67, 3.94)\n55.54\n&lt; .001\n0.00\n\n\n\nschwab\n-0.20\n(-0.39, -0.02)\n-2.22\n0.027\n-0.12\n\n\n\n\n\n\n\n\n\n\n\n\nAICc\n\n\n\n\n\n937.93\n\n\nR2\n\n\n\n\n\n0.01\n\n\nR2 (adj.)\n\n\n\n\n\n0.01\n\n\nSigma\n\n\n\n\n\n0.88"
  },
  {
    "objectID": "analyseverfahren/slides.html#zwei-prädiktoren-nur-haupteffekte",
    "href": "analyseverfahren/slides.html#zwei-prädiktoren-nur-haupteffekte",
    "title": "Anwendungsorientierte Analyseverfahren",
    "section": "Zwei Prädiktoren (nur Haupteffekte)",
    "text": "Zwei Prädiktoren (nur Haupteffekte)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nCoefficient\n95% CI\nt(360)\np\nStd. Coef.\nFit\n\n\n\n\n(Intercept)\n3.63\n(3.46, 3.79)\n43.52\n&lt; .001\n0.00\n\n\n\nschwab\n-0.21\n(-0.39, -0.03)\n-2.31\n0.021\n-0.12\n\n\n\ngeschlecht w\n0.34\n(0.16, 0.52)\n3.75\n&lt; .001\n0.19\n\n\n\n\n\n\n\n\n\n\n\n\nAICc\n\n\n\n\n\n926.08\n\n\nR2\n\n\n\n\n\n0.05\n\n\nR2 (adj.)\n\n\n\n\n\n0.05\n\n\nSigma\n\n\n\n\n\n0.86"
  },
  {
    "objectID": "analyseverfahren/slides.html#modell-mit-kategoriellem-moderator",
    "href": "analyseverfahren/slides.html#modell-mit-kategoriellem-moderator",
    "title": "Anwendungsorientierte Analyseverfahren",
    "section": "Modell mit kategoriellem Moderator",
    "text": "Modell mit kategoriellem Moderator\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nCoefficient\n95% CI\nt(359)\np\nStd. Coef.\nFit\n\n\n\n\n(Intercept)\n3.71\n(3.51, 3.90)\n37.37\n&lt; .001\n0.00\n\n\n\nschwab\n-0.36\n(-0.62, -0.09)\n-2.66\n0.008\n-0.12\n\n\n\ngeschlecht w\n0.19\n(-0.07, 0.46)\n1.42\n0.158\n0.19\n\n\n\nschwab × geschlecht w\n0.27\n(-0.09, 0.63)\n1.49\n0.137\n0.08\n\n\n\n\n\n\n\n\n\n\n\n\nAICc\n\n\n\n\n\n925.89\n\n\nR2\n\n\n\n\n\n0.06\n\n\nR2 (adj.)\n\n\n\n\n\n0.05\n\n\nSigma\n\n\n\n\n\n0.86\n\n\n\n\n\n\n\nAchtung: Durch das bloße Hinzufügen des Interaktionsterms ändert sich die Interpretation der Regressionskoeffizienten! Wir sehen jetzt die Effekte des Dialekts bei Männern (geschlecht_w = 0) bzw. den Geschlechtseffekt in der Bedingung ohne Dialekt (schwab=0)."
  },
  {
    "objectID": "analyseverfahren/slides.html#konditionale-effekte",
    "href": "analyseverfahren/slides.html#konditionale-effekte",
    "title": "Anwendungsorientierte Analyseverfahren",
    "section": "Konditionale Effekte",
    "text": "Konditionale Effekte\nDurch Einsetzen in die Gleichung \\(f(Z) = b_1 + b_3Z\\) lassen sich die konditionalen Effekte von \\(X\\) (Dialekt) bei verschiedenen Ausprägungen vom Moderator \\(Z\\) (Geschlecht) schätzen:\n\n\n\n\n\n\n\n\nterm\n\n\ngeschlecht_w\n\n\nestimate\n\n\np.value\n\n\nconf.low\n\n\nconf.high\n\n\n\n\n\n\nschwab\n\n\n0\n\n\n-0.36\n\n\n0.01\n\n\n-0.62\n\n\n-0.09\n\n\n\n\nschwab\n\n\n1\n\n\n-0.09\n\n\n0.48\n\n\n-0.33\n\n\n0.15"
  },
  {
    "objectID": "analyseverfahren/slides.html#average-marginal-effects-ame",
    "href": "analyseverfahren/slides.html#average-marginal-effects-ame",
    "title": "Anwendungsorientierte Analyseverfahren",
    "section": "Average Marginal Effects (AME)",
    "text": "Average Marginal Effects (AME)\nDie durchschnittlichen Effekte von \\(X\\) über die gesamte Stichprobe (average marginal effects) lassen sich bestimmen, indem für jeden einzelnen Fall der konditionale Effekt berechnet und dann gemittelt wird.\n\n\n\n\n\n\nterm\n\n\nestimate\n\n\np.value\n\n\nconf.low\n\n\nconf.high\n\n\n\n\n\n\nschwab\n\n\n-0.21\n\n\n0.02\n\n\n-0.39\n\n\n-0.03\n\n\n\n\n\n\n\nAverage Marginal Effects (AME) entsprechen im linearen Modell den unmoderierten Koeffizienten\n\n\n\n\n\n\nterm\n\n\nestimate\n\n\nstd.error\n\n\nstatistic\n\n\np.value\n\n\n\n\n\n\nschwab\n\n\n-0.21\n\n\n0.09\n\n\n-2.31\n\n\n0.02\n\n\n\n\ngeschlecht_w\n\n\n0.34\n\n\n0.09\n\n\n3.75\n\n\n0.00"
  },
  {
    "objectID": "analyseverfahren/slides.html#vorhergesagte-werte",
    "href": "analyseverfahren/slides.html#vorhergesagte-werte",
    "title": "Anwendungsorientierte Analyseverfahren",
    "section": "Vorhergesagte Werte",
    "text": "Vorhergesagte Werte\n\nDurch Einsetzen der Werte von \\(X\\) in die Regressionsgleichung lassen sich wie immer die vorhergesagten Werte in \\(Y\\) schätzen.\nIm Beispiel gibt es nur 4 typische Bedingungen (2 Treatment x 2 Geschlecht), die wir explizit vorhersagen.\n\n\n\n\n\n\n\n\nschwab\n\n\ngeschlecht_w\n\n\nestimate\n\n\nstd.error\n\n\nconf.low\n\n\nconf.high\n\n\ndf\n\n\n\n\n\n\n0\n\n\n0\n\n\n3.71\n\n\n0.10\n\n\n3.51\n\n\n3.90\n\n\nInf\n\n\n\n\n0\n\n\n1\n\n\n3.90\n\n\n0.09\n\n\n3.72\n\n\n4.08\n\n\nInf\n\n\n\n\n1\n\n\n0\n\n\n3.35\n\n\n0.09\n\n\n3.17\n\n\n3.53\n\n\nInf\n\n\n\n\n1\n\n\n1\n\n\n3.81\n\n\n0.08\n\n\n3.65\n\n\n3.97\n\n\nInf"
  },
  {
    "objectID": "analyseverfahren/slides.html#visualisierung-der-vorhersagen-3",
    "href": "analyseverfahren/slides.html#visualisierung-der-vorhersagen-3",
    "title": "Anwendungsorientierte Analyseverfahren",
    "section": "Visualisierung der Vorhersagen",
    "text": "Visualisierung der Vorhersagen"
  },
  {
    "objectID": "analyseverfahren/slides.html#erweiterungen",
    "href": "analyseverfahren/slides.html#erweiterungen",
    "title": "Anwendungsorientierte Analyseverfahren",
    "section": "Erweiterungen",
    "text": "Erweiterungen\n\ndieselbe Analyselogik gilt auch für Moderatoren mit mehr als zwei Ausprägungen, d.h.\n\nalle konditionalen Effekte gelten dann für die Referenzgruppe\nes gibt jeweils \\(k-1\\) Haupt- und Interaktionseffekte\n\nin (zum Glück) seltenen Fällen gibt es auch 3-Wege-Interaktionen (2 Moderatoren)\n\nEinbeziehung bzw. Berechnung der Interaktionsterme \\(XZ_1\\), \\(XZ_2\\) und \\(XZ_1Z_2\\)\nInterpretation doppelt konditionaler Effekt sehr kompliziert"
  },
  {
    "objectID": "analyseverfahren/slides.html#beispiel-moderation-mit-3-gruppen",
    "href": "analyseverfahren/slides.html#beispiel-moderation-mit-3-gruppen",
    "title": "Anwendungsorientierte Analyseverfahren",
    "section": "Beispiel Moderation mit 3 Gruppen",
    "text": "Beispiel Moderation mit 3 Gruppen\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nCoefficient\n95% CI\nt(987)\np\nStd. Coef.\nFit\n\n\n\n\n(Intercept)\n2.82\n(2.55, 3.09)\n20.37\n&lt; .001\n-0.16\n\n\n\nGender (female)\n-0.63\n(-1.07, -0.19)\n-2.81\n0.005\n-0.46\n\n\n\nEducation (Middle)\n0.50\n(0.18, 0.82)\n3.04\n0.002\n0.37\n\n\n\nEducation (High)\n0.98\n(0.66, 1.30)\n6.00\n&lt; .001\n0.72\n\n\n\nGender (female) × Education (Middle)\n-0.11\n(-0.61, 0.40)\n-0.42\n0.672\n-0.08\n\n\n\nGender (female) × Education (High)\n-0.45\n(-0.94, 0.05)\n-1.75\n0.080\n-0.33\n\n\n\n\n\n\n\n\n\n\n\n\nAICc\n\n\n\n\n\n3300.42\n\n\nR2\n\n\n\n\n\n0.14\n\n\nR2 (adj.)\n\n\n\n\n\n0.13\n\n\nSigma\n\n\n\n\n\n1.27"
  },
  {
    "objectID": "analyseverfahren/slides.html#beispiel-moderation-mit-3-gruppen-1",
    "href": "analyseverfahren/slides.html#beispiel-moderation-mit-3-gruppen-1",
    "title": "Anwendungsorientierte Analyseverfahren",
    "section": "Beispiel Moderation mit 3 Gruppen",
    "text": "Beispiel Moderation mit 3 Gruppen"
  },
  {
    "objectID": "analyseverfahren/slides.html#beispiel-3-way-interaction",
    "href": "analyseverfahren/slides.html#beispiel-3-way-interaction",
    "title": "Anwendungsorientierte Analyseverfahren",
    "section": "Beispiel 3-Way-Interaction",
    "text": "Beispiel 3-Way-Interaction\n\nQuelle: Rains et al. (2023)"
  },
  {
    "objectID": "analyseverfahren/slides.html#fazit-der-letzten-sitzung",
    "href": "analyseverfahren/slides.html#fazit-der-letzten-sitzung",
    "title": "Anwendungsorientierte Analyseverfahren",
    "section": "Fazit der letzten Sitzung",
    "text": "Fazit der letzten Sitzung\n\nModerationsanalysen mit kategoriellen Variablen sind technisch leicht durchführbar, erfordern aber eine neue Interpretation\ndie Interpretation der stat. Signifikanz der Interaktionsterme ist einfach, die substanzielle Interpretation schwierig\ndurch Hinzunahme des Interaktionsterms werden aus den beteiligten Haupteffekten automatisch konditionale Effekte in der Referenzgruppe (!)\ndie Koeffizienten der Prädiktoren ohne Interaktionsterm bleiben unkonditional (!)"
  },
  {
    "objectID": "analyseverfahren/slides.html#wiederholung-kategorielle-moderatoren",
    "href": "analyseverfahren/slides.html#wiederholung-kategorielle-moderatoren",
    "title": "Anwendungsorientierte Analyseverfahren",
    "section": "Wiederholung: Kategorielle Moderatoren",
    "text": "Wiederholung: Kategorielle Moderatoren\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nCoefficient\n95% CI\nt(987)\np\nStd. Coef.\nFit\n\n\n\n\n(Intercept)\n8.81\n(8.13, 9.49)\n25.59\n&lt; .001\n0.11\n\n\n\nGender (female)\n-0.12\n(-1.21, 0.98)\n-0.21\n0.833\n-0.04\n\n\n\nEducation (Middle)\n-0.60\n(-1.40, 0.20)\n-1.47\n0.141\n-0.19\n\n\n\nEducation (High)\n-0.75\n(-1.54, 0.05)\n-1.85\n0.065\n-0.24\n\n\n\nGender (female) × Education (Middle)\n0.63\n(-0.63, 1.88)\n0.98\n0.326\n0.20\n\n\n\nGender (female) × Education (High)\n0.74\n(-0.50, 1.98)\n1.17\n0.242\n0.23\n\n\n\n\n\n\n\n\n\n\n\n\nAICc\n\n\n\n\n\n5108.02\n\n\nR2\n\n\n\n\n\n0.01\n\n\nR2 (adj.)\n\n\n\n\n\n0.00\n\n\nSigma\n\n\n\n\n\n3.16"
  },
  {
    "objectID": "analyseverfahren/slides.html#metrische-moderatoren",
    "href": "analyseverfahren/slides.html#metrische-moderatoren",
    "title": "Anwendungsorientierte Analyseverfahren",
    "section": "Metrische Moderatoren",
    "text": "Metrische Moderatoren\n\ndie grundlegende Logik aus Interaktionsterm und konditionalen Effekten bleibt gleich\nInterpretation des Interaktionseffekts vorwiegend Vorzeichen + Signifikanz\ndurch Zentrierung kann man klarer interpretierbarer konditionale Effekte erhalten\nz.B. Mittelwertzentrierung: Effekt von X bei mittlerem Z\nder konditionale Effekt bei mittlerem Z ist nicht dasselbe wie der unkonditionale Effekt"
  },
  {
    "objectID": "analyseverfahren/slides.html#regression-mit-metrischem-moderator",
    "href": "analyseverfahren/slides.html#regression-mit-metrischem-moderator",
    "title": "Anwendungsorientierte Analyseverfahren",
    "section": "Regression mit metrischem Moderator",
    "text": "Regression mit metrischem Moderator\n\nAnstelle einer dichotomen Variable kann man auch eine metrische Moderatorvariable berücksichtigt werden, hier zum Beispiel die Voreinstellung gegenüber dem schwäbischen Dialekt (atol).\nHypothese: Je positiver die Einstellung zum schwäbischen Dialekt bei einer Versuchsperson, desto positiver der Effekt der Experimentalbedingung\nReminder: der Koeffizient für Dialekt bezieht sich nun auf einen konkreten Wert von atol (konditionaler Effekt)"
  },
  {
    "objectID": "analyseverfahren/slides.html#regression-ohne-moderator",
    "href": "analyseverfahren/slides.html#regression-ohne-moderator",
    "title": "Anwendungsorientierte Analyseverfahren",
    "section": "Regression ohne Moderator",
    "text": "Regression ohne Moderator\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nCoefficient\n95% CI\nt(360)\np\nStd. Coef.\nFit\n\n\n\n\n(Intercept)\n3.44\n(3.02, 3.85)\n16.38\n&lt; .001\n0.00\n\n\n\nschwab\n-0.20\n(-0.38, -0.02)\n-2.15\n0.032\n-0.11\n\n\n\natol\n0.11\n(0.00, 0.23)\n1.88\n0.060\n0.10\n\n\n\n\n\n\n\n\n\n\n\n\nAICc\n\n\n\n\n\n936.42\n\n\nR2\n\n\n\n\n\n0.02\n\n\nR2 (adj.)\n\n\n\n\n\n0.02\n\n\nSigma\n\n\n\n\n\n0.87"
  },
  {
    "objectID": "analyseverfahren/slides.html#regression-mit-metrischem-moderator-1",
    "href": "analyseverfahren/slides.html#regression-mit-metrischem-moderator-1",
    "title": "Anwendungsorientierte Analyseverfahren",
    "section": "Regression mit metrischem Moderator",
    "text": "Regression mit metrischem Moderator\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nCoefficient\n95% CI\nt(359)\np\nStd. Coef.\nFit\n\n\n\n\n(Intercept)\n4.19\n(3.60, 4.79)\n13.79\n&lt; .001\n0.01\n\n\n\nschwab\n-1.53\n(-2.32, -0.74)\n-3.80\n&lt; .001\n-0.11\n\n\n\natol\n-0.12\n(-0.29, 0.06)\n-1.30\n0.196\n0.09\n\n\n\nschwab × atol\n0.40\n(0.17, 0.64)\n3.40\n&lt; .001\n0.18\n\n\n\n\n\n\n\n\n\n\n\n\nAICc\n\n\n\n\n\n926.98\n\n\nR2\n\n\n\n\n\n0.05\n\n\nR2 (adj.)\n\n\n\n\n\n0.05\n\n\nSigma\n\n\n\n\n\n0.86\n\n\n\n\n\n\n\nAchtung: Der konditionale Effekt für Dialekt macht nur Sinn, wenn atol auch 0 sein kann (Skala ist aber 1-5!)."
  },
  {
    "objectID": "analyseverfahren/slides.html#konditionale-effekte-durch-zentrierung",
    "href": "analyseverfahren/slides.html#konditionale-effekte-durch-zentrierung",
    "title": "Anwendungsorientierte Analyseverfahren",
    "section": "Konditionale Effekte durch Zentrierung",
    "text": "Konditionale Effekte durch Zentrierung\n\nZentrierung von atol mit 1, d.h. Koeffizient für Dialekt gilt für atol = 1 (Minimum)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nCoefficient\n95% CI\nt(359)\np\nStd. Coef.\nFit\n\n\n\n\n(Intercept)\n4.08\n(3.65, 4.51)\n18.69\n&lt; .001\n0.10\n\n\n\nschwab\n-1.13\n(-1.69, -0.56)\n-3.91\n&lt; .001\n0.06\n\n\n\natol - 1\n-0.12\n(-0.29, 0.06)\n-1.30\n0.196\n0.09\n\n\n\nschwab × atol - 1\n0.40\n(0.17, 0.64)\n3.40\n&lt; .001\n0.18\n\n\n\n\n\n\n\n\n\n\n\n\nAICc\n\n\n\n\n\n926.98\n\n\nR2\n\n\n\n\n\n0.05\n\n\nR2 (adj.)\n\n\n\n\n\n0.05\n\n\nSigma\n\n\n\n\n\n0.86"
  },
  {
    "objectID": "analyseverfahren/slides.html#mittelwertzentrierung-1",
    "href": "analyseverfahren/slides.html#mittelwertzentrierung-1",
    "title": "Anwendungsorientierte Analyseverfahren",
    "section": "Mittelwertzentrierung",
    "text": "Mittelwertzentrierung\n\nüblicherweise wird auf den Mittelwert von \\(Z\\) zentriert\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nCoefficient\n95% CI\nt(359)\np\nStd. Coef.\nFit\n\n\n\n\n(Intercept)\n3.81\n(3.68, 3.95)\n56.55\n&lt; .001\n0.01\n\n\n\nschwab\n-0.20\n(-0.38, -0.02)\n-2.21\n0.028\n-0.11\n\n\n\natol - mean(atol, na rm = T)\n-0.12\n(-0.29, 0.06)\n-1.30\n0.196\n0.09\n\n\n\nschwab × atol - mean(atol, na rm = T)\n0.40\n(0.17, 0.64)\n3.40\n&lt; .001\n0.18\n\n\n\n\n\n\n\n\n\n\n\n\nAICc\n\n\n\n\n\n926.98\n\n\nR2\n\n\n\n\n\n0.05\n\n\nR2 (adj.)\n\n\n\n\n\n0.05\n\n\nSigma\n\n\n\n\n\n0.86"
  },
  {
    "objectID": "analyseverfahren/slides.html#conditional-effects",
    "href": "analyseverfahren/slides.html#conditional-effects",
    "title": "Anwendungsorientierte Analyseverfahren",
    "section": "Conditional Effects",
    "text": "Conditional Effects\n\nwie bei Modellvorhersagen können wir für typische Werte des Moderators den Koeffizienten von \\(X\\) schätzen\n\n\n\n\n\n\n\nterm\n\n\natol\n\n\nestimate\n\n\np.value\n\n\nconf.low\n\n\nconf.high\n\n\n\n\n\n\nschwab\n\n\n1\n\n\n-1.13\n\n\n0.00\n\n\n-1.69\n\n\n-0.56\n\n\n\n\nschwab\n\n\n2\n\n\n-0.72\n\n\n0.00\n\n\n-1.07\n\n\n-0.37\n\n\n\n\nschwab\n\n\n3\n\n\n-0.32\n\n\n0.00\n\n\n-0.51\n\n\n-0.13\n\n\n\n\nschwab\n\n\n4\n\n\n0.08\n\n\n0.50\n\n\n-0.16\n\n\n0.32\n\n\n\n\nschwab\n\n\n5\n\n\n0.48\n\n\n0.03\n\n\n0.05\n\n\n0.92"
  },
  {
    "objectID": "analyseverfahren/slides.html#conditional-effects-plot",
    "href": "analyseverfahren/slides.html#conditional-effects-plot",
    "title": "Anwendungsorientierte Analyseverfahren",
    "section": "Conditional effects plot",
    "text": "Conditional effects plot"
  },
  {
    "objectID": "analyseverfahren/slides.html#johnson-neyman-intervalle",
    "href": "analyseverfahren/slides.html#johnson-neyman-intervalle",
    "title": "Anwendungsorientierte Analyseverfahren",
    "section": "Johnson-Neyman Intervalle",
    "text": "Johnson-Neyman Intervalle\n\nes werden Intervallgrenzen geschätzt, jenseits derer die Regressionskoeffizienten von \\(X\\) signifikant sind\n\n\nJOHNSON-NEYMAN INTERVAL\nWhen atol is OUTSIDE the interval [3.35, 4.74], the slope of schwab is p &lt; .05.\nNote: The range of observed values of atol is [1.00, 5.00]\n\n\nProblem 1: Alpha-Fehler durch (sehr) häufige Tests\nProblem 2: “The difference between signficant and insignificant is not itself signficant” (Andrew Gelman), sprich: die Punkte, an denen die stat. Signifikanz “umspringt”, haben keinerlei besondere Eigenschaften\nnicht verwenden!"
  },
  {
    "objectID": "analyseverfahren/slides.html#modellvorhersagen-2",
    "href": "analyseverfahren/slides.html#modellvorhersagen-2",
    "title": "Anwendungsorientierte Analyseverfahren",
    "section": "Modellvorhersagen",
    "text": "Modellvorhersagen\n\nwie immer lassen sich mit ausgewählten Werten der Prädiktoren auch Vorhersagen berechnen\n\n\n\n\n\n\n\nschwab\n\n\natol\n\n\nestimate\n\n\nstd.error\n\n\nconf.low\n\n\nconf.high\n\n\ndf\n\n\n\n\n\n\n0\n\n\n1\n\n\n4.08\n\n\n0.22\n\n\n3.65\n\n\n4.51\n\n\nInf\n\n\n\n\n0\n\n\n3\n\n\n3.85\n\n\n0.07\n\n\n3.70\n\n\n3.99\n\n\nInf\n\n\n\n\n0\n\n\n5\n\n\n3.62\n\n\n0.16\n\n\n3.30\n\n\n3.94\n\n\nInf\n\n\n\n\n1\n\n\n1\n\n\n2.95\n\n\n0.19\n\n\n2.59\n\n\n3.32\n\n\nInf\n\n\n\n\n1\n\n\n3\n\n\n3.53\n\n\n0.06\n\n\n3.40\n\n\n3.65\n\n\nInf\n\n\n\n\n1\n\n\n5\n\n\n4.10\n\n\n0.15\n\n\n3.81\n\n\n4.39\n\n\nInf"
  },
  {
    "objectID": "analyseverfahren/slides.html#visualisierung-der-modellvorhersagen",
    "href": "analyseverfahren/slides.html#visualisierung-der-modellvorhersagen",
    "title": "Anwendungsorientierte Analyseverfahren",
    "section": "Visualisierung der Modellvorhersagen",
    "text": "Visualisierung der Modellvorhersagen"
  },
  {
    "objectID": "analyseverfahren/slides.html#tipps",
    "href": "analyseverfahren/slides.html#tipps",
    "title": "Anwendungsorientierte Analyseverfahren",
    "section": "Tipps",
    "text": "Tipps\n\nauf korrekte Interpretation der Referenzgruppen achten bei kategoriellen Moderatoren\nmetrische Variablen zentrieren, die keinen interpretierbaren Nullpunkt haben, bevor man Interaktionsterme einfügt\nimmer auch \\(X\\) und \\(Z\\) im Modell zu haben, wenn der Interaktionsterm \\(XZ\\) im Modell ist\npragmatischer Vorschlag: wenn kein signifikanter Interaktionseffekt, dann lieber unkonditionales Modell (ohne Moderator) berichten\nsubstanzielle Interpretation durch Berechnung und Visualisierung von conditional effects und Modellvorhersagen"
  },
  {
    "objectID": "analyseverfahren/slides.html#fazit-1",
    "href": "analyseverfahren/slides.html#fazit-1",
    "title": "Anwendungsorientierte Analyseverfahren",
    "section": "Fazit",
    "text": "Fazit\n\nlineare Modelle mit Moderation sind in der Regel sehr (zu!) leicht zu spezifizieren, aber zumeist deutlich schwieriger substanziell zu interpretieren (außer Signifikanz des Interaktionseffekts)\nauch wenn die Regressionstabelle optisch sehr ähnlich aussieht, ändert sich Interpretation grundsätzlich\nviele SozialwissenschaftlerInnen interpretieren moderierte Effekte entweder gar nicht oder falsch\nModerationshypothesen sind nicht per se theoretisch wertvoll, und auch bei Moderationsanalysen gibt es Alpha-Fehler"
  },
  {
    "objectID": "analyseverfahren/slides.html#take-home-aufgabe-3",
    "href": "analyseverfahren/slides.html#take-home-aufgabe-3",
    "title": "Anwendungsorientierte Analyseverfahren",
    "section": "Take-Home Aufgabe #3",
    "text": "Take-Home Aufgabe #3\nAltay et al. (2022) untersuchen experimentell, ob falsche Nachrichten weniger als wahre geteilt werden, und wie dies von der Interessantheit der Nachricht abhängt.\nBeantworten Sie folgende Forschungsfragen mit Hilfe der Studien-Daten:\n\nWerden wahre Nachrichten eher geteilt als falsche?\nWerden interessante Nachrichten eher geteilt als uninteressante?\nGibt es den im Titel des Artikels angesprochenen Effekt eines zusätzlichen “interesting-if-true” Effekts auf das Teilen von Nachrichten? Wie fällt dieser Interaktionseffekt aus?\n\n\n\nAltay, S., De Araujo, E., & Mercier, H. (2022). “If this account is true, it is most enormously wonderful”: Interestingness-if-true and the sharing of true and false news. Digital Journalism, 10(3), 373-394."
  },
  {
    "objectID": "analyseverfahren/slides.html#take-home-aufgabe-3-1",
    "href": "analyseverfahren/slides.html#take-home-aufgabe-3-1",
    "title": "Anwendungsorientierte Analyseverfahren",
    "section": "Take-Home Aufgabe #3",
    "text": "Take-Home Aufgabe #3\n\nStellen Sie die Ergebnisse des/der geschätzen Modells/Modelle sinnvoll tabellarisch oder grafisch dar (Screenshot reicht).\nBeantworten Sie die Forschungsfragen anhand von Ihnen ausgewählter Kennwerte bzw. Quantities of Interest (2-3 Sätze pro Forschungsfrage)\nLösung als PDF-Datei bitte bis 09.07.2025, 10 Uhr in Moodle hochladen."
  },
  {
    "objectID": "analyseverfahren/slides.html#take-home-aufgabe-3-2",
    "href": "analyseverfahren/slides.html#take-home-aufgabe-3-2",
    "title": "Anwendungsorientierte Analyseverfahren",
    "section": "Take-Home Aufgabe #3",
    "text": "Take-Home Aufgabe #3\n\n# Daten laden\naltay22 = read_tsv(\"data/altay2022.tsv\")\n\n\n\n\n\n\n\nShare\n\n\nType\n\n\nInteresting\n\n\n\n\n\n\n2\n\n\nTN\n\n\n3\n\n\n\n\n1\n\n\nTN\n\n\n6\n\n\n\n\n1\n\n\nTN\n\n\n4\n\n\n\n\n\n\n\nShare = Wahrscheinlichkeit, die Nachricht mit anderen zu teilen (1-6, höher ist wahrscheinlicher)\nType = Nachrichtentyp (experimentell variiert, TN=wahr, FN=falsch)\nInteresting = Wahrgenommene Interessantheit der Nachricht (1-7, höher ist interessanter)"
  },
  {
    "objectID": "analyseverfahren/slides.html#kategorielle-outcomes---chi2-test",
    "href": "analyseverfahren/slides.html#kategorielle-outcomes---chi2-test",
    "title": "Anwendungsorientierte Analyseverfahren",
    "section": "Kategorielle Outcomes - \\(\\chi^2\\) Test",
    "text": "Kategorielle Outcomes - \\(\\chi^2\\) Test\n\noft sind wir an Zusammenhängen von kategoriellen Variablen interessiert\nKlassische Analysestrategie: Kreuztabelle und \\(\\chi^2\\) Test auf Unabhängigkeit\nVorteil: einfache Darstellung (Tabelle mit Spaltenprozenten, \\(\\chi^2\\) Wert, p-Wert, Kontingenzkoeffizient)\nNachteil: der \\(\\chi^2\\) Test ist ein Globaltest, d.h. wir testen nur, ob es irgendwo signifikante Abweichungen der beobachteten von den erwarteten Häufigkeiten gibt, aber nicht wie und wo\nweiterer Nachteil: nur kategorielle Prädiktoren, nur bivariate Zusammenhänge\nAlternative: GLM mit logistischer Link-Funktion"
  },
  {
    "objectID": "analyseverfahren/slides.html#lineare-regression-bei-dichotomer-av",
    "href": "analyseverfahren/slides.html#lineare-regression-bei-dichotomer-av",
    "title": "Anwendungsorientierte Analyseverfahren",
    "section": "Lineare Regression bei dichotomer AV",
    "text": "Lineare Regression bei dichotomer AV\n\n\n\nviele vorausgesagte Werte von Y kann es in den Daten nicht geben, da nur die Werte 0 und 1 empirisch vorkommen.\nlinearer Zusammenhang ist nicht gegeben, d.h. wir verstoßen gegen die Annahmen der OLS-Regression\ntrotzdem häufiger Einsatz als Linear Probability Model (LPM) mit einfacher Interpretation"
  },
  {
    "objectID": "analyseverfahren/slides.html#inverse-logit-funktion",
    "href": "analyseverfahren/slides.html#inverse-logit-funktion",
    "title": "Anwendungsorientierte Analyseverfahren",
    "section": "(Inverse) Logit-Funktion",
    "text": "(Inverse) Logit-Funktion\n\n\n\nLogit-Funktion: \\(P(Y) = \\frac {1}{1+e^{-(\\beta_0 + \\beta_1 x)}}\\)\nDie Logit-Funktion transformiert alle Werte in einen Bereich von 0-1.\nDie Werte von 0-1 können als Wahrscheinlichkeiten interpretiert werden."
  },
  {
    "objectID": "analyseverfahren/slides.html#lineare-vs.-logistische-regression",
    "href": "analyseverfahren/slides.html#lineare-vs.-logistische-regression",
    "title": "Anwendungsorientierte Analyseverfahren",
    "section": "Lineare vs. logistische Regression",
    "text": "Lineare vs. logistische Regression\n\\(Logit(Y) = b_0 + b_1 X_i + \\epsilon_i\\)\n\ngleiche Annahmen zu Unabhängigkeit und Multikollinearität\ngleiche Logik der Modellspezifikation mit Nullmodell und Prädiktorvariablen\ngleiche Logik der statistischen Inferenz, d.h. Standardfehler und Konfidenzintervalle\nunterschiedliche Interpretation der Koeffizienten (sowohl unstandardisiert als auch standardisiert)\nunterschiedliche Maße der Modellgüte ( \\(R^2\\), etc.)"
  },
  {
    "objectID": "analyseverfahren/slides.html#interpretation-logistischer-modelle",
    "href": "analyseverfahren/slides.html#interpretation-logistischer-modelle",
    "title": "Anwendungsorientierte Analyseverfahren",
    "section": "Interpretation logistischer Modelle",
    "text": "Interpretation logistischer Modelle\n\nunstandardisierte Koeffizienten sind bei logistischer Regression schwer interpretierbar\nInterpretation als (Änderung von) Wahrscheinlichkeiten ist falsch, u.a. weil diese nicht konstant sind\n3 Möglichkeiten, logistische Modelle zu interpretieren:\n\nDivide-by-4-Regel mit unstandardisierten Koeffizienten\nAverage Marginal Effects\nOdds-Ratios"
  },
  {
    "objectID": "analyseverfahren/slides.html#unstandardisierte-koeffizienten",
    "href": "analyseverfahren/slides.html#unstandardisierte-koeffizienten",
    "title": "Anwendungsorientierte Analyseverfahren",
    "section": "Unstandardisierte Koeffizienten",
    "text": "Unstandardisierte Koeffizienten\n\ndie Interpretation von unstandardisierten Koeffizienten im logistischen Modell hängt (auch) am Intercept bzw. an den anderen Kovariaten\nder Intercept lässt sich durch die sog. Inverse Logit Funktion (in R plogis()) in eine Baseline-Wahrscheinlichkeit umrechnen\ndie Veränderung der Wahrscheinlichkeiten bei einer Änderung von \\(X\\) (Slope) ist nicht in allen Fällen gleich groß\nGelman & Hill (2007) empfehlen für eine schnelle Interpretation unstandardisierte Koeffizienten die Divide-by-4-Regel\n\\(B/4\\) ist eine Obergrenze für die Änderung in der Wahrscheinlichkeit P(Y=1), wenn \\(X\\) sich um eine Einheit ändert\nAbweichung ist am Rande der Verteilung von \\(Y\\) größer als in der Mitte"
  },
  {
    "objectID": "analyseverfahren/slides.html#average-marginal-effects",
    "href": "analyseverfahren/slides.html#average-marginal-effects",
    "title": "Anwendungsorientierte Analyseverfahren",
    "section": "Average Marginal Effects",
    "text": "Average Marginal Effects\n\nfür jeden Wert von \\(X\\) lässt sich der Anstieg in der Logit-Funktion von \\(Y\\) berechnen.\nwenn wir dies für alle Werte in der Stichprobe tun, und davon den Mittelwert errechnen, erhalten wir den AME\ndieser lässt sich als durchschnittliche Veränderung in der Wahrscheinlichkeit P(Y=1) über alle Fälle interpretieren\nalternativ können wir auch wieder typische Fälle auswählen und dafür die vorgesagten Werten von \\(Y\\) schätzen\ndies bietet sich vor allem bei Modellen mit kategoriellen Prädiktorvariablen an (vgl. ANOVA)"
  },
  {
    "objectID": "analyseverfahren/slides.html#odds-ratios---expb",
    "href": "analyseverfahren/slides.html#odds-ratios---expb",
    "title": "Anwendungsorientierte Analyseverfahren",
    "section": "Odds Ratios - Exp(B)",
    "text": "Odds Ratios - Exp(B)\n\ndie meisten logistischen Regressionen berichten statt B den Wert Exp(B), der auch als Odds Ratio (OR) bezeichnen wird\nOdds = \\(P(x)/1-P(x)\\) kann man im Deutschen als Chance oder Risiko übersetzen, nicht jedoch als Wahrscheinlichkeit!\neine OR=1 bedeutet kein Effekt, OR &gt; 1 bedeutet eine erhöhte Chance bzw. Risiko, eine OR &lt; 1 eine niedrigere Chance/Risiko\nExp(B) = .5 heißt: mit jedem Skalenpunkt mehr X besteht ein halb so großes Risiko\nExp(B) = 2 heißt: mit jedem Skalenpunkt mehr X verdoppelt sich das Risiko"
  },
  {
    "objectID": "analyseverfahren/slides.html#modellgüte-pseudo-r2",
    "href": "analyseverfahren/slides.html#modellgüte-pseudo-r2",
    "title": "Anwendungsorientierte Analyseverfahren",
    "section": "Modellgüte: Pseudo \\(R^2\\)",
    "text": "Modellgüte: Pseudo \\(R^2\\)\n\nweit verbreitetes Maß für die Güte einer logistischen Regression ist das Pseudo \\(R^2\\) von McFadden, Nagelkerke oder Cox & Snell.\ndiese setzen die Log-Likelihood des Nullmodells mit dem gefitteten Modell in Beziehung, beschreiben also wieviel besser das Modell gegenüber dem Nullmodell ist\ndie Interpretation ist vergleichbar mit dem klassischen \\(R^2\\), wobei nicht immer klar ist, inwiefern der Wertebereich wirklich von 0-1 geht"
  },
  {
    "objectID": "analyseverfahren/slides.html#daten-4",
    "href": "analyseverfahren/slides.html#daten-4",
    "title": "Anwendungsorientierte Analyseverfahren",
    "section": "Daten",
    "text": "Daten\n\n\n\n\n\n\ncbbully_gen\n\n\ncbvictim_gen\n\n\nage\n\n\ngender\n\n\ninternetuse\n\n\nclass\n\n\n\n\n\n\n0\n\n\n0\n\n\n13\n\n\nmale\n\n\n2.0\n\n\nG7a\n\n\n\n\n0\n\n\n0\n\n\n16\n\n\nmale\n\n\n1.0\n\n\nG10b\n\n\n\n\n0\n\n\n0\n\n\n14\n\n\nmale\n\n\n2.5\n\n\nG8b\n\n\n\n\n0\n\n\n0\n\n\n13\n\n\nmale\n\n\n1.0\n\n\nG7b\n\n\n\n\n0\n\n\n0\n\n\n18\n\n\nmale\n\n\n1.0\n\n\nG12\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVariable\n\n\nn_Obs\n\n\nMean\n\n\nSD\n\n\nMedian\n\n\nMAD\n\n\nMin\n\n\nMax\n\n\n\n\n\n\ncbvictim_gen\n\n\n275\n\n\n0.11\n\n\n0.31\n\n\n0\n\n\n0\n\n\n0\n\n\n1"
  },
  {
    "objectID": "analyseverfahren/slides.html#nullmodell",
    "href": "analyseverfahren/slides.html#nullmodell",
    "title": "Anwendungsorientierte Analyseverfahren",
    "section": "Nullmodell",
    "text": "Nullmodell\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nCoefficient\n95% CI\nz\np\nStd. Coef.\nFit\n\n\n\n\n(Intercept)\n-2.14\n(-2.52, -1.75)\n-10.89\n&lt; .001\n-2.14\n\n\n\n\n\n\n\n\n\n\n\n\nAICc\n\n\n\n\n\n187.31\n\n\nTjur’s R2\n\n\n\n\n\n0.00\n\n\nSigma\n\n\n\n\n\n1.00\n\n\nLog_loss\n\n\n\n\n\n0.34\n\n\n\n\n\n\nplogis(-2.14)\n\n[1] 0.1052694"
  },
  {
    "objectID": "analyseverfahren/slides.html#kategorieller-prädiktor",
    "href": "analyseverfahren/slides.html#kategorieller-prädiktor",
    "title": "Anwendungsorientierte Analyseverfahren",
    "section": "Kategorieller Prädiktor",
    "text": "Kategorieller Prädiktor\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nCoefficient\n95% CI\nz\np\nStd. Coef.\nFit\n\n\n\n\n(Intercept)\n-2.48\n(-3.13, -1.94)\n-8.27\n&lt; .001\n-2.48\n\n\n\ngender (female)\n0.69\n(-0.08, 1.50)\n1.74\n0.082\n0.69\n\n\n\n\n\n\n\n\n\n\n\n\nAICc\n\n\n\n\n\n186.26\n\n\nTjur’s R2\n\n\n\n\n\n0.01\n\n\nSigma\n\n\n\n\n\n1.00\n\n\nLog_loss\n\n\n\n\n\n0.33"
  },
  {
    "objectID": "analyseverfahren/slides.html#odds-ratios-expb",
    "href": "analyseverfahren/slides.html#odds-ratios-expb",
    "title": "Anwendungsorientierte Analyseverfahren",
    "section": "Odds-Ratios (Exp(B))",
    "text": "Odds-Ratios (Exp(B))\n\n\n\n\n\n\nParameter\n\n\nCoefficient\n\n\nCI\n\n\nCI_low\n\n\nCI_high\n\n\nz\n\n\np\n\n\nFit\n\n\n\n\n\n\n(Intercept)\n\n\n0.08\n\n\n0.95\n\n\n0.04\n\n\n0.14\n\n\n-8.27\n\n\n0.00\n\n\nNA\n\n\n\n\ngender [female]\n\n\n2.00\n\n\n0.95\n\n\n0.92\n\n\n4.46\n\n\n1.74\n\n\n0.08\n\n\nNA"
  },
  {
    "objectID": "analyseverfahren/slides.html#ame-und-modellvorhersagen",
    "href": "analyseverfahren/slides.html#ame-und-modellvorhersagen",
    "title": "Anwendungsorientierte Analyseverfahren",
    "section": "AME und Modellvorhersagen",
    "text": "AME und Modellvorhersagen\nAME\n\n\n\n\n\n\nterm\n\n\nestimate\n\n\nstd.error\n\n\nstatistic\n\n\np.value\n\n\nconf.low\n\n\nconf.high\n\n\n\n\n\n\ngender\n\n\n0.07\n\n\n0.04\n\n\n1.71\n\n\n0.09\n\n\n-0.01\n\n\n0.14\n\n\n\n\n\n\n\n\nVorhergesagte Wahrscheinlichkeiten\n\n\n\n\n\n\ngender\n\n\nestimate\n\n\nstd.error\n\n\nstatistic\n\n\np.value\n\n\ns.value\n\n\nconf.low\n\n\nconf.high\n\n\ndf\n\n\n\n\n\n\nmale\n\n\n0.08\n\n\n0.02\n\n\n3.61\n\n\n0\n\n\n11.65\n\n\n0.04\n\n\n0.12\n\n\nInf\n\n\n\n\nfemale\n\n\n0.14\n\n\n0.03\n\n\n4.45\n\n\n0\n\n\n16.85\n\n\n0.08\n\n\n0.21\n\n\nInf"
  },
  {
    "objectID": "analyseverfahren/slides.html#visualisierung-der-modellvorhersagen-1",
    "href": "analyseverfahren/slides.html#visualisierung-der-modellvorhersagen-1",
    "title": "Anwendungsorientierte Analyseverfahren",
    "section": "Visualisierung der Modellvorhersagen",
    "text": "Visualisierung der Modellvorhersagen"
  },
  {
    "objectID": "analyseverfahren/slides.html#multiple-logistische-regression",
    "href": "analyseverfahren/slides.html#multiple-logistische-regression",
    "title": "Anwendungsorientierte Analyseverfahren",
    "section": "Multiple logistische Regression",
    "text": "Multiple logistische Regression\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nCoefficient\n95% CI\nz\np\nStd. Coef.\nFit\n\n\n\n\n(Intercept)\n-2.98\n(-3.82, -2.23)\n-7.41\n&lt; .001\n-2.56\n\n\n\ngender (female)\n0.76\n(-0.02, 1.58)\n1.88\n0.060\n0.76\n\n\n\ninternetuse\n0.19\n(0.00, 0.37)\n2.10\n0.036\n0.34\n\n\n\n\n\n\n\n\n\n\n\n\nAICc\n\n\n\n\n\n184.36\n\n\nTjur’s R2\n\n\n\n\n\n0.03\n\n\nSigma\n\n\n\n\n\n1.00\n\n\nLog_loss\n\n\n\n\n\n0.32"
  },
  {
    "objectID": "analyseverfahren/slides.html#average-marginal-effects-1",
    "href": "analyseverfahren/slides.html#average-marginal-effects-1",
    "title": "Anwendungsorientierte Analyseverfahren",
    "section": "Average Marginal Effects",
    "text": "Average Marginal Effects\n\n\n\n\n\n\nterm\n\n\nestimate\n\n\nstd.error\n\n\nstatistic\n\n\np.value\n\n\nconf.low\n\n\nconf.high\n\n\n\n\n\n\ngender\n\n\n0.07\n\n\n0.04\n\n\n1.85\n\n\n0.06\n\n\n0\n\n\n0.15\n\n\n\n\ninternetuse\n\n\n0.02\n\n\n0.01\n\n\n1.98\n\n\n0.05\n\n\n0\n\n\n0.04"
  },
  {
    "objectID": "analyseverfahren/slides.html#modellvorhersagen-3",
    "href": "analyseverfahren/slides.html#modellvorhersagen-3",
    "title": "Anwendungsorientierte Analyseverfahren",
    "section": "Modellvorhersagen",
    "text": "Modellvorhersagen"
  },
  {
    "objectID": "analyseverfahren/slides.html#fazit-2",
    "href": "analyseverfahren/slides.html#fazit-2",
    "title": "Anwendungsorientierte Analyseverfahren",
    "section": "Fazit",
    "text": "Fazit\n\nin vielen Fällen ist die logistische Regression eine sinnvolle Alternative zu Kreuztabellen\ndie Modellierung ist praktisch identisch mit linearen Regressionsmodellen\ndie Interpretation der Koeffizienten ist komplexer, aber AME und Modellvorhersagen helfen dabei\ndas Linear Probability Model führt oft zu ähnlichen Ergebnissen (vor allem wenn Y nicht allzu selten oder häufig 1 ist)"
  },
  {
    "objectID": "analyseverfahren/slides.html#take-home-3---haupteffekte",
    "href": "analyseverfahren/slides.html#take-home-3---haupteffekte",
    "title": "Anwendungsorientierte Analyseverfahren",
    "section": "Take-Home #3 - Haupteffekte",
    "text": "Take-Home #3 - Haupteffekte\n\nlm(Share ~ Type + Interesting, data = altay22)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nCoefficient\n95% CI\nt(2987)\np\nStd. Coef.\nFit\n\n\n\n\n(Intercept)\n0.36\n(0.21, 0.52)\n4.57\n&lt; .001\n-0.11\n\n\n\nType (TN)\n0.35\n(0.25, 0.46)\n6.89\n&lt; .001\n0.23\n\n\n\nInteresting\n0.45\n(0.41, 0.48)\n26.98\n&lt; .001\n0.44\n\n\n\n\n\n\n\n\n\n\n\n\nAICc\n\n\n\n\n\n10512.35\n\n\nR2\n\n\n\n\n\n0.20\n\n\nR2 (adj.)\n\n\n\n\n\n0.20\n\n\nSigma\n\n\n\n\n\n1.40"
  },
  {
    "objectID": "analyseverfahren/slides.html#take-home-3---interaktionseffekt",
    "href": "analyseverfahren/slides.html#take-home-3---interaktionseffekt",
    "title": "Anwendungsorientierte Analyseverfahren",
    "section": "Take-Home #3 - Interaktionseffekt",
    "text": "Take-Home #3 - Interaktionseffekt\n\nlm(Share ~ Type + Interesting + Type:Interesting, data = altay22)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nCoefficient\n95% CI\nt(2986)\np\nStd. Coef.\nFit\n\n\n\n\n(Intercept)\n0.64\n(0.44, 0.83)\n6.31\n&lt; .001\n-0.11\n\n\n\nType (TN)\n-0.25\n(-0.54, 0.04)\n-1.69\n0.091\n0.23\n\n\n\nInteresting\n0.38\n(0.34, 0.43)\n17.37\n&lt; .001\n0.38\n\n\n\nType (TN) × Interesting\n0.15\n(0.08, 0.21)\n4.38\n&lt; .001\n0.14\n\n\n\n\n\n\n\n\n\n\n\n\nAICc\n\n\n\n\n\n10495.21\n\n\nR2\n\n\n\n\n\n0.21\n\n\nR2 (adj.)\n\n\n\n\n\n0.21\n\n\nSigma\n\n\n\n\n\n1.40"
  },
  {
    "objectID": "analyseverfahren/slides.html#take-home-3---modellvorhersagen",
    "href": "analyseverfahren/slides.html#take-home-3---modellvorhersagen",
    "title": "Anwendungsorientierte Analyseverfahren",
    "section": "Take-Home #3 - Modellvorhersagen",
    "text": "Take-Home #3 - Modellvorhersagen"
  },
  {
    "objectID": "analyseverfahren/slides.html#nochmal-modellannahmen-unabhängigkeit",
    "href": "analyseverfahren/slides.html#nochmal-modellannahmen-unabhängigkeit",
    "title": "Anwendungsorientierte Analyseverfahren",
    "section": "Nochmal Modellannahmen: Unabhängigkeit",
    "text": "Nochmal Modellannahmen: Unabhängigkeit\n\nbeim GLM gehen wir davon aus, dass die Residuen unabhängig voneinander sind\nAnnahme ist verletzt, wenn die Fälle der Stichprobe nicht unabhängig voneinander sind\ntypische Fälle sind (a) zeitliche Abhängigkeiten, z.B. durch Messwiederholung, und (b) Abhängigkeiten durch geschachtelte Daten\nwenn Unabhängigkeitsannahme verletzt ist, werden (a) Schätzer verzerrt sein und (b) die Standardfehler zu klein, d.h. erhöhtes Risiko für Alpha-Fehler"
  },
  {
    "objectID": "analyseverfahren/slides.html#was-sind-geschachtelte-nested-daten",
    "href": "analyseverfahren/slides.html#was-sind-geschachtelte-nested-daten",
    "title": "Anwendungsorientierte Analyseverfahren",
    "section": "Was sind geschachtelte (nested) Daten?",
    "text": "Was sind geschachtelte (nested) Daten?\nLevel-1-Einheiten gehören zu/sind geschachtelt in Level-2-Einheiten.\n\nSchüler geschachtelt in Klassen oder Schulen\nBeiträge geschachtelt in Nachrichtenoutlets, Accounts, Ausgaben oder Sendungen\nMessungen geschachtelt in Personen (Personen sind Level-2!)\nDaten können auch auf mehr als zwei hierarchischen Ebenen (Schüler, Klasse, Schule) geschachtelt oder kreuzklassifiziert sein\nbei kreuzklassifizierten Daten gehören Level-1-Einheiten zu min. zwei verschiedenen Kontexten (z.B. Bewertungen von Werbespots gehören zu bewertenden Personen und bewerteten Spots)"
  },
  {
    "objectID": "analyseverfahren/slides.html#warum-multilevel-modelle",
    "href": "analyseverfahren/slides.html#warum-multilevel-modelle",
    "title": "Anwendungsorientierte Analyseverfahren",
    "section": "Warum Multilevel-Modelle?",
    "text": "Warum Multilevel-Modelle?\n\nstatistische Gründe: Die Schachtelung der Level-1-Einheiten muss auch berücksichtigt werden, wenn nur Level-1-Zusammenhänge von Interesse sind (dependence as a nuisance).\nsubstanziellen Gründe: Multilevel-Modelle erlauben eine Zerlegung in Between- und Within-Group-Varianz und damit die adäquate Modellierung von Zusammenhängen auf verschiedenen Ebenen (dependence as an interesting phenomenon)."
  },
  {
    "objectID": "analyseverfahren/slides.html#grundbegriffe",
    "href": "analyseverfahren/slides.html#grundbegriffe",
    "title": "Anwendungsorientierte Analyseverfahren",
    "section": "Grundbegriffe",
    "text": "Grundbegriffe\n\nMultilevel Model = Hierarchical Model = Mixed Effects Model (= Mehrebenen-Modell)\nBetween-Group-Varianz = Varianz, die durch Unterschiede in den Level-2-Einheiten erzeugt wird\nWithin-Group-Varianz = Varianz, die durch Unterschiede der Level-1-Einheiten innerhalb derselben Level-2-Einheit erzeugt wird\nFixed Effects = Zusammenhänge, die in allen Level-2-Kontexten gleich sind\nRandom (Varying) Effects = Zusammenhänge, die über die Level-2-Kontexte variieren\nCross-Level-Interaction = Zusammenhang zwischen Level-1-Effekt und Level-2-Kontextmerkmalen"
  },
  {
    "objectID": "analyseverfahren/slides.html#nullmodell-mit-varierenden-intercepts",
    "href": "analyseverfahren/slides.html#nullmodell-mit-varierenden-intercepts",
    "title": "Anwendungsorientierte Analyseverfahren",
    "section": "Nullmodell mit varierenden Intercepts",
    "text": "Nullmodell mit varierenden Intercepts\nDas Multilevel-Nullmodell für geschachtelte Daten mit \\(i\\) Individuen in \\(j\\) Gruppen besteht aus je einem Nullmodell pro Ebene:\nLevel 1: \\(Y_{ij} = b_{0j}+ \\epsilon_{ij}\\) und Level 2: \\(b_{0j} = \\gamma_{00} + u_{0j}\\)\noder zusammengenommen: \\(Y_{ij} = \\gamma_{00} + u_{0j} + \\epsilon_{ij}\\)\n\\(\\gamma_{00}\\) ist der globale Mittelwert von \\(Y\\), \\(u_{0j}\\) ist die gruppenspezifische Abweichung vom globalen Mittelwert und \\(\\epsilon_{ij}\\) ist das individuelle Residuum."
  },
  {
    "objectID": "analyseverfahren/slides.html#intra-class-correlation-icc",
    "href": "analyseverfahren/slides.html#intra-class-correlation-icc",
    "title": "Anwendungsorientierte Analyseverfahren",
    "section": "Intra-Class-Correlation (ICC)",
    "text": "Intra-Class-Correlation (ICC)\n\nzu Beginn sollte man ein Nullmodell (d.h. ohne Prädiktoren) schätzen, um die Intra-Class-Correlation (ICC) zu berechnen\nICC Anteil der Varianz in einer Variable, der durch die Kontexte (Level-2) erklärt wird. Technisch: der Anteil Between-Group-Varianz (also die Varianz von \\(u_{0j}\\)) an der Gesamtvarianz von \\(Y\\).\nwenn der ICC hoch ist (viel Gruppenvarianz), lohnt sich die Betrachtung von Level-2-Prädiktoren\nwenn der ICC niedrig ist (wenig Gruppenvarianz), sind Level-1-Prädiktoren ein sinnvolleres Ziel\nselbst bei kleinem ICC ist Mehrebenenanalyse sinnvoll, da sie nie “schlechter” als ein klassisches Regressionsmodell ist"
  },
  {
    "objectID": "analyseverfahren/slides.html#regression-und-multilevel-regression",
    "href": "analyseverfahren/slides.html#regression-und-multilevel-regression",
    "title": "Anwendungsorientierte Analyseverfahren",
    "section": "Regression und Multilevel-Regression",
    "text": "Regression und Multilevel-Regression\n\nMultilevel-Modelle sind eine konzeptionelle Erweiterung der (linearen) Regression\nalle Annahmen der Regression (Normalverteilung der Residuen, Homoskedastizität, Linearität) weiterhin\ngruppenspezifischen Abweichungen werden oft nur summarisch, d.h. z.B. ihre Varianz berichtet, aber nicht einzeln inspiziert\nZentrierung ist üblich, Standardisierung der Koeffizienten eher selten"
  },
  {
    "objectID": "analyseverfahren/slides.html#random-bzw.-varying--intercept-modell",
    "href": "analyseverfahren/slides.html#random-bzw.-varying--intercept-modell",
    "title": "Anwendungsorientierte Analyseverfahren",
    "section": "Random (bzw. Varying-) Intercept Modell",
    "text": "Random (bzw. Varying-) Intercept Modell\n-Intercepts dürfen gruppenspezifisch variieren, Regressionskoeffizienten \\(B\\) sind für alle Level-2-Einheiten gleich\n\\(Y_{ij} = \\gamma_{00} + u_{0j} + B_1 x_1 +  B_2 x_2 + ... + \\epsilon_{ij}\\)\n\ndie variierenden Intercepts die Abweichungen der einzelnen Level-2-Einheiten vom globalen Intercept\nOutput und Interpretation der Regressionskoeffizienten entspricht dem regulären linearen Regressionsmodell"
  },
  {
    "objectID": "analyseverfahren/slides.html#r2-und-modellvergleich",
    "href": "analyseverfahren/slides.html#r2-und-modellvergleich",
    "title": "Anwendungsorientierte Analyseverfahren",
    "section": "\\(R^2\\) und Modellvergleich",
    "text": "\\(R^2\\) und Modellvergleich\n\nIn Multilevel-Modellen gibt es keinen Standard für die Berechnung von \\(R^2\\)\nAlternative 1: separate Inspektion bzw. Modellvergleich der einzelnen Varianzkomponenten (Residual und Level-2-Varianz) hat den Vorteil, dass man recht klar erkennen kann, welche L1- bzw. L2-Prädiktoren wie das Modell verbessern\nAlternative 2: Globalmaße, die in entweder nur die Fixed Effects (marginal \\(R2\\)) oder Fixed und Random Effects (conditional \\(R2\\)) berücksichtigen (Nakagawa et al., 2017)\nWie beim partiellen F-Test der Regression kann man auch verschiedene Modelle miteinander hinsichtlich ihrer Varianzaufklärung vergleichen, dies wird oft Likelihood-Ratio-Test genannt"
  },
  {
    "objectID": "analyseverfahren/slides.html#modellerweiterungen",
    "href": "analyseverfahren/slides.html#modellerweiterungen",
    "title": "Anwendungsorientierte Analyseverfahren",
    "section": "Modellerweiterungen",
    "text": "Modellerweiterungen\n\n\n\nzusätzlich zu den Intercepts kann man auch Regressionskoeffizienten über die Level-2-Einheiten variieren lassen, um die Effektheterogenität über Gruppen zu prüfen\nebenso kann man Interaktionen sowohl innerhalb einer Ebene als auch sog. Cross-Level-Interactions modellieren, d.h. ob der Kontext- den Individualeffekt moderiert"
  },
  {
    "objectID": "analyseverfahren/slides.html#beispielstudie-fähnrich-et-al.-2020",
    "href": "analyseverfahren/slides.html#beispielstudie-fähnrich-et-al.-2020",
    "title": "Anwendungsorientierte Analyseverfahren",
    "section": "Beispielstudie: Fähnrich et al. (2020)",
    "text": "Beispielstudie: Fähnrich et al. (2020)"
  },
  {
    "objectID": "analyseverfahren/slides.html#daten-5",
    "href": "analyseverfahren/slides.html#daten-5",
    "title": "Anwendungsorientierte Analyseverfahren",
    "section": "Daten",
    "text": "Daten\n\nStichprobe von 10807 Facebook-Posts von 42 Universitäten\nUni-Fans ist die Anzahl Fans der Facebook-Seite (in Tausend), d.h. hier eine Level-2-Variable\nAlle anderen Variablen sind pro Post, d.h. Level-1-Variablen.\n\n\n\n\n\n\n\nuni\n\n\nuni_fans\n\n\ncreated_time\n\n\ntype\n\n\nlikes_count\n\n\ncomments_count\n\n\n\n\n\n\nUT Southwestern\n\n\n15.41\n\n\n2015-05-10 22:40:25\n\n\nlink\n\n\n5\n\n\n0\n\n\n\n\nJohns Hopkins U\n\n\n113.61\n\n\n2013-08-13 15:50:01\n\n\nphoto\n\n\n103\n\n\n3\n\n\n\n\nU British Columbia\n\n\n121.04\n\n\n2013-06-20 18:22:58\n\n\nphoto\n\n\n66\n\n\n5\n\n\n\n\nU Colorado Boulder\n\n\n154.47\n\n\n2012-10-30 20:03:57\n\n\nlink\n\n\n253\n\n\n56\n\n\n\n\nU Michigan\n\n\n710.50\n\n\n2013-08-01 17:26:54\n\n\nphoto\n\n\n7968\n\n\n261"
  },
  {
    "objectID": "analyseverfahren/slides.html#outcome-variable-4",
    "href": "analyseverfahren/slides.html#outcome-variable-4",
    "title": "Anwendungsorientierte Analyseverfahren",
    "section": "Outcome-Variable",
    "text": "Outcome-Variable\n\n\n\n\n\n\nVariable\n\n\nn_Obs\n\n\nMean\n\n\nSD\n\n\nMedian\n\n\nMAD\n\n\nMin\n\n\nMax\n\n\n\n\n\n\ncomments_count\n\n\n10807\n\n\n12.15\n\n\n36.46\n\n\n3\n\n\n4.45\n\n\n0\n\n\n1556"
  },
  {
    "objectID": "analyseverfahren/slides.html#nullmodell-und-icc",
    "href": "analyseverfahren/slides.html#nullmodell-und-icc",
    "title": "Anwendungsorientierte Analyseverfahren",
    "section": "Nullmodell und ICC",
    "text": "Nullmodell und ICC\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nCoefficient\n95% CI\nt(10804)\np\nEffects\nGroup\nStd. Coef.\nFit\n\n\n\n\n(Intercept)\n14.34\n(9.23, 19.44)\n5.50\n&lt; .001\nfixed\n\n0.06\n\n\n\n\n16.71\n\n\n\nrandom\nuni\n\n\n\n\n\n33.32\n\n\n\nrandom\nResidual\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAICc\n\n\n\n\n\n\n\n106618.77\n\n\nR2 (conditional)\n\n\n\n\n\n\n\n0.20\n\n\nR2 (marginal)\n\n\n\n\n\n\n\n0.00\n\n\nSigma\n\n\n\n\n\n\n\n33.32\n\n\n\n\n\n\n\n\n16.71^2 / (16.71^2 + 33.32^2)\n\n[1] 0.2009607"
  },
  {
    "objectID": "analyseverfahren/slides.html#vorhergesagte-werte-uni-page",
    "href": "analyseverfahren/slides.html#vorhergesagte-werte-uni-page",
    "title": "Anwendungsorientierte Analyseverfahren",
    "section": "Vorhergesagte Werte (Uni-Page)",
    "text": "Vorhergesagte Werte (Uni-Page)\n\n\n\n\n\n\nuni\n\n\nestimate\n\n\nstd.error\n\n\nstatistic\n\n\np.value\n\n\nconf.low\n\n\nconf.high\n\n\ndf\n\n\n\n\n\n\nColumbia U\n\n\n2.33\n\n\n2.61\n\n\n0.89\n\n\n0.37\n\n\n-2.78\n\n\n7.44\n\n\nInf\n\n\n\n\nCornell U\n\n\n9.40\n\n\n2.61\n\n\n3.61\n\n\n0.00\n\n\n4.29\n\n\n14.51\n\n\nInf\n\n\n\n\nDuke U\n\n\n8.69\n\n\n2.61\n\n\n3.34\n\n\n0.00\n\n\n3.58\n\n\n13.80\n\n\nInf\n\n\n\n\nHarvard U\n\n\n66.38\n\n\n2.61\n\n\n25.48\n\n\n0.00\n\n\n61.27\n\n\n71.48\n\n\nInf\n\n\n\n\nImperial College London\n\n\n3.40\n\n\n2.61\n\n\n1.30\n\n\n0.19\n\n\n-1.71\n\n\n8.50\n\n\nInf\n\n\n\n\nJohns Hopkins U\n\n\n3.18\n\n\n2.61\n\n\n1.22\n\n\n0.22\n\n\n-1.92\n\n\n8.29\n\n\nInf\n\n\n\n\nMIT\n\n\n15.76\n\n\n2.61\n\n\n6.05\n\n\n0.00\n\n\n10.66\n\n\n20.87\n\n\nInf\n\n\n\n\nNew York U\n\n\n10.71\n\n\n2.61\n\n\n4.11\n\n\n0.00\n\n\n5.61\n\n\n15.82\n\n\nInf\n\n\n\n\nNorthwestern U\n\n\n7.88\n\n\n2.61\n\n\n3.03\n\n\n0.00\n\n\n2.78\n\n\n12.99\n\n\nInf\n\n\n\n\nPrinceton U\n\n\n5.63\n\n\n2.61\n\n\n2.16\n\n\n0.03\n\n\n0.53\n\n\n10.74\n\n\nInf"
  },
  {
    "objectID": "analyseverfahren/slides.html#varying-intercept-modell-topic-research",
    "href": "analyseverfahren/slides.html#varying-intercept-modell-topic-research",
    "title": "Anwendungsorientierte Analyseverfahren",
    "section": "Varying Intercept-Modell (Topic Research)",
    "text": "Varying Intercept-Modell (Topic Research)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nCoefficient\n95% CI\nt(10387)\np\nEffects\nGroup\nStd. Coef.\nFit\n\n\n\n\n(Intercept)\n15.57\n(10.48, 20.67)\n5.99\n&lt; .001\nfixed\n\n0.06\n\n\n\ntopic research\n-4.06\n(-5.53, -2.59)\n-5.42\n&lt; .001\nfixed\n\n-0.05\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAICc\n\n\n\n\n\n\n\n102577.73\n\n\nR2 (conditional)\n\n\n\n\n\n\n\n0.20\n\n\nR2 (marginal)\n\n\n\n\n\n\n\n0.00\n\n\nSigma\n\n\n\n\n\n\n\n33.41"
  },
  {
    "objectID": "analyseverfahren/slides.html#modellvorhersagen-varying-intercepts",
    "href": "analyseverfahren/slides.html#modellvorhersagen-varying-intercepts",
    "title": "Anwendungsorientierte Analyseverfahren",
    "section": "Modellvorhersagen (varying intercepts)",
    "text": "Modellvorhersagen (varying intercepts)"
  },
  {
    "objectID": "analyseverfahren/slides.html#varying-intercept-vs.-varying-slope-modell",
    "href": "analyseverfahren/slides.html#varying-intercept-vs.-varying-slope-modell",
    "title": "Anwendungsorientierte Analyseverfahren",
    "section": "Varying Intercept vs. Varying Slope-Modell",
    "text": "Varying Intercept vs. Varying Slope-Modell\n\n\n\n\n\n\n\n\nnpar\n\n\nAIC\n\n\nBIC\n\n\nlogLik\n\n\n-2*log(L)\n\n\nChisq\n\n\nDf\n\n\nPr(&gt;Chisq)\n\n\n\n\n\n\nm1_research\n\n\n4\n\n\n102582.7\n\n\n102611.7\n\n\n-51287.36\n\n\n102574.7\n\n\n\n\n\n\n\n\n\n\nm2_research_vs\n\n\n6\n\n\n102532.8\n\n\n102576.3\n\n\n-51260.39\n\n\n102520.8\n\n\n53.93\n\n\n2\n\n\n0"
  },
  {
    "objectID": "analyseverfahren/slides.html#varying-slopes-pro-uni-page",
    "href": "analyseverfahren/slides.html#varying-slopes-pro-uni-page",
    "title": "Anwendungsorientierte Analyseverfahren",
    "section": "Varying Slopes pro Uni-Page",
    "text": "Varying Slopes pro Uni-Page\n\n\n\n\n\n\nterm\n\n\nuni\n\n\nestimate\n\n\nstd.error\n\n\nstatistic\n\n\np.value\n\n\nconf.low\n\n\nconf.high\n\n\n\n\n\n\ntopic_research\n\n\nColumbia U\n\n\n-0.43\n\n\n1.22\n\n\n-0.35\n\n\n0.72\n\n\n-2.82\n\n\n1.96\n\n\n\n\ntopic_research\n\n\nCornell U\n\n\n-3.15\n\n\n1.22\n\n\n-2.58\n\n\n0.01\n\n\n-5.54\n\n\n-0.76\n\n\n\n\ntopic_research\n\n\nDuke U\n\n\n-2.72\n\n\n1.22\n\n\n-2.23\n\n\n0.03\n\n\n-5.11\n\n\n-0.33\n\n\n\n\ntopic_research\n\n\nHarvard U\n\n\n-24.59\n\n\n1.22\n\n\n-20.16\n\n\n0.00\n\n\n-26.98\n\n\n-22.20\n\n\n\n\ntopic_research\n\n\nImperial College London\n\n\n-0.91\n\n\n1.22\n\n\n-0.75\n\n\n0.45\n\n\n-3.30\n\n\n1.48\n\n\n\n\ntopic_research\n\n\nJohns Hopkins U\n\n\n-0.73\n\n\n1.22\n\n\n-0.60\n\n\n0.55\n\n\n-3.13\n\n\n1.66\n\n\n\n\ntopic_research\n\n\nMIT\n\n\n-5.51\n\n\n1.22\n\n\n-4.52\n\n\n0.00\n\n\n-7.90\n\n\n-3.12\n\n\n\n\ntopic_research\n\n\nNew York U\n\n\n-3.48\n\n\n1.22\n\n\n-2.85\n\n\n0.00\n\n\n-5.87\n\n\n-1.09\n\n\n\n\ntopic_research\n\n\nNorthwestern U\n\n\n-2.43\n\n\n1.22\n\n\n-1.99\n\n\n0.05\n\n\n-4.82\n\n\n-0.04\n\n\n\n\ntopic_research\n\n\nPrinceton U\n\n\n-1.67\n\n\n1.22\n\n\n-1.37\n\n\n0.17\n\n\n-4.07\n\n\n0.72"
  },
  {
    "objectID": "analyseverfahren/slides.html#modellvorhersagen-varying-slopes",
    "href": "analyseverfahren/slides.html#modellvorhersagen-varying-slopes",
    "title": "Anwendungsorientierte Analyseverfahren",
    "section": "Modellvorhersagen (varying slopes)",
    "text": "Modellvorhersagen (varying slopes)"
  },
  {
    "objectID": "analyseverfahren/slides.html#modell-mit-level-2-prädiktor",
    "href": "analyseverfahren/slides.html#modell-mit-level-2-prädiktor",
    "title": "Anwendungsorientierte Analyseverfahren",
    "section": "Modell mit Level-2-Prädiktor",
    "text": "Modell mit Level-2-Prädiktor\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nCoefficient\n95% CI\nt(10384)\np\nEffects\nGroup\nStd. Coef.\nFit\n\n\n\n\n(Intercept)\n10.88\n(6.56, 15.19)\n4.94\n&lt; .001\nfixed\n\n0.05\n\n\n\ntopic research\n-5.69\n(-8.35, -3.04)\n-4.21\n&lt; .001\nfixed\n\n-0.07\n\n\n\nuni fans\n0.01\n(0.01, 0.01)\n8.18\n&lt; .001\nfixed\n\n0.21\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAICc\n\n\n\n\n\n\n\n102509.01\n\n\nR2 (conditional)\n\n\n\n\n\n\n\n0.16\n\n\nR2 (marginal)\n\n\n\n\n\n\n\n0.05\n\n\nSigma\n\n\n\n\n\n\n\n33.32"
  },
  {
    "objectID": "analyseverfahren/slides.html#fazit-3",
    "href": "analyseverfahren/slides.html#fazit-3",
    "title": "Anwendungsorientierte Analyseverfahren",
    "section": "Fazit",
    "text": "Fazit\n\nin der Kommunikationswissenschaft sind geschachtelte Daten nahezu überall anzutreffen, sei es bei Inhaltsanalysen, Panel- oder Mehrländer-Befragungen\noft sind auch Personen die Level-2-Einheiten, z.B. bei Experience-Sampling-Daten oder Within-Subject-Experimenten\ndie Grundlogik der Multilevel-Analyse entspricht dem linearen Modell, lediglich die Art und Weise, die Schachtelung zu berücksichtigen, variiert\nwenn Verdacht auf Verletzung der Unabhängigkeitsannahme besteht, kann man immer zumindest ein Varying Intercept Modell schätzen, das nie “schlechter” als ein lineares Regressionsmodell ist\ntechnisch muss man in R (fast) nur lm() durch lmer() ersetzen und die Modellformel leicht anpassen (siehe praktische Übung)"
  },
  {
    "objectID": "analyseverfahren/slides.html#take-home-3",
    "href": "analyseverfahren/slides.html#take-home-3",
    "title": "Anwendungsorientierte Analyseverfahren",
    "section": "Take-Home #3",
    "text": "Take-Home #3\n\nin den Studien von Altay et al. (2022) haben ale TeilnehmerInnen mehrere Artikel bewertet\nUnabhängigkeit der Bewertungen ist damit klar verletzt, unsere Single-Level-Analysen eigentlich nicht korrekt\nder ICC ist mit .45 sehr groß, d.h. Bereitschaft, einen Beitrag zu teilen, hängt erheblich von der Person, nicht (nur) vom Beitrag ab\n\n\n\n\n\n\n\nICC_adjusted\n\n\nICC_unadjusted\n\n\noptional\n\n\n\n\n\n\n0.45\n\n\n0.45\n\n\nFALSE"
  },
  {
    "objectID": "analyseverfahren/slides.html#take-home-3---single-vs.-multilevel-modell",
    "href": "analyseverfahren/slides.html#take-home-3---single-vs.-multilevel-modell",
    "title": "Anwendungsorientierte Analyseverfahren",
    "section": "Take-Home #3 - Single vs. Multilevel Modell",
    "text": "Take-Home #3 - Single vs. Multilevel Modell\n\n\n\n\n \nShare\nShare\n\n\nPredictors\nEstimates\nCI\np\nEstimates\nCI\np\n\n\n(Intercept)\n2.23\n2.15 – 2.30\n&lt;0.001\n2.23\n2.11 – 2.35\n&lt;0.001\n\n\nType [TN]\n0.36\n0.26 – 0.46\n&lt;0.001\n0.34\n0.27 – 0.42\n&lt;0.001\n\n\nInteresting c\n0.38\n0.34 – 0.43\n&lt;0.001\n0.34\n0.30 – 0.37\n&lt;0.001\n\n\nType [TN] × Interesting c\n0.15\n0.08 – 0.21\n&lt;0.001\n0.14\n0.09 – 0.19\n&lt;0.001\n\n\nRandom Effects\n\n\n\nσ2\n \n1.04\n\n\n\nτ00\n \n0.92 Participants\n\n\nICC\n \n0.47\n\n\nN\n \n299 Participants\n\nObservations\n2990\n2990\n\n\nR2 / R2 adjusted\n0.206 / 0.205\n0.173 / 0.562"
  },
  {
    "objectID": "analyseverfahren/slides.html#take-home-3-1",
    "href": "analyseverfahren/slides.html#take-home-3-1",
    "title": "Anwendungsorientierte Analyseverfahren",
    "section": "Take-Home #3",
    "text": "Take-Home #3\n\nKoeffizienten sind sich im Multilevel-Modell praktisch gleich\nPräzision der Schätzung ist höher (kleinere Standardfehler, engere CI)\nwir haben aber zusätzlich erfahren, dass Sharing fast zur Hälfte von der Person abhängt\ndementsprechend kann man Follow-Up-Studien oder Interventionen planen"
  },
  {
    "objectID": "analyseverfahren/slides.html#literatur-1",
    "href": "analyseverfahren/slides.html#literatur-1",
    "title": "Anwendungsorientierte Analyseverfahren",
    "section": "Literatur",
    "text": "Literatur\n\n\n\n\nAuty, S., & Lewis, C. (2004). Exploring children’s choice: The reminder effect of product placement. Psychology & Marketing, 21(9), 697–713. https://doi.org/10.1002/mar.20025\n\n\nFestl, R., Scharkow, M., & Quandt, T. (2013). Peer Influence, Internet use and Cyberbullying: A Comparison of Different Context Effects among German Adolescents. Journal of Children and Media, 7(4), 446–462. https://doi.org/10.1080/17482798.2013.781514\n\n\nJohannes, N., Dienlin, T., Bakhshi, H., & Przybylski, A. K. (2022). No effect of different types of media on well-being. Scientific Reports, 12(1), 61.\n\n\nKümpel, A. S. (2019). Getting Tagged, Getting Involved with News? A Mixed-Methods Investigation of the Effects and Motives of News-Related Tagging Activities on Social Network Sites. Journal of Communication, 69(4), 373–395. https://doi.org/10.1093/joc/jqz019\n\n\nVan Erkel, P. F., & Van Aelst, P. (2021). Why don’t we learn from social media? Studying effects of and mechanisms behind social media news use on general surveillance political knowledge. Political Communication, 38(4), 407–425. https://doi.org/10.1080/10584609.2020.1784328\n\n\nVögele, C., & Bachl, M. (2017). Der Einfluss des Dialekts auf die Bewertung von Politikern. Studies in Communication | Media, 6(2), 196–215. https://doi.org/10.5771/2192-4007-2017-2-196"
  },
  {
    "objectID": "inhaltsanalyse/slides.html#lernziele",
    "href": "inhaltsanalyse/slides.html#lernziele",
    "title": "Inhaltsanalyse: Inhalte öffentlicher Kommunikation",
    "section": "Lernziele",
    "text": "Lernziele\n\nWie führen wir ein Forschungsprojekt durch?\nWie koordinieren und managen wir ein komplexes Projekt mit mehren Mitarbeitern unter Zeitdruck? (Projektmanagement)\nWie präsentieren wir Projektfortschritte, Forschungsprozesse und Forschungsergebnisse?\nWie geben wir konstruktives Feedback im Forschungsprozess? Wie nehmen wir Feedback an und setzen es um?\nSpaß haben in der Forschung!"
  },
  {
    "objectID": "inhaltsanalyse/slides.html#warum-computational-methods",
    "href": "inhaltsanalyse/slides.html#warum-computational-methods",
    "title": "Inhaltsanalyse: Inhalte öffentlicher Kommunikation",
    "section": "Warum Computational Methods?",
    "text": "Warum Computational Methods?\n\nmein Lehr- und Forschungsbereich\nhohe Nachfrage in der Kommunikationswissenschaft\nrelevante Skills in vielen Jobs außerhalb der Wissenschaft (Data Science, Journalismus, Marktforschung)\nZiel ist vor allem Verständnis der Grundlagen und Dinge ausprobieren"
  },
  {
    "objectID": "inhaltsanalyse/slides.html#inhalt",
    "href": "inhaltsanalyse/slides.html#inhalt",
    "title": "Inhaltsanalyse: Inhalte öffentlicher Kommunikation",
    "section": "Inhalt",
    "text": "Inhalt\n\n\n\n\n\n\n\n\n\nSitzung\n\n\nDatum\n\n\nThema\n\n\n\n\n\n\n1\n\n\n25.10.2024\n\n\nEinführung und Grundlagen\n\n\n\n\n2\n\n\n08.11.2024\n\n\nCCS: Inhaltsanalyse mit LLM\n\n\n\n\n3\n\n\n15.11.2024\n\n\nThemenwahl und Forschungsfragen\n\n\n\n\n4\n\n\n22.11.2024\n\n\nStudiendesign und Stichprobe*\n\n\n\n\n5\n\n\n29.11.2024\n\n\nCCS: Datenerhebung\n\n\n\n\n6\n\n\n06.12.2024\n\n\nKategorien und Codierung*\n\n\n\n\n7\n\n\n13.12.2024\n\n\nCCS: Reli-Test und Validierung*\n\n\n\n\n8\n\n\n20.12.2024\n\n\nCodebuch-Finalisierung (Sprechstunde)\n\n\n\n\n9\n\n\n10.01.2025\n\n\nFeldphase (Sprechstunde)\n\n\n\n\n10\n\n\n17.01.2025\n\n\nDatenanalyse und -visualisierung*\n\n\n\n\n11\n\n\n24.01.2025\n\n\nErgebnisaufbereitung\n\n\n\n\n12\n\n\n31.01.2025\n\n\nAbschluss"
  },
  {
    "objectID": "inhaltsanalyse/slides.html#literatur",
    "href": "inhaltsanalyse/slides.html#literatur",
    "title": "Inhaltsanalyse: Inhalte öffentlicher Kommunikation",
    "section": "Literatur",
    "text": "Literatur"
  },
  {
    "objectID": "inhaltsanalyse/slides.html#leistungen",
    "href": "inhaltsanalyse/slides.html#leistungen",
    "title": "Inhaltsanalyse: Inhalte öffentlicher Kommunikation",
    "section": "Leistungen",
    "text": "Leistungen\nAktive Teilnahme\n\naktive Mitarbeit in einer Arbeitsgruppe\n1 Gruppenbericht zum Stand der Arbeit\n3 Hausaufgaben zu CCS-Sitzungen\n\nPrüfungsleistung\n\nProjektbericht als Gruppenhausarbeit"
  },
  {
    "objectID": "inhaltsanalyse/slides.html#studentische-arbeitsgruppen",
    "href": "inhaltsanalyse/slides.html#studentische-arbeitsgruppen",
    "title": "Inhaltsanalyse: Inhalte öffentlicher Kommunikation",
    "section": "Studentische Arbeitsgruppen",
    "text": "Studentische Arbeitsgruppen\n\ni.d.R. 4 Studierende pro Gruppe (= max. 5 Gruppen im Seminar)\n‚Learning by doing’ in der AG\nvon anderen AGs lernen über andere Methoden, Themen und Arbeitsweisen\nLernen von Feedback zur eigenen Arbeit und der Arbeit der anderen AGs"
  },
  {
    "objectID": "inhaltsanalyse/slides.html#gruppenberichte",
    "href": "inhaltsanalyse/slides.html#gruppenberichte",
    "title": "Inhaltsanalyse: Inhalte öffentlicher Kommunikation",
    "section": "Gruppenberichte",
    "text": "Gruppenberichte\n\njedes Gruppenmitglied ist federführend für einen Bericht\nProtokollierung des Diskussionsprozesse in der AG seit dem letzen Bericht\nVorbereitung einer zusammenfassenden Kurzpräsentation (5 min) mit 2-3 Folien\nUpload der Folien spätestens Fr, 8h in Moodle\nalle anderen geben Feedback für eigene und andere AG"
  },
  {
    "objectID": "inhaltsanalyse/slides.html#sitzungen-zu-ccs",
    "href": "inhaltsanalyse/slides.html#sitzungen-zu-ccs",
    "title": "Inhaltsanalyse: Inhalte öffentlicher Kommunikation",
    "section": "Sitzungen zu CCS",
    "text": "Sitzungen zu CCS\n\nInverted Classroom, d.h. verpflichtende Vorbereitung https://stats.ifp.uni-mainz.de/ba-ccs-track/\nHausaufgaben für jede CCS-Sitzung, Abgabe jeweils Do, 12h in Moodle\neigenes Notebook zu den praktischen Sitzungen mitbringen\nwir verwenden R und RStudio, https://rstudio.ifp.uni-mainz.de\ngern paarweise arbeiten, das hilft in der Sitzung und macht mehr Spaß"
  },
  {
    "objectID": "inhaltsanalyse/slides.html#hausarbeiten",
    "href": "inhaltsanalyse/slides.html#hausarbeiten",
    "title": "Inhaltsanalyse: Inhalte öffentlicher Kommunikation",
    "section": "Hausarbeiten",
    "text": "Hausarbeiten\n\nGruppenhausarbeit als Modulprüfung\nmaximal (!) 10 Seiten pro Gruppenmitglied, max. 10.000 Wörter insgesamt\nDokumentation der eigenen Arbeit, d.h. Gruppenberichte können recycled werden\nes muss nichts “rauskommen”, außer dass sie etwas gelernt haben\nFormalien und Regeln wissenschaftlicher Arbeit sind wichtig und notenrelevant"
  },
  {
    "objectID": "inhaltsanalyse/slides.html#aufgabe",
    "href": "inhaltsanalyse/slides.html#aufgabe",
    "title": "Inhaltsanalyse: Inhalte öffentlicher Kommunikation",
    "section": "Aufgabe",
    "text": "Aufgabe\nhttps://sosci.zdv.uni-mainz.de/ia_btw2021/\n\nCodieren Sie politische TikTok-Inhalte zunächst alleine in verschiedenen Formaten.\nWas ist Ihnen beim Codieren aufgefallen? Was war einfach, was schwierig?"
  },
  {
    "objectID": "inhaltsanalyse/slides.html#definitionen",
    "href": "inhaltsanalyse/slides.html#definitionen",
    "title": "Inhaltsanalyse: Inhalte öffentlicher Kommunikation",
    "section": "Definitionen",
    "text": "Definitionen\n„Content analysis is a research technique for the objective, systematic, and quantitative description of the manifest content of communication.” (Berelson 1952, S. 18)\n„Die Inhaltsanalyse ist eine empirische Methode zur systematischen, intersubjektiv nachvollziehbaren Beschreibung inhaltlicher und formaler Merkmale von Mitteilungen” (Früh, 1998, S.24)\n“Content analysis is a research technique for making replicable and valid inferences from texts (or other meaningful matter) to the contexts of their use.” (Krippendorff, 2004, S. 18)"
  },
  {
    "objectID": "inhaltsanalyse/slides.html#theorie-der-inhaltsanalyse---inferenzen",
    "href": "inhaltsanalyse/slides.html#theorie-der-inhaltsanalyse---inferenzen",
    "title": "Inhaltsanalyse: Inhalte öffentlicher Kommunikation",
    "section": "Theorie der Inhaltsanalyse - Inferenzen",
    "text": "Theorie der Inhaltsanalyse - Inferenzen\n\nQuelle: Früh, 2007"
  },
  {
    "objectID": "inhaltsanalyse/slides.html#aufgabe-1",
    "href": "inhaltsanalyse/slides.html#aufgabe-1",
    "title": "Inhaltsanalyse: Inhalte öffentlicher Kommunikation",
    "section": "Aufgabe",
    "text": "Aufgabe\nDiskutieren Sie in Paaren, wie nach Benoit et al. (2009) politische Positionen zu Aussagen werden, und welche Inferenzen wir durch Analysen dieser Aussagen ziehen können."
  },
  {
    "objectID": "inhaltsanalyse/slides.html#aufgabe-2",
    "href": "inhaltsanalyse/slides.html#aufgabe-2",
    "title": "Inhaltsanalyse: Inhalte öffentlicher Kommunikation",
    "section": "Aufgabe",
    "text": "Aufgabe\nEs soll Sexismus in Social Media Posts dichotom codiert werden (ja/nein).\n\nEntwerfen Sie eine kurze (1-3 Sätze) Codieranweisung auf englisch.\nTauschen Sie die Codieranweisung mit Ihrer Sitznachbarin aus.\nCodieren Sie die 5 Aussagen auf der nächsten Seite mit Hilfe der Codieranweisung.\nNutzen Sie eine KI (ChatGPT, Gemini, Copilot) und lassen Sie diese dieselben 5 Aussagen codieren.\nNotieren Sie Ihre und die KI-basierten Codierentscheidungen."
  },
  {
    "objectID": "inhaltsanalyse/slides.html#posts",
    "href": "inhaltsanalyse/slides.html#posts",
    "title": "Inhaltsanalyse: Inhalte öffentlicher Kommunikation",
    "section": "Posts",
    "text": "Posts\n\n\n\n\n\n\n\n\n\n\nid\ntext\n\n\n\n\n1\nAnd toxic masculinity is actually a byproduct of toxic femininity.\n\n\n2\nIs he working on stuff too? Ask her where she goes to school, what she plans to study, etc. She’ll ask you the same questions in return if she’s interested.\n\n\n3\nThis is coming from the bitch who once flashed a teacher to distract him so her boyfriend could sneak out of detention. God the bitch used to be so much cooler.\n\n\n4\nHoly fucking shit dude. Fuck this bitch. Seriously. OP, I wish I could say I feel your pain but I don’t. All I can say is I hope you pull through it all. I fully believe in karma and it is a bigger bitch than this woman.\n\n\n5\nPeople have no problems with a female lead. They got problems with them shoving down bullshit PC/SJW down their throats. Disney already ruined Star Wars Marvel is just next on the list."
  },
  {
    "objectID": "inhaltsanalyse/slides.html#zero-shot-codierung",
    "href": "inhaltsanalyse/slides.html#zero-shot-codierung",
    "title": "Inhaltsanalyse: Inhalte öffentlicher Kommunikation",
    "section": "Zero-Shot-Codierung",
    "text": "Zero-Shot-Codierung\n\nLarge Language Models (umgangssprachlich oft KI) können verschiedene sprachliche Aufgaben “lösen”, u.a. auch inhaltsanalytische\nda die Modelle dafür nicht extra angepasst werden müssen, spricht man von Zero-Shot-Codierung\nim Gegensatz zu älteren automatischen Verfahren braucht es (fast) keine Umstellung gegenüber manuellem Codieren\nzahlreiche aktuelle Studien untersuchen, ob man manuelle Codierung durch LLM-basierte ersetzen kann\nob und wie gut man eigene Kategorien mit LLM codieren kann, muss man ausprobieren (und machen wir)"
  },
  {
    "objectID": "inhaltsanalyse/slides.html#hausaufgaben",
    "href": "inhaltsanalyse/slides.html#hausaufgaben",
    "title": "Inhaltsanalyse: Inhalte öffentlicher Kommunikation",
    "section": "Hausaufgaben",
    "text": "Hausaufgaben\n\nhttps://stats.ifp.uni-mainz.de/ba-ccs-track/ia-zeroshot.html selbständig durcharbeiten\nHausaufgabe (Abgabe Do, 12h, Moodle)\nLektüre: Törnberg (2023)"
  },
  {
    "objectID": "inhaltsanalyse/slides.html#ha-zero-shot-codierung",
    "href": "inhaltsanalyse/slides.html#ha-zero-shot-codierung",
    "title": "Inhaltsanalyse: Inhalte öffentlicher Kommunikation",
    "section": "HA Zero-Shot-Codierung",
    "text": "HA Zero-Shot-Codierung\n\nWie hat unser Beispielcode funktioniert?\nWie haben Sie die Aufgaben gelöst?\nWie kann man größere Mengen an Codierungen automatisch durchführen?"
  },
  {
    "objectID": "inhaltsanalyse/slides.html#wie-funktioniert-ein-neuronales-netz",
    "href": "inhaltsanalyse/slides.html#wie-funktioniert-ein-neuronales-netz",
    "title": "Inhaltsanalyse: Inhalte öffentlicher Kommunikation",
    "section": "Wie funktioniert ein Neuronales Netz?",
    "text": "Wie funktioniert ein Neuronales Netz?\n\nhttps://medium.com/data-science-365/overview-of-a-neural-networks-learning-process-61690a502fa"
  },
  {
    "objectID": "inhaltsanalyse/slides.html#was-sind-transformer-modelle",
    "href": "inhaltsanalyse/slides.html#was-sind-transformer-modelle",
    "title": "Inhaltsanalyse: Inhalte öffentlicher Kommunikation",
    "section": "Was sind Transformer Modelle",
    "text": "Was sind Transformer Modelle\n\nExplainer: https://ig.ft.com/generative-ai/"
  },
  {
    "objectID": "inhaltsanalyse/slides.html#multimodale-embeddings-clip",
    "href": "inhaltsanalyse/slides.html#multimodale-embeddings-clip",
    "title": "Inhaltsanalyse: Inhalte öffentlicher Kommunikation",
    "section": "Multimodale Embeddings: CLIP",
    "text": "Multimodale Embeddings: CLIP\n\nhttps://openai.com/index/clip/"
  },
  {
    "objectID": "inhaltsanalyse/slides.html#wie-funktioniert-chatgpt",
    "href": "inhaltsanalyse/slides.html#wie-funktioniert-chatgpt",
    "title": "Inhaltsanalyse: Inhalte öffentlicher Kommunikation",
    "section": "Wie funktioniert ChatGPT?",
    "text": "Wie funktioniert ChatGPT?\n\nhttps://openai.com/blog/chatgpt"
  },
  {
    "objectID": "inhaltsanalyse/slides.html#aufgabe-prompting-strategien",
    "href": "inhaltsanalyse/slides.html#aufgabe-prompting-strategien",
    "title": "Inhaltsanalyse: Inhalte öffentlicher Kommunikation",
    "section": "Aufgabe: Prompting-Strategien",
    "text": "Aufgabe: Prompting-Strategien\n\nWorin unterscheiden sich Zero-Shot-, Few-Shot- und Chain-of-Thought-Strategien für die Codierung? (vgl. Weber & Reichardt, 2024)\nEntwickeln Sie für die Hausaufgabe zur Codierung Studierende je einen Prompt-Typ und testen Sie diese.\n(Wie) funktioniert dies bei der Bildklassifikation?"
  },
  {
    "objectID": "inhaltsanalyse/slides.html#vor--und-nachteile-der-llm-codierung",
    "href": "inhaltsanalyse/slides.html#vor--und-nachteile-der-llm-codierung",
    "title": "Inhaltsanalyse: Inhalte öffentlicher Kommunikation",
    "section": "Vor- und Nachteile der LLM-Codierung",
    "text": "Vor- und Nachteile der LLM-Codierung\n\nPrompts ähneln manuellen Codieranweisungen (+ etwas Prompt Engineering)\nLLM können Codierentscheidung und Begründungen liefern\nviele verschiedene kommerzielle und freie LLM sind verfügbar, Ensemble Codierung möglich\nnicht alles lässt sich leicht per LLM codieren (z.B. einfach Personen zählen)\nkommerzielle LLM kosten Geld pro Abfrage und haben ggf. Guardrails, die die Codierung verhindern bzw. erschweren\ndie Nutzung von LLM ist datenschutzrechtlich und ethisch bedenklich\nmultimodalle LLM sind aktuell noch sehr neu und ungetestet\nvalidieren, validieren, validieren!"
  },
  {
    "objectID": "inhaltsanalyse/slides.html#aufgabe-codepläne-in-aktueller-forschung",
    "href": "inhaltsanalyse/slides.html#aufgabe-codepläne-in-aktueller-forschung",
    "title": "Inhaltsanalyse: Inhalte öffentlicher Kommunikation",
    "section": "Aufgabe: Codepläne in aktueller Forschung",
    "text": "Aufgabe: Codepläne in aktueller Forschung\n\nIn Moodle sind 15 Titelseiten plus Codepläne aus aktuelleren Publikationen abgelegt.\nSuchen Sie einen oder mehrere interessante Artikel aus und versuchen probehalber einige oder alle dort codierten Kategorien einmal anzuwenden.\nLaden Sie sich dafür exemplarisch Texte oder Bilder aus dem Internet und codieren Sie diese (a) manuell und (b) mit Hilfe von LLM."
  },
  {
    "objectID": "inhaltsanalyse/slides.html#hausaufgaben-1",
    "href": "inhaltsanalyse/slides.html#hausaufgaben-1",
    "title": "Inhaltsanalyse: Inhalte öffentlicher Kommunikation",
    "section": "Hausaufgaben",
    "text": "Hausaufgaben\n\nBilden Sie Arbeitsgruppen (à 4 Personen) und entwickeln Sie erste Themenideen (ca. 1-3 Themen).\nBringen Sie die Themenideen als kurze Pitches samt Forschungsfrage(n) mit."
  },
  {
    "objectID": "inhaltsanalyse/slides.html#noch-einmal-inferenzen",
    "href": "inhaltsanalyse/slides.html#noch-einmal-inferenzen",
    "title": "Inhaltsanalyse: Inhalte öffentlicher Kommunikation",
    "section": "Noch einmal: Inferenzen",
    "text": "Noch einmal: Inferenzen\n\nFrüh, 2007"
  },
  {
    "objectID": "inhaltsanalyse/slides.html#was-ist-eine-gute-forschungsfrage",
    "href": "inhaltsanalyse/slides.html#was-ist-eine-gute-forschungsfrage",
    "title": "Inhaltsanalyse: Inhalte öffentlicher Kommunikation",
    "section": "Was ist eine gute Forschungsfrage?",
    "text": "Was ist eine gute Forschungsfrage?\n\nEine Forschungsfrage ist eine Frage!\nEine Forschungsfrage lässt sich empirisch beantworten, am besten mit der eigenen Inhaltsanalyse.\nEine Forschungsfrage ist weder zu allgemein noch zu spezifisch.\nEine Forschungsfrage hat oft eine (implizite oder explizite) Vergleichsdimension.\nInhaltliche und methodische Forschungsfragen sind gleich relevant."
  },
  {
    "objectID": "inhaltsanalyse/slides.html#was-ist-eine-gute-hypothese",
    "href": "inhaltsanalyse/slides.html#was-ist-eine-gute-hypothese",
    "title": "Inhaltsanalyse: Inhalte öffentlicher Kommunikation",
    "section": "Was ist eine gute Hypothese?",
    "text": "Was ist eine gute Hypothese?\n\nEine Hypothese ist empirisch falsifizierbar, und es muss klar sein, wann sie falsifiziert ist.\nEine Hypothese ist klar und widerspruchsfrei formuliert.\nEine Hypothese ist einfach, komplexe Hypothesen sollten in einfache Hypothesen zerlegt werden.\nEs ist nicht schlimm, sich widersprechende Hypothesen zu formulieren (H1a vs H1b).\nEine Nullhypothese ist selten eine interessante Hypothese, und oft nicht leicht zu prüfen."
  },
  {
    "objectID": "inhaltsanalyse/slides.html#woher-bekommt-man-gute-hypothesen",
    "href": "inhaltsanalyse/slides.html#woher-bekommt-man-gute-hypothesen",
    "title": "Inhaltsanalyse: Inhalte öffentlicher Kommunikation",
    "section": "Woher bekommt man gute Hypothesen?",
    "text": "Woher bekommt man gute Hypothesen?\n\nexistierende Theorien mit klaren Annahmen\nexistierende empirische Befunde (auch bei mehrdeutiger Ergebnislage)\neigene Herleitung aus plausiblen, begründeten Annahmen\nnicht: 3 Sätze Alltagserfahrung"
  },
  {
    "objectID": "inhaltsanalyse/slides.html#begriffsarbeit",
    "href": "inhaltsanalyse/slides.html#begriffsarbeit",
    "title": "Inhaltsanalyse: Inhalte öffentlicher Kommunikation",
    "section": "Begriffsarbeit",
    "text": "Begriffsarbeit\n\nQuelle: Kromrey et al. (2016)"
  },
  {
    "objectID": "inhaltsanalyse/slides.html#aufgaben-bis-nächste-woche",
    "href": "inhaltsanalyse/slides.html#aufgaben-bis-nächste-woche",
    "title": "Inhaltsanalyse: Inhalte öffentlicher Kommunikation",
    "section": "Aufgaben bis nächste Woche",
    "text": "Aufgaben bis nächste Woche\n\nRecherchieren sie relevante Literatur zu ihrem Thema.\nFormulieren sie (eher allgemeine) 1-2 Forschungsfragen.\nStellen sie 3-5 (eher konkrete) Hypothesen auf (mit Begründung!).\nUnterziehen Sie die für Ihre Studie relevanten Konstrukte einer dimensionalen und semantischen Analyse."
  },
  {
    "objectID": "inhaltsanalyse/slides.html#forschungsdesign",
    "href": "inhaltsanalyse/slides.html#forschungsdesign",
    "title": "Inhaltsanalyse: Inhalte öffentlicher Kommunikation",
    "section": "Forschungsdesign",
    "text": "Forschungsdesign\n\ndie Grundlagen fast aller empirischen Untersuchungen ist der Vergleich\nbei der Inhaltsanalyse typische Vergleiche:\n\nverschiedene Medienangebote oder Plattformen\nverschiedene Kommunikatoren\nverschiedene Messzeitpunkte\n\nmehr als zwei Vergleichsdimensionen machen die Analyse und Ergebnisdarstellung oft komplex"
  },
  {
    "objectID": "inhaltsanalyse/slides.html#einheiten-der-inhaltsanalyse",
    "href": "inhaltsanalyse/slides.html#einheiten-der-inhaltsanalyse",
    "title": "Inhaltsanalyse: Inhalte öffentlicher Kommunikation",
    "section": "Einheiten der Inhaltsanalyse",
    "text": "Einheiten der Inhaltsanalyse\n\nAuswahleinheit\nUntersuchungseinheit\nAnalyseeinheit\nCodiereinheit\nKontexteinheit"
  },
  {
    "objectID": "inhaltsanalyse/slides.html#auswahl-vs.-analyseeinheit",
    "href": "inhaltsanalyse/slides.html#auswahl-vs.-analyseeinheit",
    "title": "Inhaltsanalyse: Inhalte öffentlicher Kommunikation",
    "section": "Auswahl vs. Analyseeinheit",
    "text": "Auswahl vs. Analyseeinheit\nAuswahleinheit\n\nalle vorliegende Materialen, die aus dem gesamten Spektrum verfügbaren Medienmaterials für die Untersuchung ausgewählt werden\n\nBeispiel: Facebook-Posts der IfP-Seite (inkl. dazugehöriger Kommentare)\n\n\nAnalyseeinheit\n\nEinheit, auf die man sich bei der Interpretation beziehen will und für die ein Codebogen angelegt wird\n\nz.B. Beitrag, Foto, Absatz oder Aussage"
  },
  {
    "objectID": "inhaltsanalyse/slides.html#analyseeinheit-aussage-oder-beitrag",
    "href": "inhaltsanalyse/slides.html#analyseeinheit-aussage-oder-beitrag",
    "title": "Inhaltsanalyse: Inhalte öffentlicher Kommunikation",
    "section": "Analyseeinheit: Aussage oder Beitrag?",
    "text": "Analyseeinheit: Aussage oder Beitrag?\nBeitrag\n\nweniger aufwändig, aber ungenauer\nentspricht eher dem Verständnis der Rezipienten, weil sie aller Wahrscheinlichkeit nicht jede Aussage wahrnehmen und behalten\n\nAussage\n\nsehr aufwändig, aber ggf. genauer\nggf. enthalten Beiträge unterschiedliche Aussagen, die man berücksichtigen will\nHerausforderung: reliable Identifikation derselben Aussagen"
  },
  {
    "objectID": "inhaltsanalyse/slides.html#stichprobenziehung",
    "href": "inhaltsanalyse/slides.html#stichprobenziehung",
    "title": "Inhaltsanalyse: Inhalte öffentlicher Kommunikation",
    "section": "Stichprobenziehung",
    "text": "Stichprobenziehung\nGrundgesamtheit\n\nAlle Botschaften (Artikel, Beiträge usw.), über die die Studie etwas aussagen soll\nAuswahl der Grundgesamtheit setzt sich zusammen aus Auswahl der Medien und Auswahl des Untersuchungszeitraums\n\nAuswahlverfahren bei der Stichprobenbildung\n\nVollerhebung (alle Einheiten)\nZufallsauswahl (z.B. mehrstufig)\nnicht zufallsgesteuert (willkürliche, typische Fälle)"
  },
  {
    "objectID": "inhaltsanalyse/slides.html#stichprobenpraxis",
    "href": "inhaltsanalyse/slides.html#stichprobenpraxis",
    "title": "Inhaltsanalyse: Inhalte öffentlicher Kommunikation",
    "section": "Stichprobenpraxis",
    "text": "Stichprobenpraxis\n\noft werden Inhalte in einer mehrstufigen Auswahl gezogen\nnicht auf allen Stufen ist derselbe Auswahlmechnismus nötig oder sinnvoll\nBeispiel:\n\nAuswahl von Politikeraccounts auf Instagram (gezielte Auswahl)\nAuswahl von 100 zufälligen Beiträgen aus 2019 (einfache Zufallsstichprobe)\nAuswahl jedes 5. Nutzerkommentars (bis zu 20) (systematsche Zufallsstichprobe)"
  },
  {
    "objectID": "inhaltsanalyse/slides.html#stichproben-und-inferenzschlüsse",
    "href": "inhaltsanalyse/slides.html#stichproben-und-inferenzschlüsse",
    "title": "Inhaltsanalyse: Inhalte öffentlicher Kommunikation",
    "section": "Stichproben und Inferenzschlüsse",
    "text": "Stichproben und Inferenzschlüsse\n\ndie Auswahl der Untersuchungseinheiten bestimmt, welche Inferenzschlüsse man ziehen kann\nstreng genommen sind statistische Inferenzen nur für Zufallsstichproben möglich\nFür welche zusätzlichen (unbekannten) Untersuchungseinheiten können wir Voraussagen treffen?\nBeispiel:\n\nSie finden stat. signifikante Unterschiede zwischen Posts der offiziellen SPD- und FDP-Twitter-Accounts im Oktober 2019\nAuf was beziehen sich Ihre Inferenzen?"
  },
  {
    "objectID": "inhaltsanalyse/slides.html#stichprobenumfang",
    "href": "inhaltsanalyse/slides.html#stichprobenumfang",
    "title": "Inhaltsanalyse: Inhalte öffentlicher Kommunikation",
    "section": "Stichprobenumfang",
    "text": "Stichprobenumfang\n\nje größer die Stichprobe, desto präziser die Schätzung\nStichprobenumfang hat nichts mit Repräsentativität zu tun"
  },
  {
    "objectID": "inhaltsanalyse/slides.html#beschaffung-des-materials",
    "href": "inhaltsanalyse/slides.html#beschaffung-des-materials",
    "title": "Inhaltsanalyse: Inhalte öffentlicher Kommunikation",
    "section": "Beschaffung des Materials",
    "text": "Beschaffung des Materials\n\nWoher bekomme ich die Inhalte?\ntechnische Schwierigkeiten, z.B. zuverlässiges Speichern der Inhalte\nrechtliche Schwierigkeiten, z.B. Verbot in Terms of Services\nWelche Teile (Text, Bild, Video, etc.) des Beitrags werden zur Codierung benötigt?\nKann ich die Inhalte automatisch speichern und verarbeiten?"
  },
  {
    "objectID": "inhaltsanalyse/slides.html#aufgaben-bis-zur-nächsten-sitzung",
    "href": "inhaltsanalyse/slides.html#aufgaben-bis-zur-nächsten-sitzung",
    "title": "Inhaltsanalyse: Inhalte öffentlicher Kommunikation",
    "section": "Aufgaben bis zur nächsten Sitzung",
    "text": "Aufgaben bis zur nächsten Sitzung\n\nLesen Sie Datenerhebung in R\nLösen Sie die Hausaufgaben 1 und 2 in R\nWenn Sie Firefox installiert haben: Bitte Zeeschuimer Erweiterung installieren https://github.com/digitalmethodsinitiative/zeeschuimer/releases/download/v1.11.1/zeeschuimer-v1.11.1.xpi"
  },
  {
    "objectID": "inhaltsanalyse/slides.html#aufgaben-bis-zur-übernächsten-sitzung",
    "href": "inhaltsanalyse/slides.html#aufgaben-bis-zur-übernächsten-sitzung",
    "title": "Inhaltsanalyse: Inhalte öffentlicher Kommunikation",
    "section": "Aufgaben bis zur übernächsten Sitzung",
    "text": "Aufgaben bis zur übernächsten Sitzung\n\nFinalisieren Sie die Forschungsfragen und Hypothesen.\nDiskutieren und finalisieren Sie das Untersuchungsdesign Ihrer Studie.\nDefinieren Sie Untersuchungseinheit(en) und Grundgesamtheit.\nEntwickeln Sie einen konzeptionell angemessenen Stichprobenplan.\nÜberlegen Sie, wie die Stichprobenziehung praktisch umgesetzt werden kann."
  },
  {
    "objectID": "inhaltsanalyse/slides.html#erhebung-von-inhalten-für-inhaltsanalysen",
    "href": "inhaltsanalyse/slides.html#erhebung-von-inhalten-für-inhaltsanalysen",
    "title": "Inhaltsanalyse: Inhalte öffentlicher Kommunikation",
    "section": "Erhebung von Inhalten für Inhaltsanalysen",
    "text": "Erhebung von Inhalten für Inhaltsanalysen\n\nsehr viele Text- und Bild-Inhalte sind digital (und online) vorhanden, aber Zugang für wissenschaftliche Zwecke oft problembehaftet\nProblem 1: Vollständigkeit, z.B. durch selektive Rechtevergabe oder technische Zugangsbarrieren im Archiv\nProblem 2: Rechtslage/Copyright, wobei Forschung und Lehre stark priviligiert sind\nProblem 3: Ethische Fragen, etwa ob Individuen Schaden bei der Erhebung ersteht oder Zustimmung der Betroffenen vorliegt\nProblem 4: Praktische und methodische Fragen, etwa wie man möglichst zuverlässig Inhalte erheben kann"
  },
  {
    "objectID": "inhaltsanalyse/slides.html#online-archive-traditioneller-medien",
    "href": "inhaltsanalyse/slides.html#online-archive-traditioneller-medien",
    "title": "Inhaltsanalyse: Inhalte öffentlicher Kommunikation",
    "section": "Online-Archive traditioneller Medien",
    "text": "Online-Archive traditioneller Medien\n\nseitens der Anbieter, z.B. SPIEGEL oder ZEIT Archiv, Tagesschau Sendungsarchiv\nkommerzielle Datenbanken, z.B. LexisNexis oder Factiva\nGDELT (Global Database of Events, Language and Tone) und Mediacloud als riesige, nicht-kommerzielle Datenbanken (ohne Volltexte)\nNewsAPI als kommerzielle Datenbank mit einfachem Zugriff, aber limitiertem (kostenlosen) Zugang"
  },
  {
    "objectID": "inhaltsanalyse/slides.html#social-media-plattformen",
    "href": "inhaltsanalyse/slides.html#social-media-plattformen",
    "title": "Inhaltsanalyse: Inhalte öffentlicher Kommunikation",
    "section": "Social Media Plattformen",
    "text": "Social Media Plattformen\n\nfast alle großen Social Media Plattformen mit eigenen durchsuchbaren Archiven\nhohe technische Hürden gegen automatisierte Erhebung im großen Stil (Mastodon &gt; TikTok &gt; Facebook/Instagram)\nhohes Risiko, dass gerade noch funktionierende Zugänge kurzfristig nicht verfügbar sind\nAlternative zur anbieterseitigen Erhebung: Data Donation"
  },
  {
    "objectID": "inhaltsanalyse/slides.html#mobile-apps-und-andere-geschlossene-systeme",
    "href": "inhaltsanalyse/slides.html#mobile-apps-und-andere-geschlossene-systeme",
    "title": "Inhaltsanalyse: Inhalte öffentlicher Kommunikation",
    "section": "Mobile Apps und andere geschlossene Systeme",
    "text": "Mobile Apps und andere geschlossene Systeme\n\ntechnisch extrem schwierig zu erheben durch Sandboxing auf Android/iOS\nAlternative 1: Überwachung und Mitschnitt von Netzwerk-Traffic\nAlternative 2: Data Donations von NutzerInnen, z.B. in Form von Screenshots (u.a. Screenome Project)"
  },
  {
    "objectID": "inhaltsanalyse/slides.html#datenerhebung-mit-r",
    "href": "inhaltsanalyse/slides.html#datenerhebung-mit-r",
    "title": "Inhaltsanalyse: Inhalte öffentlicher Kommunikation",
    "section": "Datenerhebung mit R",
    "text": "Datenerhebung mit R\nMöglichkeiten, aufsteigend vom leichtesten zum schwierigsten\n\nmaschinenlesbaren Dateien direkt aus dem WWW einlesen (z.B. CSV-Files)\nfertige R-Pakete für einzelne Plattformen/Anbieter verwenden\nüber API (Application Programming Interface) halb-standardisierte Daten erhalten\nüber Web-Scraping HTML-Inhalte von Websites herunterladen und verarbeiten\nüber ferngesteuerte Browser Inhalte erheben oder Screenshots erstellen\nNutzerInnen um Datenspenden bitten"
  },
  {
    "objectID": "inhaltsanalyse/slides.html#was-ist-eine-api",
    "href": "inhaltsanalyse/slides.html#was-ist-eine-api",
    "title": "Inhaltsanalyse: Inhalte öffentlicher Kommunikation",
    "section": "Was ist eine API?",
    "text": "Was ist eine API?\n\nAustausch maschinenlesbarer Daten zwischen verschiedenen Programmen/Computern\nFormate sind standardisiert (z.B. XML oder JSON), Inhalte variieren\nWeb-APIs nutzen die gleichen Protokolle wie Browser, aber liefern anderen Datenstrukturen\noft nutzen Plattformen für ihre eigenen (Mobil-) Apps ebenfalls APIs\nmit speziellen R-Paketen können diese API-Daten wieder in R-Objekte wie z.B. Datenframes umgewandelt werden"
  },
  {
    "objectID": "inhaltsanalyse/slides.html#beispiel-json",
    "href": "inhaltsanalyse/slides.html#beispiel-json",
    "title": "Inhaltsanalyse: Inhalte öffentlicher Kommunikation",
    "section": "Beispiel JSON",
    "text": "Beispiel JSON\nhttps://api.breakingbadquotes.xyz/v1/quotes\n\n\n[\n    {\n        \"quote\": \"We're done when I say we're done.\",\n        \"author\": \"Walter White\"\n    }\n]"
  },
  {
    "objectID": "inhaltsanalyse/slides.html#workflow",
    "href": "inhaltsanalyse/slides.html#workflow",
    "title": "Inhaltsanalyse: Inhalte öffentlicher Kommunikation",
    "section": "Workflow",
    "text": "Workflow\n\nDatenquelle finden (Website, Feed, API)\nrelevanten Ausgangspunkt finden (Suchanfrage, Accountname, etc.)\nDaten herunterladen\nDaten filtern und auswählen\nDaten in ein standardisiertes Format für die Analyse bringen\n(Daten quick & dirty auswerten oder visualisieren)"
  },
  {
    "objectID": "inhaltsanalyse/slides.html#buchempfehlungen",
    "href": "inhaltsanalyse/slides.html#buchempfehlungen",
    "title": "Inhaltsanalyse: Inhalte öffentlicher Kommunikation",
    "section": "Buchempfehlungen",
    "text": "Buchempfehlungen"
  },
  {
    "objectID": "inhaltsanalyse/slides.html#cli-tools-in-python",
    "href": "inhaltsanalyse/slides.html#cli-tools-in-python",
    "title": "Inhaltsanalyse: Inhalte öffentlicher Kommunikation",
    "section": "CLI-Tools in Python",
    "text": "CLI-Tools in Python\n\nfür spezifische Aufgaben gibt es zahlreiche Tools, z.B.\nVideos herunterladen - youtube-dlp\nAudio transkribieren - whisper-ctranslate2\nVideos in Einzelbilder zerlegen - vcsi\nPython ist auf Mac und Linux-Systemen installiert, unter Windows kann es nachinstalliert werden\nInstallation der einzelnen Pakete über pip install &lt;tool&gt;"
  },
  {
    "objectID": "inhaltsanalyse/slides.html#aufgabe-1-1",
    "href": "inhaltsanalyse/slides.html#aufgabe-1-1",
    "title": "Inhaltsanalyse: Inhalte öffentlicher Kommunikation",
    "section": "Aufgabe 1",
    "text": "Aufgabe 1\n\nInstallieren Sie das CLI-Tool youtube-dlp und laden Sie Videos und Metadaten eines TikTok-Kanals herunter.\nImportieren Sie die Daten in R. Welche Meta-Daten werden gesammelt?"
  },
  {
    "objectID": "inhaltsanalyse/slides.html#zeeschuimer-datenspende",
    "href": "inhaltsanalyse/slides.html#zeeschuimer-datenspende",
    "title": "Inhaltsanalyse: Inhalte öffentlicher Kommunikation",
    "section": "Zeeschuimer-Datenspende",
    "text": "Zeeschuimer-Datenspende\n\nFirefox-Erweiterung, die beim Surfen auf bestimmten Plattformen die angezeigten Inhalte und deren Metadaten speichert\nExport als ndjson-Datei, die man mit R einlesen kann\nvor allem für Instagram und ggf. auch TikTok interessant\nsehr umfangreiche Meta-Daten, aber etwas unübersichtlich"
  },
  {
    "objectID": "inhaltsanalyse/slides.html#aufgabe-2-1",
    "href": "inhaltsanalyse/slides.html#aufgabe-2-1",
    "title": "Inhaltsanalyse: Inhalte öffentlicher Kommunikation",
    "section": "Aufgabe 2",
    "text": "Aufgabe 2\n\nLaden Sie mit Zeeschuimer Daten von Instagram oder TikTok herunter.\nImportieren Sie die Daten in R.\nWerten Sie die Daten ein wenig aus."
  },
  {
    "objectID": "inhaltsanalyse/slides.html#aufgabe-3",
    "href": "inhaltsanalyse/slides.html#aufgabe-3",
    "title": "Inhaltsanalyse: Inhalte öffentlicher Kommunikation",
    "section": "Aufgabe 3",
    "text": "Aufgabe 3\n\nÜberlegen Sie, welche Online-Daten Sie für Ihr Projekt wie erheben wollen.\nWelche weiteren Schritte sind nötig (Transkription, Bildzerlegung, etc.)?\nErstellen Sie eine Datenpipeline auf dem Papier, die wir dann ggf. automatisieren können."
  },
  {
    "objectID": "inhaltsanalyse/slides.html#aufgaben-bis-zur-nächsten-sitzung-1",
    "href": "inhaltsanalyse/slides.html#aufgaben-bis-zur-nächsten-sitzung-1",
    "title": "Inhaltsanalyse: Inhalte öffentlicher Kommunikation",
    "section": "Aufgaben bis zur nächsten Sitzung",
    "text": "Aufgaben bis zur nächsten Sitzung\n\nFinalisieren Sie die Forschungsfragen und Hypothesen.\nDiskutieren und finalisieren Sie das Untersuchungsdesign Ihrer Studie.\nDefinieren Sie Untersuchungseinheit(en) und Grundgesamtheit.\nEntwickeln Sie einen konzeptionell angemessenen Stichprobenplan.\nÜberlegen Sie, wie die Stichprobenziehung praktisch umgesetzt werden kann."
  },
  {
    "objectID": "inhaltsanalyse/slides.html#codierprozess-als-gelenkte-rezeption",
    "href": "inhaltsanalyse/slides.html#codierprozess-als-gelenkte-rezeption",
    "title": "Inhaltsanalyse: Inhalte öffentlicher Kommunikation",
    "section": "Codierprozess als gelenkte Rezeption",
    "text": "Codierprozess als gelenkte Rezeption\n\nProblem: Informationen über die Struktur von großen Mengen von Botschaften\n\nLösung 1: Selektion: Nicht alle Dimensionen der Botschaften werden berücksichtigt\nLösung 2: Klassifikation: Die Dimensionen werden kategorisiert und gemessen\n\nNachteil: Informationsverlust\nVorteile:\n\nReduktion von Komplexität\nAnalyse großer Mengen von Botschaften möglich"
  },
  {
    "objectID": "inhaltsanalyse/slides.html#kategorien",
    "href": "inhaltsanalyse/slides.html#kategorien",
    "title": "Inhaltsanalyse: Inhalte öffentlicher Kommunikation",
    "section": "Kategorien",
    "text": "Kategorien\n\nFormale Kategorien\n\nMedium, Autor\nUmfang des Beitrag\nDatum\n\nInhaltliche Kategorien\n\nThemen der Artikel („Hauptthema”)\nAkteure der Artikel („Hauptakteur”)\nUrheber von Aussagen\nTendenz/Bewertung"
  },
  {
    "objectID": "inhaltsanalyse/slides.html#kategorienbildung",
    "href": "inhaltsanalyse/slides.html#kategorienbildung",
    "title": "Inhaltsanalyse: Inhalte öffentlicher Kommunikation",
    "section": "Kategorienbildung",
    "text": "Kategorienbildung\n\nempiriegeleitet\n\nAuswahl von Beispielen\nSammlung von Themen, Aussagen, Argumenten usw., die repräsentativ sind\nIdentifikation der inhaltlichen Struktur und Bildung von Gruppen\n\nerster Kategorieentwurf\n\ntheoriegeleitet\n\nFrühere Studien und Hypothesen\nErwartung zu Inhalt und Struktur\nerster Kategorieentwurf"
  },
  {
    "objectID": "inhaltsanalyse/slides.html#kategorien-im-codebuch",
    "href": "inhaltsanalyse/slides.html#kategorien-im-codebuch",
    "title": "Inhaltsanalyse: Inhalte öffentlicher Kommunikation",
    "section": "Kategorien im Codebuch",
    "text": "Kategorien im Codebuch\n\nVerbale Beschreibung\n\n\n“Hier wird codiert, ob der Post ein politisches Thema behandelt.”\n\n\nInformation über die Indikatoren (wenn nötig)\n\n\n“Politische Themen werden codiert, wenn der Beitrag Politikfelder (z.B. Innen- oder Wirtschaftspolitik), den politischen Prozess (z.B. Wahlen) oder politische Institutionen (z.B. Bundestag) behandelt.”\n\n\nMessanweisungen i.e.S. (= Regeln für die Überführung der Daten)\n\n\n0 = kein politisches Thema, 1 = politisches Thema"
  },
  {
    "objectID": "inhaltsanalyse/slides.html#kriterien-guter-kategorien",
    "href": "inhaltsanalyse/slides.html#kriterien-guter-kategorien",
    "title": "Inhaltsanalyse: Inhalte öffentlicher Kommunikation",
    "section": "Kriterien guter Kategorien",
    "text": "Kriterien guter Kategorien\n\nKategorien müssen die Forschungsfragen beantworten können.\nKategorien müssen trennscharf sein.\nKategorien müssen erschöpfend sein („Sonstiges”-Kategorie)\nKategorien müssen auf dem selben Klassifikationsprinzip beruhen, d.h. sie dürfen nur eine Dimension messen."
  },
  {
    "objectID": "inhaltsanalyse/slides.html#strategien-für-kategorien",
    "href": "inhaltsanalyse/slides.html#strategien-für-kategorien",
    "title": "Inhaltsanalyse: Inhalte öffentlicher Kommunikation",
    "section": "Strategien für Kategorien",
    "text": "Strategien für Kategorien\n\nMultinomiale Variablen = mehrere Ausprägung\n\n1 = Außenpolitik, 2 = Innenpolitik, 3 = Wirtschaftspolitik\nProblem: gleichzeitiges Auftreten mehrerer Ausprägungen\n\nDummy-Codierung (Mehrfachantworten)\n\nV1: Außenpolitik 0/1, V2 Innenpolitik 0/1, …\nNachteil: vielen Nullen in den Daten, Eingabe etwas aufwändiger\n\nWichtig: NIE mehrere Werte in eine Zelle des Codesheets eintragen"
  },
  {
    "objectID": "inhaltsanalyse/slides.html#aufbau-codebuch",
    "href": "inhaltsanalyse/slides.html#aufbau-codebuch",
    "title": "Inhaltsanalyse: Inhalte öffentlicher Kommunikation",
    "section": "Aufbau Codebuch",
    "text": "Aufbau Codebuch\n\nInformationen über das Thema der Analyse\nForschungsfragen/ Hypothesen\nInformationen über den Untersuchungszeitraum\nDefinitionen der Auswahl-, Analyse, Codier- und Kontexteinheit\nInformationen über das Auswahlverfahren (Vollerhebung vs. Stichprobe)\nDefinition der Zugriffskriterien\nAllgemeine Codieranweisungen\nKategoriensystem (= alle Kategorien zusammengenommen)\nCodebogen"
  },
  {
    "objectID": "inhaltsanalyse/slides.html#zero-shot-codierung-1",
    "href": "inhaltsanalyse/slides.html#zero-shot-codierung-1",
    "title": "Inhaltsanalyse: Inhalte öffentlicher Kommunikation",
    "section": "Zero-Shot Codierung",
    "text": "Zero-Shot Codierung\n\nam besten die Zero-Shot-Tasks gleich mitdenken bzw. identische Codieranweisungen für Codierer und LLM\nstructured output Beispiel in R ansehen, Code anpassen\nmehrere LLM-Modelle/Anbieter als Codierer verwenden\nvalidieren, validieren, validieren!"
  },
  {
    "objectID": "inhaltsanalyse/slides.html#aufgaben-bis-nächste-woche-1",
    "href": "inhaltsanalyse/slides.html#aufgaben-bis-nächste-woche-1",
    "title": "Inhaltsanalyse: Inhalte öffentlicher Kommunikation",
    "section": "Aufgaben bis nächste Woche",
    "text": "Aufgaben bis nächste Woche\n\nFinalisieren Sie Forschungsdesign und Stichprobenplan.\nEntwickeln Sie ein erstes Codebuch für die Studie.\nErstellen Sie ein passendes Codesheet für die Dateneingabe in Excel oder Teams.\nJedes Gruppenmitglied codiert dieselben (!) 10 Codiereinheiten, die Codierungen werden untereinander in einer Datei gesammelt."
  },
  {
    "objectID": "inhaltsanalyse/slides.html#gütekriterien",
    "href": "inhaltsanalyse/slides.html#gütekriterien",
    "title": "Inhaltsanalyse: Inhalte öffentlicher Kommunikation",
    "section": "Gütekriterien",
    "text": "Gütekriterien\n\nValidität\n\nGültigkeit der Messung\nBetrifft den gesamten Messvorgang\n\nReliabilität\n\nZuverlässigkeit (=Reproduzierbarkeit) der Messung\nBetrifft die eigentlich Messprozedur\nWird aus der Übereinstimmung in der Codierung abgeleitet"
  },
  {
    "objectID": "inhaltsanalyse/slides.html#typen-der-reliabilitätsmessung-nach-rössler-2017",
    "href": "inhaltsanalyse/slides.html#typen-der-reliabilitätsmessung-nach-rössler-2017",
    "title": "Inhaltsanalyse: Inhalte öffentlicher Kommunikation",
    "section": "Typen der Reliabilitätsmessung nach Rössler, 2017",
    "text": "Typen der Reliabilitätsmessung nach Rössler, 2017"
  },
  {
    "objectID": "inhaltsanalyse/slides.html#festlegung-von-übereinstimmung-und-abweichung",
    "href": "inhaltsanalyse/slides.html#festlegung-von-übereinstimmung-und-abweichung",
    "title": "Inhaltsanalyse: Inhalte öffentlicher Kommunikation",
    "section": "Festlegung von Übereinstimmung und Abweichung",
    "text": "Festlegung von Übereinstimmung und Abweichung\n\nFür die Bewertung der Reliabilität muss zunächst festgelegt werden, was eine Übereinstimmung und Abweichung bei der Codierung darstellt.\nEinfach bei Kategorien mit dichotomer Ausprägung (“An-/Abwesenheit”).\nSchwieriger bei Kategorien mit ordinal/metrischem Niveau.\n\nWie stark darf die Abweichung sein (Toleranzbereich)?"
  },
  {
    "objectID": "inhaltsanalyse/slides.html#reliablitätsindex-i-übereinstimmung-nach-holsti",
    "href": "inhaltsanalyse/slides.html#reliablitätsindex-i-übereinstimmung-nach-holsti",
    "title": "Inhaltsanalyse: Inhalte öffentlicher Kommunikation",
    "section": "Reliablitätsindex I: Übereinstimmung nach Holsti",
    "text": "Reliablitätsindex I: Übereinstimmung nach Holsti\n\nBerechnet die Übereinstimmung zwischen zwei Codierern.\n\nKann als prozentuale Übereinstimmung interpretiert werden.\n\nIgnoriert die Wahrscheinlichkeit von zufälliger Übereinstimmung, z.B. .5 bei dichotomen Variablen.\nBegrenzt aussagefähig bei sehr schiefen Verteilungen.\n\nBsp.: Eine 0/1 Variable wird in 9 von 10 Fällen von Codierern A abwesend codiert (0) und ein Mal mit (1). Codierer B codiert immer 0. Holsti = .9, obwohl wir gar nicht wissen, ob die Codierer überhaupt Ausprägung 1 erkennen.\n\nAkzeptable Werte: nahe 1 (formale Kategorien) oder &gt; .8 (inhaltliche Kategorien)"
  },
  {
    "objectID": "inhaltsanalyse/slides.html#reliablitätsindex-ii-krippendorffs-alpha",
    "href": "inhaltsanalyse/slides.html#reliablitätsindex-ii-krippendorffs-alpha",
    "title": "Inhaltsanalyse: Inhalte öffentlicher Kommunikation",
    "section": "Reliablitätsindex II: Krippendorffs \\(\\alpha\\)",
    "text": "Reliablitätsindex II: Krippendorffs \\(\\alpha\\)\n\nGold-Standard in der Kommunikationswissenschaft für Reliabilitätstests.\nBerücksichtigt die Wahrscheinlichkeit zufälliger Übereinstimmungen, d.h. es wird geprüft, inwieweit die beobachtete Übereinstimmung über der zufälligen liegt.\nFür mehr als zwei Codierer und verschiedene Skalenniveaus geeignet.\nAkzeptable Werte wie bei Holsti (&gt; .8), allerdings deutlich “strenger” wg. Zufallskorrektur."
  },
  {
    "objectID": "inhaltsanalyse/slides.html#validierungsmaße-für-classifier",
    "href": "inhaltsanalyse/slides.html#validierungsmaße-für-classifier",
    "title": "Inhaltsanalyse: Inhalte öffentlicher Kommunikation",
    "section": "Validierungsmaße für Classifier",
    "text": "Validierungsmaße für Classifier\n\nmanuelle Codierung als Goldstandard\nAbweichung automatischer von manueller Codierung\nGrundlage: Konfusionsmatrix mit korrekt/falsch positiven/negativen\nMaße: Precision, Recall, F-Score"
  },
  {
    "objectID": "inhaltsanalyse/slides.html#aufgaben-bis-nächste-woche-2",
    "href": "inhaltsanalyse/slides.html#aufgaben-bis-nächste-woche-2",
    "title": "Inhaltsanalyse: Inhalte öffentlicher Kommunikation",
    "section": "Aufgaben bis nächste Woche",
    "text": "Aufgaben bis nächste Woche\n\nCodebuch überarbeiten\nReliabilitätstest durchführen (20 Codiereinheiten) und auswerten\nDatenerhebung abschließen\n\nKeine Sitzung nächste Woche, aber Angebot Sprechstunde per Teams zum gleichen Termin."
  },
  {
    "objectID": "inhaltsanalyse/slides.html#datenbereinigung",
    "href": "inhaltsanalyse/slides.html#datenbereinigung",
    "title": "Inhaltsanalyse: Inhalte öffentlicher Kommunikation",
    "section": "Datenbereinigung",
    "text": "Datenbereinigung\n\nFusionieren der einzelnen Codesheets\nEntfernung von Formatierungen, zusammengefassten Zellen, etc.\nImport in SPSS oder R\nPrüfen von Missings und falschen Codes (univariate Häufigkeitstabellen)"
  },
  {
    "objectID": "inhaltsanalyse/slides.html#datenaggregation",
    "href": "inhaltsanalyse/slides.html#datenaggregation",
    "title": "Inhaltsanalyse: Inhalte öffentlicher Kommunikation",
    "section": "Datenaggregation",
    "text": "Datenaggregation\n\noft entspricht Codiereinheit (z.B. Aussage) nicht Analyseeinheit (z.B. Beitrag)\nAggregation auf Ebene der Analyseeinheit\n\nBerechnung von Summen- oder Mittelwertindices pro Analyseeinheit\nPrüfung durch Vergleich aggregierte vs. nicht aggregierte Zahlen\n\nNeuberechnung der korrekten Fallzahlen"
  },
  {
    "objectID": "inhaltsanalyse/slides.html#datenauswertung",
    "href": "inhaltsanalyse/slides.html#datenauswertung",
    "title": "Inhaltsanalyse: Inhalte öffentlicher Kommunikation",
    "section": "Datenauswertung",
    "text": "Datenauswertung\nFür jede Hypothese 3 min Schritte:\n\nDeskriptive Auswertung (z.B. Gruppenmittelwerte, Prozentanteile)\ninferenzstatistischer Test (t-Test, ANOVA, Chi-Quadrat-Test)\nErgebnisdarstellung als Text, Tabelle und/oder Grafik\n\nHinweis: Bei 0/1 Dummy-Variablen entspricht der Mittelwert dem Anteil 1, und oft reicht es, diese zu berichten bzw. zu vergleichen."
  },
  {
    "objectID": "inhaltsanalyse/slides.html#ergebnisteil-im-projektbericht",
    "href": "inhaltsanalyse/slides.html#ergebnisteil-im-projektbericht",
    "title": "Inhaltsanalyse: Inhalte öffentlicher Kommunikation",
    "section": "Ergebnisteil im Projektbericht",
    "text": "Ergebnisteil im Projektbericht\n\nBeschreibung der finalen Stichprobe (allgemein relevante Informationen)\nUnivariate Auswertung zentraler Variablen\nAuswertung der eigentlichen Hypothesen\nweitere interessante Analysen\n\nWichtig: Exaktheit, Konsistenz, Beschriftungen, etc."
  },
  {
    "objectID": "inhaltsanalyse/slides.html#aufgaben-heute",
    "href": "inhaltsanalyse/slides.html#aufgaben-heute",
    "title": "Inhaltsanalyse: Inhalte öffentlicher Kommunikation",
    "section": "Aufgaben heute",
    "text": "Aufgaben heute\n\nBereiten sie Ihre Codierdaten final auf und prüfen sie auf Konsistenz etc.\nBerechnen sie ggf. aggregierte Kennzahlen für die Analyse.\nBerechnen sie zentrale Kennzahlen der Stichprobe für den Ergebnisbericht.\nPlanen sie die notwendigen Analyseschritte für die Hypothesentests, d.h.\n\n\nWelche Variablen sind univariat und bivariate auszuwerten?\nWelche stat. Test sind für jede Hypothese notwendig?\nWann wäre die Hypothese wider- oder belegt? (nicht “bewiesen” oder “verifiziert”)\n\n\nWerten sie die Daten entsprechend aus."
  },
  {
    "objectID": "inhaltsanalyse/slides.html#zero-shot-klassifikation",
    "href": "inhaltsanalyse/slides.html#zero-shot-klassifikation",
    "title": "Inhaltsanalyse: Inhalte öffentlicher Kommunikation",
    "section": "Zero-shot Klassifikation",
    "text": "Zero-shot Klassifikation\n\nEntwickeln eines bzw. mehererer Prompts mit Instruktionen (auf englisch)\nDazu passendes Response-Schema für strukturierte Klassifikation entwickeln\nTesten der Prompts mit wenigen Stimuli\nNach Verfeinerung der Prompts: alles klassifizieren lassen\nVergleich mit manueller Codierung"
  },
  {
    "objectID": "inhaltsanalyse/slides.html#praxis",
    "href": "inhaltsanalyse/slides.html#praxis",
    "title": "Inhaltsanalyse: Inhalte öffentlicher Kommunikation",
    "section": "Praxis",
    "text": "Praxis\n\nRStudio-Server mit hinterlegtem Gemini-API-Key\nzero-shot-v2.R ausprobieren und mit eigenen Daten testen\nUpload von Stimuli am besten als gezippten Ordner\nHilfe: https://edubruell.github.io/tidyllm/"
  },
  {
    "objectID": "inhaltsanalyse/slides.html#datenmanagement",
    "href": "inhaltsanalyse/slides.html#datenmanagement",
    "title": "Inhaltsanalyse: Inhalte öffentlicher Kommunikation",
    "section": "Datenmanagement",
    "text": "Datenmanagement\n\ngültige und fehlende Werte prüfen (ggf. NA setzen)\nDatensatz filtern und finale Fallzahlen prüfen\nIndices bilden und auf Plausibilität testen\nggf. finalen Datensatz separat speichern"
  },
  {
    "objectID": "inhaltsanalyse/slides.html#datenbeschreibung-i-univariat",
    "href": "inhaltsanalyse/slides.html#datenbeschreibung-i-univariat",
    "title": "Inhaltsanalyse: Inhalte öffentlicher Kommunikation",
    "section": "Datenbeschreibung I: univariat",
    "text": "Datenbeschreibung I: univariat\n\nmtcars |&gt; \n  select(am, cyl, hp) |&gt; \n  report::report_table() |&gt; \n  summary()\n\n\n\n\n\nVariable\nMean\nSD\nMin\nMax\nn_Missing\n\n\n\n\nam\n0.40625\n0.4989909\n0\n1\n0\n\n\ncyl\n6.18750\n1.7859216\n4\n8\n0\n\n\nhp\n146.68750\n68.5628685\n52\n335\n0"
  },
  {
    "objectID": "inhaltsanalyse/slides.html#datenbeschreibung-ii-gruppiert",
    "href": "inhaltsanalyse/slides.html#datenbeschreibung-ii-gruppiert",
    "title": "Inhaltsanalyse: Inhalte öffentlicher Kommunikation",
    "section": "Datenbeschreibung II: gruppiert",
    "text": "Datenbeschreibung II: gruppiert\n\nmtcars |&gt; \n  select(am, cyl, hp) |&gt;\n  group_by(am) |&gt; \n  report::report_table() |&gt; \n  summary()\n\n\n\n\n\nGroup\nVariable\nMean\nSD\nMin\nMax\nn_Missing\n\n\n\n\n0\ncyl\n6.947368\n1.544657\n4\n8\n0\n\n\n0\nhp\n160.263158\n53.908196\n62\n245\n0\n\n\n1\ncyl\n5.076923\n1.552500\n4\n8\n0\n\n\n1\nhp\n126.846154\n84.062324\n52\n335\n0"
  },
  {
    "objectID": "inhaltsanalyse/slides.html#hypothesentests-i",
    "href": "inhaltsanalyse/slides.html#hypothesentests-i",
    "title": "Inhaltsanalyse: Inhalte öffentlicher Kommunikation",
    "section": "Hypothesentests I",
    "text": "Hypothesentests I\n\nt.test(hp ~ am, data = mtcars) |&gt; \n  report::report_table() |&gt; \n  summary()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDifference\nCI\nCI_low\nCI_high\nt\ndf_error\np\nAlternative\nd\n\n\n\n\n33.417\n0.95\n-21.87858\n88.71259\n1.266189\n18.71541\n0.2209796\ntwo.sided\n0.5853677"
  },
  {
    "objectID": "inhaltsanalyse/slides.html#hypothesentests-ii",
    "href": "inhaltsanalyse/slides.html#hypothesentests-ii",
    "title": "Inhaltsanalyse: Inhalte öffentlicher Kommunikation",
    "section": "Hypothesentests II",
    "text": "Hypothesentests II\n\naov(hp ~ am, data = mtcars) |&gt; \n  report::report_table() |&gt; \n  summary()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nSum_Squares\ndf\nMean_Square\nF\np\nEta2\n\n\n\n\nam\n8619.498\n1\n8619.498\n1.886003\n0.1798309\n0.0591483\n\n\nResiduals\n137107.377\n30\n4570.246\nNA\nNA\nNA"
  },
  {
    "objectID": "inhaltsanalyse/slides.html#hypothesentests-iii",
    "href": "inhaltsanalyse/slides.html#hypothesentests-iii",
    "title": "Inhaltsanalyse: Inhalte öffentlicher Kommunikation",
    "section": "Hypothesentests III",
    "text": "Hypothesentests III\n\nmtcars |&gt; \n  select(am, vs) |&gt; \n  table() |&gt; \n  chisq.test() |&gt; \n  report::report_table() |&gt; \n  summary()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nChi2\ndf\np\nMethod\nCramers_v_adjusted\nCramers_v_adjusted_CI_low\nCramers_v_adjusted_CI_high\n\n\n\n\n0.3475355\n1\n0.5555115\nPearson’s Chi-squared test with Yates’ continuity correction\n0\n0\n1"
  },
  {
    "objectID": "inhaltsanalyse/slides.html#hypothesentests-iii-1",
    "href": "inhaltsanalyse/slides.html#hypothesentests-iii-1",
    "title": "Inhaltsanalyse: Inhalte öffentlicher Kommunikation",
    "section": "Hypothesentests III",
    "text": "Hypothesentests III\n\ncor.test(~ mpg + hp, data = mtcars) |&gt; \n  report::report_table() |&gt; \n  summary()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter1\nParameter2\nr\nCI\nCI_low\nCI_high\np\nMethod\nAlternative\n\n\n\n\nmpg\nhp\n-0.7761684\n0.95\n-0.8852686\n-0.5860994\n2e-07\nPearson’s product-moment correlation\ntwo.sided"
  },
  {
    "objectID": "inhaltsanalyse/slides.html#visualizisierung-mit-ggplot2",
    "href": "inhaltsanalyse/slides.html#visualizisierung-mit-ggplot2",
    "title": "Inhaltsanalyse: Inhalte öffentlicher Kommunikation",
    "section": "Visualizisierung mit ggplot2",
    "text": "Visualizisierung mit ggplot2\n\nmtcars |&gt; \n  ggplot(aes(x = factor(cyl), y = hp))+\n  stat_summary(fun.data = mean_cl_boot)+\n  theme_minimal()+ labs(x = \"Zylinder\", y = \"Leistung in PS\", caption = \"n = 32\")"
  },
  {
    "objectID": "inhaltsanalyse/slides.html#tipps",
    "href": "inhaltsanalyse/slides.html#tipps",
    "title": "Inhaltsanalyse: Inhalte öffentlicher Kommunikation",
    "section": "Tipps",
    "text": "Tipps\n\nreport::report_table() (plus ggf. summary()) ist sehr vielseitig\nfür dichotome Variablen Chi-Quadrat-Test oder Linear Probability Model (= ANOVA/t-Test)\nVisualisierung mit ggplot (theme_minimal oder tinythemes::theme_ipsum_rc)\neigene Farben und Themes sehr leicht möglich (z.B. remotes::install_github('Mikata-Project/ggthemr'))\nggplot2 Grafiken abspeichern mit ggsave(\"myplot.png\", width = 8, height = 4.5)"
  },
  {
    "objectID": "inhaltsanalyse/slides.html#aufgaben-heute-1",
    "href": "inhaltsanalyse/slides.html#aufgaben-heute-1",
    "title": "Inhaltsanalyse: Inhalte öffentlicher Kommunikation",
    "section": "Aufgaben heute",
    "text": "Aufgaben heute\n\nDaten aufbereiten und auswerten\nErgebnispräsentation (1-2 Folien FF+Hypothesen, 1-2 Folien Methoden, 3-5 Folien Ergebnisse)\nPräsentation maximal 10 min nächste Woche (gern nur 1 Vortragende/r)"
  },
  {
    "objectID": "inhaltsanalyse/slides.html#evaluation",
    "href": "inhaltsanalyse/slides.html#evaluation",
    "title": "Inhaltsanalyse: Inhalte öffentlicher Kommunikation",
    "section": "Evaluation",
    "text": "Evaluation\nhttps://befragung.uni-mainz.de/evasys/online.php?p=73T1T"
  },
  {
    "objectID": "inhaltsanalyse/slides.html#projektbericht-i",
    "href": "inhaltsanalyse/slides.html#projektbericht-i",
    "title": "Inhaltsanalyse: Inhalte öffentlicher Kommunikation",
    "section": "Projektbericht I",
    "text": "Projektbericht I\n\nKennzeichnung der eigenen Arbeitsleistung ist verpflichtend (entweder auf dem Deckblatt oder unter der Kapitelüberschrift)\nGruppennote ist der Standard, ggf. Wunsch nach Einzelbenotung in der Abgabe-Email vermerken\nEidesstattliche Erklärung anfügen\nSie dürfen KI-Tools (sinnvoll!) nutzen, die Arbeit müssen Sie selbst schreiben (Kennzeichnungspflicht!).\nelektronische Abgabe per E-Mail von Codebuch, Codesheet, Hausarbeit und Analyseskript (R, SPSS, Excel) an scharkow@uni-mainz.de\nWeitere Informationen (Deckblatt, Schriftgröße, etc.) gibt es auf der Webseite des Instituts für Publizistik"
  },
  {
    "objectID": "inhaltsanalyse/slides.html#projektbericht-ii",
    "href": "inhaltsanalyse/slides.html#projektbericht-ii",
    "title": "Inhaltsanalyse: Inhalte öffentlicher Kommunikation",
    "section": "Projektbericht II",
    "text": "Projektbericht II\n\nca. 10 Seiten pro Gruppenmitglied, maximal (!) 10.000 Wörter insgesamt. Es gilt Qualität vor Quantität.\nrelevante Grafiken und Tabellen in den Text, ergänzende Analysen in den Anhang\nDokumentation der eigenen Arbeit, d.h. Berichte können recycled werden\nes muss nichts “rauskommen”, außer dass sie etwas gelernt haben\nFormalien und Regeln wissenschaftlicher Arbeit sind wichtig und notenrelevant\nsprachliche und formale Endredaktion lohnt sich, ebenso schöne Aufbereitung der Ergebnisse"
  },
  {
    "objectID": "inhaltsanalyse/slides.html#projektbericht-iii",
    "href": "inhaltsanalyse/slides.html#projektbericht-iii",
    "title": "Inhaltsanalyse: Inhalte öffentlicher Kommunikation",
    "section": "Projektbericht III",
    "text": "Projektbericht III\n\nübliche Gliederung jeder empirischen Studie (gern an Fachartikeln orientieren)\nzentrale Begriffe sind zu definieren, Forschungsfragen und Hypothesen sind aus der Literatur herzuleiten\nmethodisches Vorgehen ist zu erläutern und zu begründen (u.a. Stichprobe, Codebuch, Reliabilität, etc.)\nAbbildungen und Tabellen sind verständlich (!) zu beschriften (inkl. Fallzahl!)\nErgebnisse sind inhaltlich zu interpretieren und in den Forschungsstand einzuordnen\n(Was ist neu? Was wurde bestätigt? Was nicht? Praktische Implikationen? Weitere Forschung?)"
  },
  {
    "objectID": "inhaltsanalyse/slides.html#literatur-1",
    "href": "inhaltsanalyse/slides.html#literatur-1",
    "title": "Inhaltsanalyse: Inhalte öffentlicher Kommunikation",
    "section": "Literatur",
    "text": "Literatur\n\n\n\n\nBenoit, K., Laver, M., & Mikhaylov, S. (2009). Treating Words as Data with Error: Uncertainty in Text Statements of Policy Positions. American Journal of Political Science, 53(2), 495–513. https://doi.org/10.1111/j.1540-5907.2009.00383.x\n\n\nKromrey, H., Roose, J., & Strübing, J. (2016). Empirische Sozialforschung: Modelle und Methoden der standardisierten Datenerhebung und Datenauswertung (Bd. 1040). Utb.\n\n\nTörnberg, P. (2023). How to use LLMs for text analysis. https://arxiv.org/pdf/2307.13106\n\n\nWeber, M., & Reichardt, M. (2024). Evaluation is all you need. Prompting Generative Large Language Models for Annotation Tasks in the Social Sciences. A Primer using Open Models. https://arxiv.org/pdf/2401.00284"
  },
  {
    "objectID": "ma-datenanalyse/index.html#beschreibung",
    "href": "ma-datenanalyse/index.html#beschreibung",
    "title": "MA Fortgeschrittene Datenanalyse mit R",
    "section": "Beschreibung",
    "text": "Beschreibung\nZiel der Übung ist die Vermittlung von praktischen Kenntnissen in der fortgeschrittenen Datenanalyse mit R. Behandelt werden lineare Modelle, Längsschnitt- und Multilevel-Modelle sowie explorative und konfirmatorische Faktorenanalyse."
  },
  {
    "objectID": "ma-datenanalyse/index.html#seminarplan",
    "href": "ma-datenanalyse/index.html#seminarplan",
    "title": "MA Fortgeschrittene Datenanalyse mit R",
    "section": "Seminarplan",
    "text": "Seminarplan\n\n\n\n\n\n\n\n\n\n\n\nSitzung\nDatum\nThema\n\n\n\n\n1\n22.10.2024\nR Basics (Blocktermin Fr)\n\n\n2\n29.10.2024\nR Basics (Blocktermin Mo)\n\n\n3\n05.11.2024\nANOVA und Regression\n\n\n4\n12.11.2024\nModerationsanalyse\n\n\n5\n19.11.2024\nMediationsanalyse und Pfadmodelle\n\n\n6\n26.11.2024\nLagged und Cross-Lagged Modelle\n\n\n7\n03.12.2024\nMultilevel-Längsschnittanalyse\n\n\n8\n10.12.2024\nMultilevelmodelle\n\n\n9\n17.12.2024\nWiederholung\n\n\n10\n07.01.2025\nÜbung (keine Sitzung)\n\n\n11\n14.01.2025\nExplorative Faktorenanalyse\n\n\n12\n21.01.2025\nKonfirmatorische Faktorenanalyse\n\n\n13\n28.01.2025\nMessinvarianz\n\n\n14\n04.02.2025\nWiederholung/Übung"
  },
  {
    "objectID": "experiment/slides.html#kursbeschreibung",
    "href": "experiment/slides.html#kursbeschreibung",
    "title": "Experiment: Mediennutzung und -wirkung",
    "section": "Kursbeschreibung",
    "text": "Kursbeschreibung\nIm Kurs werden eigene Experimente zu einem selbstgewählten Thema von der Entwicklung der Forschungsfrage bis hin zur Darstellung der Ergebnisse praktisch eingeübt.\nDer Kurs ist als inverted classroom konzipiert, d.h. die Studierenden eignen sich allein oder in der Gruppe die Inhalte an, die Sitzungen dienen vornehmlich dem Austausch untereinander und mit mir."
  },
  {
    "objectID": "experiment/slides.html#lernziele",
    "href": "experiment/slides.html#lernziele",
    "title": "Experiment: Mediennutzung und -wirkung",
    "section": "Lernziele",
    "text": "Lernziele\n\nWie führen wir ein Forschungsprojekt durch?\nWie koordinieren und managen wir ein komplexes Projekt mit mehren Mitarbeitern unter Zeitdruck? (Projektmanagement)\nWie präsentieren wir Projektfortschritte, Forschungsprozesse und Forschungsergebnisse?\nWie geben wir konstruktives Feedback im Forschungsprozess? Wie nehmen wir Feedback an und setzen es um?\nSpaß haben in der Forschung!"
  },
  {
    "objectID": "experiment/slides.html#warum-computational-methods",
    "href": "experiment/slides.html#warum-computational-methods",
    "title": "Experiment: Mediennutzung und -wirkung",
    "section": "Warum Computational Methods?",
    "text": "Warum Computational Methods?\n\nmein Lehr- und Forschungsbereich :-)\nhohe Nachfrage in der Kommunikationswissenschaft\nrelevante Skills in vielen Jobs außerhalb der Wissenschaft (Data Science, Journalismus, Marktforschung)\nZiel ist vor allem Verständnis der Grundlagen und Dinge ausprobieren\nfür das eigenene Projekte kann jede Gruppe so viele oder wenige automatische Verfahren verwenden, wie sie will"
  },
  {
    "objectID": "experiment/slides.html#studentische-arbeitsgruppen",
    "href": "experiment/slides.html#studentische-arbeitsgruppen",
    "title": "Experiment: Mediennutzung und -wirkung",
    "section": "Studentische Arbeitsgruppen",
    "text": "Studentische Arbeitsgruppen\n\nmaximal 4-5 Studierende pro Gruppe (4-5 Gruppen im Seminar)\n‚Learning by doing‘ in der AG\nVon anderen AGs lernen über andere Methoden, Themen und Arbeitsweisen\nLernen von Feedback zur eigenen Arbeit und der Arbeit der anderen AGs"
  },
  {
    "objectID": "experiment/slides.html#struktur-der-sitzungen",
    "href": "experiment/slides.html#struktur-der-sitzungen",
    "title": "Experiment: Mediennutzung und -wirkung",
    "section": "Struktur der Sitzungen",
    "text": "Struktur der Sitzungen\n\nmin. zwei Team-Mitglieder sollten da sein (1x Bericht, 1x Feedback an andere)\n5-Minuten-Gruppenbericht (jedes Gruppenmitglied ist einmal an der Reihe) und Feedbackrunde\nggf. Refresher und Diskussion der methodischen Grundlagen\nDiskussion der nächsten Arbeitsschritte"
  },
  {
    "objectID": "experiment/slides.html#gruppenberichte",
    "href": "experiment/slides.html#gruppenberichte",
    "title": "Experiment: Mediennutzung und -wirkung",
    "section": "Gruppenberichte",
    "text": "Gruppenberichte\n\njedes Gruppenmitglied ist federführend für ein Sitzungsthema und den dazugehörigen Bericht in der jeweils nächsten Sitzung zuständig\ndie ggf. übrigbleibende Gruppenberichte machen sie als Gruppe (z.B. Themen)\n\nAufgaben\n\nProtokollierung des Diskussionsprozesse in der AG\nVorbereitung einer Kurzpräsentation (5 min) mit 3-4 Folien\nUpload von Folien spätestens Mo 8h, Präsentation in der Sitzung"
  },
  {
    "objectID": "experiment/slides.html#themen",
    "href": "experiment/slides.html#themen",
    "title": "Experiment: Mediennutzung und -wirkung",
    "section": "Themen",
    "text": "Themen\n\nin diesem Seminar keine zentrale Themenvorgabe\njede Gruppe kann und soll sich ein eigenes Thema und eine eigene Forschungsfrage erarbeiten\nwichtig ist, ob Sie das Thema ein Semester lang motiviert, aufwändige und schwierige Gruppenarbeiten zu erfüllen\n\nThemenvorschlag dieses Semester: Irgendwas mit generativer KI (Text, Bild, etc.)"
  },
  {
    "objectID": "experiment/slides.html#sitzungen-zu-computational-methods",
    "href": "experiment/slides.html#sitzungen-zu-computational-methods",
    "title": "Experiment: Mediennutzung und -wirkung",
    "section": "Sitzungen zu Computational Methods",
    "text": "Sitzungen zu Computational Methods\n\nMaterial https://stats.ifp.uni-mainz.de/ba-ccs-track\nbitte eigenes Notebook zu den praktischen Sitzungen mitbringen\nwir verwenden ggf. R und RStudio, https://rstudio.ifp.uni-mainz.de\ngern paarweise arbeiten, das hilft in der Sitzung und macht mehr Spaß\nLernziel ist, grundlegende Methoden kennenzulernen und Sachen einfach auszuprobieren"
  },
  {
    "objectID": "experiment/slides.html#aufgaben-zur-nächsten-sitzung",
    "href": "experiment/slides.html#aufgaben-zur-nächsten-sitzung",
    "title": "Experiment: Mediennutzung und -wirkung",
    "section": "Aufgaben zur nächsten Sitzung",
    "text": "Aufgaben zur nächsten Sitzung\nGrundlagen wiederholen\n\nBitte schauen Sie diese Videos und/oder lesen Sie die einführenden Kapitel im Lehrbuch.\n\nhttps://video.uni-mainz.de/Panopto/Pages/Viewer.aspx?id=be301c13-62dc-4038-a1ce-aba500e7bc0c\nhttps://video.uni-mainz.de/Panopto/Pages/Viewer.aspx?id=49adf458-ec65-4619-ba19-aba300e08f16"
  },
  {
    "objectID": "experiment/slides.html#experiment-vorschlagen",
    "href": "experiment/slides.html#experiment-vorschlagen",
    "title": "Experiment: Mediennutzung und -wirkung",
    "section": "Experiment vorschlagen",
    "text": "Experiment vorschlagen\n\nSchauen Sie die auf Moodle hochgeladenen Beispielstudien zur Inspiration an.\nÜberlegen Sie, was Sie gern experimentell untersuchen wollen. Die Machbarkeit ist erst einmal sekundär.\nFassen Sie Ihre Überlegungen auf max. 1/2 A4-Seite zusammen. Diese stellen Sie in der nächsten Sitzung mündlich kurz vor.\nRelevant sind grob Thema, Versuchsbedingen, Outcome-Variablen"
  },
  {
    "objectID": "experiment/slides.html#literatur",
    "href": "experiment/slides.html#literatur",
    "title": "Experiment: Mediennutzung und -wirkung",
    "section": "Literatur",
    "text": "Literatur\n\n\n\nKoch, T., Peter, C., & Müller, P. (2019). Das Experiment in der Kommunikations- und Medienwissenschaft. Grundlagen, Durchführung und Auswertung experimenteller Forschung. Wiesbaden: Springer VS."
  },
  {
    "objectID": "experiment/slides.html#themenvorstellung",
    "href": "experiment/slides.html#themenvorstellung",
    "title": "Experiment: Mediennutzung und -wirkung",
    "section": "Themenvorstellung",
    "text": "Themenvorstellung\nStellen Sie kurz sich und Ihren Themenvorschlag vor!"
  },
  {
    "objectID": "experiment/slides.html#aufgaben-zur-nächsten-sitzung-1",
    "href": "experiment/slides.html#aufgaben-zur-nächsten-sitzung-1",
    "title": "Experiment: Mediennutzung und -wirkung",
    "section": "Aufgaben zur nächsten Sitzung",
    "text": "Aufgaben zur nächsten Sitzung\n\nGruppen bilden (4-5 Personen, ungern weniger)\nE-Mail schreiben, wer in der Gruppe für welches Thema zuständig ist\nStudien mit verwandten Themen recherchieren\nNotebook (bzw. Tablet mit Tastatur) mitbringen\nggf. RStudio und R installieren"
  },
  {
    "objectID": "experiment/slides.html#theorie-und-empirie",
    "href": "experiment/slides.html#theorie-und-empirie",
    "title": "Experiment: Mediennutzung und -wirkung",
    "section": "Theorie und Empirie",
    "text": "Theorie und Empirie\nKlassische empirische Sozialforschung\n\nTheorieentwicklung in Form verbaler Aussagen\nTheorieprüfung anhand empirischer Daten\n(Null-)Hypothesentests als Abgleich von Theorie und Empirie\n\nSimulationen\n\nTheorieentwicklung in Form von Algorithmen/Code\nGenerierung von (mehrfach) simulierten Daten\nAbgleich der simulierten mit empirischen Daten"
  },
  {
    "objectID": "experiment/slides.html#typen-von-simulationen",
    "href": "experiment/slides.html#typen-von-simulationen",
    "title": "Experiment: Mediennutzung und -wirkung",
    "section": "Typen von Simulationen",
    "text": "Typen von Simulationen\n\nMonte-Carlo-Simulation\nsoziale Simulationen (Waldherr & Wettstein, 2019)"
  },
  {
    "objectID": "experiment/slides.html#monte-carlo-simulation",
    "href": "experiment/slides.html#monte-carlo-simulation",
    "title": "Experiment: Mediennutzung und -wirkung",
    "section": "Monte-Carlo-Simulation",
    "text": "Monte-Carlo-Simulation\n\nAnnahmen über Verteilung von Daten in der Grundgesamtheit\nwiederholtes Ziehen von Zufallsstichproben aus der Grundgesamtheit\nwiederholte Anwendung eines Verfahrens und Analyse der Ergebnisse"
  },
  {
    "objectID": "experiment/slides.html#beispiel-t-test",
    "href": "experiment/slides.html#beispiel-t-test",
    "title": "Experiment: Mediennutzung und -wirkung",
    "section": "Beispiel T-Test",
    "text": "Beispiel T-Test\n\nmales = rnorm(n = 1e6, m = 180, sd = 10)\nfemales = rnorm(n = 1e6, m = 166, sd = 10)\nt.test(females, males) \n\n\n    Welch Two Sample t-test\n\ndata:  females and males\nt = -989.18, df = 2e+06, p-value &lt; 2.2e-16\nalternative hypothesis: true difference in means is not equal to 0\n95 percent confidence interval:\n -14.02052 -13.96507\nsample estimates:\nmean of x mean of y \n 166.0046  179.9974"
  },
  {
    "objectID": "experiment/slides.html#simulation-mit-zufallsziehung",
    "href": "experiment/slides.html#simulation-mit-zufallsziehung",
    "title": "Experiment: Mediennutzung und -wirkung",
    "section": "Simulation mit Zufallsziehung",
    "text": "Simulation mit Zufallsziehung\n\ndo_t_test = function(n, group1, group2){\n  m = sample(group1, n)\n  w = sample(group2, n)\n  t.test(m,w)$p.value\n}\n\ndo_t_test(100, females, males)\n\n[1] 5.068076e-22\n\ndo_t_test(100, males, males)\n\n[1] 0.6115184"
  },
  {
    "objectID": "experiment/slides.html#alpha-fehler",
    "href": "experiment/slides.html#alpha-fehler",
    "title": "Experiment: Mediennutzung und -wirkung",
    "section": "Alpha-Fehler",
    "text": "Alpha-Fehler\n\nset.seed(123)\nresults_h0 = replicate(1000, do_t_test(n = 100, males, males))\nresults_h0 |&gt; head()\n\n[1] 0.9448921 0.0061930 0.7275112 0.2651163 0.8653915 0.7656020\n\nsum(results_h0 &lt;= .05)\n\n[1] 56"
  },
  {
    "objectID": "experiment/slides.html#beta-fehler-und-power",
    "href": "experiment/slides.html#beta-fehler-und-power",
    "title": "Experiment: Mediennutzung und -wirkung",
    "section": "Beta-Fehler und Power",
    "text": "Beta-Fehler und Power\n\nresults_h1_n10 = replicate(1000, do_t_test(n = 5, females, males))\nresults_h1_n100 = replicate(1000, do_t_test(n = 50, females, males))\n\nsum(results_h1_n10 &lt;= .05)\n\n[1] 450\n\nsum(results_h1_n100 &lt;= .05)\n\n[1] 1000"
  },
  {
    "objectID": "experiment/slides.html#power-analyse",
    "href": "experiment/slides.html#power-analyse",
    "title": "Experiment: Mediennutzung und -wirkung",
    "section": "Power-Analyse",
    "text": "Power-Analyse\n\nfür jedes Experiment sollte vorher eine Power-Analyse durchgeführt werden\nplausible Annahmen (z.B. aus der Literatur) für Effektgrößen/Unterschiede zwischen den Versuchsbedingungen\nfür einfache Designs gibt es z.B. Online-Calculators\nfür komplexere Designs Monte-Carlo-Simulation\nwir zielen auf ca. 80% Power für den erwarteten Effekt"
  },
  {
    "objectID": "experiment/slides.html#vor--und-nachteile-monte-carlo-simulation",
    "href": "experiment/slides.html#vor--und-nachteile-monte-carlo-simulation",
    "title": "Experiment: Mediennutzung und -wirkung",
    "section": "Vor- und Nachteile Monte-Carlo-Simulation",
    "text": "Vor- und Nachteile Monte-Carlo-Simulation\n\neignen sich vor allem zum Prüfen von Verfahren (tut meine Analyse was sie soll?) und zur\nPower-Analyse (kann meine Studie einen bestimmten Effekt finden?)\ndatengenerierender Prozess muss (näherungsweise) bekannt sein\nRegelspezifikation über Formeln\nisolierte Betrachtung aller Fälle (keine Interaktionen zwischen Agenten)"
  },
  {
    "objectID": "experiment/slides.html#soziale-simulationen",
    "href": "experiment/slides.html#soziale-simulationen",
    "title": "Experiment: Mediennutzung und -wirkung",
    "section": "Soziale Simulationen",
    "text": "Soziale Simulationen\n\nkomplexe Gleichungssysteme - Makromodelle\nMikrosimulation (Sample von Agenten wird künstlich “gealtert”)\nDiscrete-Event-Simulations (z.B. Warteschlangenmodelle)\nZelluläre Automaten (z.B. Schellings Segregationsmodell)\nAgent-based Models"
  },
  {
    "objectID": "experiment/slides.html#agentenbasierte-modelle-abm",
    "href": "experiment/slides.html#agentenbasierte-modelle-abm",
    "title": "Experiment: Mediennutzung und -wirkung",
    "section": "Agentenbasierte Modelle (ABM)",
    "text": "Agentenbasierte Modelle (ABM)\nComputermodelle mit folgenden Komponenten:\n\nAgenten\nUmwelt\nRegeln\n\nGeeignet zur Modellierung und Simulation komplexer Systeme mit\n\nheterogenen, interagierenden und adaptiven Agenten\ndynamischen, nicht-linearen Prozessen\nMikro-Makro-Verknüpfungen"
  },
  {
    "objectID": "experiment/slides.html#spezifikation-der-simulation",
    "href": "experiment/slides.html#spezifikation-der-simulation",
    "title": "Experiment: Mediennutzung und -wirkung",
    "section": "Spezifikation der Simulation",
    "text": "Spezifikation der Simulation\n\nin ABM häufig relativ einfache Handlungs-Regeln\nformale Spezifikation mit probabilistischer Komponente\nwenige Parameter innerhalb der Agenten, wenige für die Umwelt\nProblem 1: sozialwissenschaftliche Theorie oft nicht ausreichend spezifisch und vollständig\nProblem 2: Annahmen des Modells vs. Ergebnisse der Simulation"
  },
  {
    "objectID": "experiment/slides.html#generative-agentenmodelle",
    "href": "experiment/slides.html#generative-agentenmodelle",
    "title": "Experiment: Mediennutzung und -wirkung",
    "section": "Generative Agentenmodelle",
    "text": "Generative Agentenmodelle\n\nstatt formaler (programmierter) Regeln sprachliche Regeln\nNutzung eines LLM als Agent (“Roleplaying”)\nLLM ergänzt sprachliche Anweisungen und Rolle durch verbale Antworten\nAntworten hängen von den Trainingsdaten und der Qualität des LLM ab\nbislang sehr wenige Validierungsstudien (Larooij & Törnberg, 2025)\noft relativ naive Annahmen über die Generalisierbarkeit der Ergebnisse (= Ersatz für menschliche Agenten)"
  },
  {
    "objectID": "experiment/slides.html#beispiel-1-analoge-simulation-heroes-cowards",
    "href": "experiment/slides.html#beispiel-1-analoge-simulation-heroes-cowards",
    "title": "Experiment: Mediennutzung und -wirkung",
    "section": "Beispiel 1: Analoge Simulation Heroes & Cowards",
    "text": "Beispiel 1: Analoge Simulation Heroes & Cowards\n\nWir definieren unseren Seminarraum als Umwelt, inkl. aller physikalischen Einschränkungen\nAgenten des ABM: Teilnehmerinnen\neinfache Handlungsanweisungen und minimale soziale Interaktion"
  },
  {
    "objectID": "experiment/slides.html#beispiel-2-generative-agenten-mit-llm",
    "href": "experiment/slides.html#beispiel-2-generative-agenten-mit-llm",
    "title": "Experiment: Mediennutzung und -wirkung",
    "section": "Beispiel 2: Generative Agenten mit LLM",
    "text": "Beispiel 2: Generative Agenten mit LLM\n\nForschungfrage: Wie wirken Emojis in Textnachrichten?\nWhatsapp-Nachrichten mit und ohne passende Emojis (generiert mit ChatGPT)\nverschiedene Agentenpersonas (Alter, Geschlecht, Erfahrung)\nExperimentaldesign Within-Subjects: alle Agenten bewerten alle Nachrichten (mit einer Replikation)\nverwendetes Modell GPT3.5 (Kosten wenige Cent pro Durchlauf)"
  },
  {
    "objectID": "experiment/slides.html#simulierte-daten",
    "href": "experiment/slides.html#simulierte-daten",
    "title": "Experiment: Mediennutzung und -wirkung",
    "section": "Simulierte Daten",
    "text": "Simulierte Daten\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nagent_age\nagent_experience\nagent_gender\nscenario_condition\nscenario_message\nanswer_friendly\n\n\n\n\n60\nloves texting and knows all the emojis.\nman\nannoyed with matching emojis\nKim, make sure you buy and bring a pack of coffee. 😒☕\n1\n\n\n60\nloves texting and knows all the emojis.\nman\nfriendly with matching emojis\nHey Kim, could you vacuum the living room? 🧹😊 You’re a star!\n4\n\n\n40\njust learned how to use Whatsapp\nwoman\nannoyed without emojis\nKim, don’t forget to wash the dishes.\n2"
  },
  {
    "objectID": "experiment/slides.html#simulierte-ergebnisse",
    "href": "experiment/slides.html#simulierte-ergebnisse",
    "title": "Experiment: Mediennutzung und -wirkung",
    "section": "Simulierte Ergebnisse",
    "text": "Simulierte Ergebnisse"
  },
  {
    "objectID": "experiment/slides.html#ausblick-llm-basierte-abm",
    "href": "experiment/slides.html#ausblick-llm-basierte-abm",
    "title": "Experiment: Mediennutzung und -wirkung",
    "section": "Ausblick LLM-basierte ABM",
    "text": "Ausblick LLM-basierte ABM\n\nvielfältige Anwendungsbereiche, vor allem auch im Bereich Rezeptionsforschung\nrelativ einfache Regelspezifikation, komplexe Agentenpersonas (ggf. mit Gedächtnis)\nVerknüpfung mit realen Stimuli einfach möglich\nInter-Agent-Kommunikation möglich, aber bislang in Expected Parrot nicht umgesetzt\nNachteile: Biases der LLM schlagen durch, unklare Generalisierbarkeit\nLLM-Antworten sind definitiv nicht äquivalent mit menschlichen Befragten!"
  },
  {
    "objectID": "experiment/slides.html#aufgaben-zur-nächsten-sitzung-2",
    "href": "experiment/slides.html#aufgaben-zur-nächsten-sitzung-2",
    "title": "Experiment: Mediennutzung und -wirkung",
    "section": "Aufgaben zur nächsten Sitzung",
    "text": "Aufgaben zur nächsten Sitzung\n\npraktische Übung nachbereiten https://stats.ifp.uni-mainz.de/ba-ccs-track/exp-simulation.html\nHausaufgabe in R erledigen"
  },
  {
    "objectID": "experiment/slides.html#agenda-heute",
    "href": "experiment/slides.html#agenda-heute",
    "title": "Experiment: Mediennutzung und -wirkung",
    "section": "Agenda heute",
    "text": "Agenda heute\n\nFragen zu Grundlagen des Experiments\nKausalmodelle und Experimentaldesign\nForschungsfragen und Hypothesen\nBegriffsarbeit"
  },
  {
    "objectID": "experiment/slides.html#experimente-randomisierung-kausalität",
    "href": "experiment/slides.html#experimente-randomisierung-kausalität",
    "title": "Experiment: Mediennutzung und -wirkung",
    "section": "Experimente, Randomisierung, Kausalität",
    "text": "Experimente, Randomisierung, Kausalität\n\nExperimente dienen primär der Überprüfung kausaler Zusammenhänge\nkausale Interpretation durch Experimentaldesign\n\nzeitliche Reihenfolge\nDrittvariablenkontrolle\n\nKontrolle aller (beobachteten und nicht beobachteten) Drittvariablen durch Randomisierung und/oder Kovariate"
  },
  {
    "objectID": "experiment/slides.html#problem-1-drittvariablen-kovariate",
    "href": "experiment/slides.html#problem-1-drittvariablen-kovariate",
    "title": "Experiment: Mediennutzung und -wirkung",
    "section": "Problem 1: Drittvariablen (Kovariate)",
    "text": "Problem 1: Drittvariablen (Kovariate)\n\nKovariate können recht einfach bei der Datenauswertung eingefügt werden\nDrittvariablenkontrolle bei Randomisierung unnötig, kann aber Präzision der Schätzung erhöhen, aber\n\nKovariate muss zeitlich und kausal vor der Experimentalmanipulation\nInklusion von Post-Treatment-Variablen verzerrt die Schätzung des Effekts\n\nsowohl Exklusion als auch Inklusion von Kovariaten können problematisch sein\nim Zweifelsfall eher weniger oder keine Kovariate ins Modell aufnehmen"
  },
  {
    "objectID": "experiment/slides.html#mediation-und-moderation",
    "href": "experiment/slides.html#mediation-und-moderation",
    "title": "Experiment: Mediennutzung und -wirkung",
    "section": "Mediation und Moderation",
    "text": "Mediation und Moderation\n\niv"
  },
  {
    "objectID": "experiment/slides.html#kausalität-im-experiment",
    "href": "experiment/slides.html#kausalität-im-experiment",
    "title": "Experiment: Mediennutzung und -wirkung",
    "section": "Kausalität im Experiment",
    "text": "Kausalität im Experiment\n\nQuelle: Koch et al. (2019)"
  },
  {
    "objectID": "experiment/slides.html#problem-2-mediation-und-indirekte-effekte",
    "href": "experiment/slides.html#problem-2-mediation-und-indirekte-effekte",
    "title": "Experiment: Mediennutzung und -wirkung",
    "section": "Problem 2: Mediation und indirekte Effekte",
    "text": "Problem 2: Mediation und indirekte Effekte\n\n\n\n\nder totale Effekt \\(c\\) lässt sich kausal interpretieren, wenn Exposure experimentell variiert wird\ndas Hinzufügen des Mediators verändert die Interpretation, nur \\(a\\) kann nun kausal interpretiert werden\nder indirekte Effekt \\(ab\\) kann nicht kausal interpretiert werden, und auch nicht der direkte Effect \\(c'\\) Bullock et al. (2010)\n\n\n\n\n\n\nRijnhart et al. (2021)"
  },
  {
    "objectID": "experiment/slides.html#aufgabe-in-kleingruppen",
    "href": "experiment/slides.html#aufgabe-in-kleingruppen",
    "title": "Experiment: Mediennutzung und -wirkung",
    "section": "Aufgabe in Kleingruppen",
    "text": "Aufgabe in Kleingruppen\n\nLesen und diskutieren sie gemeinsam Abstract, Hypothesen, Design und Stimuli von Wang & Sundar (2022) (15min)\nFassen Sie die Haupthypothesen und deren empirische Umsetzung im Experiment in eigenen Worten zusammen.\nMarkieren Sie die einzelnen Hypothesen als Pfade im Pfadmodell.\nWelche der Hypothesen können mit dem Experiment kausal getestet werden?"
  },
  {
    "objectID": "experiment/slides.html#wang2022",
    "href": "experiment/slides.html#wang2022",
    "title": "Experiment: Mediennutzung und -wirkung",
    "section": "Wang & Sundar (2022)",
    "text": "Wang & Sundar (2022)\n\nQuelle: Wang & Sundar (2022)"
  },
  {
    "objectID": "experiment/slides.html#problem-2-moderation",
    "href": "experiment/slides.html#problem-2-moderation",
    "title": "Experiment: Mediennutzung und -wirkung",
    "section": "Problem 2: Moderation",
    "text": "Problem 2: Moderation\n\nEffektheterogenität, d.h. der Zusammenhang von X und Y ist nicht für alle gleich\nder Effekt von X auf Y hängt von Moderatorvariable Z ab (“wird von Z moderiert”)\ndie Größe und die Richtung des Regressionskoeffizienten ist davon abhängig, welche Ausprägung Z hat\nBeispiele:\n\nExperimente mit min. 2 Faktoren, die sich gegenseitig beeiflussen\nEffektheterogenität in verschiedenen Subgruppen der Stichprobe (Kovariate)\n\nkonditionale Kausalität schwierig zu testen und zu interpretieren\nModeratonshypothesen erfordern deutlich höhere statistische Power"
  },
  {
    "objectID": "experiment/slides.html#was-ist-eine-gute-forschungsfrage",
    "href": "experiment/slides.html#was-ist-eine-gute-forschungsfrage",
    "title": "Experiment: Mediennutzung und -wirkung",
    "section": "Was ist eine gute Forschungsfrage?",
    "text": "Was ist eine gute Forschungsfrage?\n\nEine Forschungsfrage ist eine Frage!\nEine Forschungsfrage lässt sich empirisch beantworten, am besten mit der eigenen Inhaltsanalyse.\nEine Forschungsfrage ist weder zu allgemein noch zu spezifisch.\nEine Forschungsfrage hat oft eine (implizite oder explizite) Vergleichsdimension."
  },
  {
    "objectID": "experiment/slides.html#was-ist-eine-gute-hypothese",
    "href": "experiment/slides.html#was-ist-eine-gute-hypothese",
    "title": "Experiment: Mediennutzung und -wirkung",
    "section": "Was ist eine gute Hypothese?",
    "text": "Was ist eine gute Hypothese?\n\nEine Hypothese ist empirisch falsifizierbar, und es muss klar sein, wann sie falsifiziert ist.\nEine Hypothese ist klar und widerspruchsfrei formuliert.\nEine Hypothese ist einfach, komplexe Hypothesen sollten in einfache Hypothesen zerlegt werden.\nEs ist nicht schlimm, sich widersprechende Hypothesen zu formulieren (H1a vs H1b).\nEine Nullhypothese ist selten eine interessante Hypothese, und oft nicht leicht zu prüfen."
  },
  {
    "objectID": "experiment/slides.html#komplexe-hypothesen",
    "href": "experiment/slides.html#komplexe-hypothesen",
    "title": "Experiment: Mediennutzung und -wirkung",
    "section": "Komplexe Hypothesen",
    "text": "Komplexe Hypothesen\n\nMediationshypothesen lassen sich fast nie kausal prüfen, auch nicht im Experiment.\nMediationshypothesen sind praktisch immer kausal, selbst wenn das Gegenteil (in den Limitationen) behauptet wird.\nModerationshypothesen sind legitim, aber erfordern mehr Aufwand (z.B. Stichprobengröße)\nWir sind zunächst an unkonditionalen Effekten interessiert (Sparsamkeit des Modells).\nKovariaten- und Moderationshypothesen sollten nicht im Vordergrund des Experiments stehen."
  },
  {
    "objectID": "experiment/slides.html#begriffsarbeit",
    "href": "experiment/slides.html#begriffsarbeit",
    "title": "Experiment: Mediennutzung und -wirkung",
    "section": "Begriffsarbeit",
    "text": "Begriffsarbeit\n\nKomrey, Roose & Strübing, 2016"
  },
  {
    "objectID": "experiment/slides.html#aufgaben-bis-nächste-woche",
    "href": "experiment/slides.html#aufgaben-bis-nächste-woche",
    "title": "Experiment: Mediennutzung und -wirkung",
    "section": "Aufgaben bis nächste Woche",
    "text": "Aufgaben bis nächste Woche\n\nEinigen sie sich in der Gruppe auf ein Thema.\nRecherchieren sie mindestens 4 thematische verwandte Studien, vorzugsweise Experimente.\nFormulieren Sie Forschungsfragen und Hypothesen.\nDefinieren und erarbeiten Sie zentrale Begriffe, die in den Forschungsfragen und Hypothesen vorkommen."
  },
  {
    "objectID": "experiment/slides.html#agenda-heute-1",
    "href": "experiment/slides.html#agenda-heute-1",
    "title": "Experiment: Mediennutzung und -wirkung",
    "section": "Agenda heute",
    "text": "Agenda heute\n\nFinalisierung Forschungsfragen und Hypothesen\nForschungsdesign\nStichprobe"
  },
  {
    "objectID": "experiment/slides.html#experimentalfaktoren",
    "href": "experiment/slides.html#experimentalfaktoren",
    "title": "Experiment: Mediennutzung und -wirkung",
    "section": "Experimentalfaktoren",
    "text": "Experimentalfaktoren\n\nQuelle: Koch et al. (2019)"
  },
  {
    "objectID": "experiment/slides.html#between--und-within-subject-design",
    "href": "experiment/slides.html#between--und-within-subject-design",
    "title": "Experiment: Mediennutzung und -wirkung",
    "section": "Between- und Within-Subject-Design",
    "text": "Between- und Within-Subject-Design\n\nQuelle: Koch et al. (2019)"
  },
  {
    "objectID": "experiment/slides.html#studiendesign-und-stat.-power",
    "href": "experiment/slides.html#studiendesign-und-stat.-power",
    "title": "Experiment: Mediennutzung und -wirkung",
    "section": "Studiendesign und stat. Power",
    "text": "Studiendesign und stat. Power\n\nQuelle: https://measuringu.com/between-within/"
  },
  {
    "objectID": "experiment/slides.html#studiendesign-und-datenanalyse",
    "href": "experiment/slides.html#studiendesign-und-datenanalyse",
    "title": "Experiment: Mediennutzung und -wirkung",
    "section": "Studiendesign und Datenanalyse",
    "text": "Studiendesign und Datenanalyse\n\n\n\nBetween-Subjects\n\n\n\n\n\n\nparticipant_id\ntreatment\noutcome\n\n\n\n\n1\nA\n4\n\n\n2\nB\n1\n\n\n3\nC\n3\n\n\n4\nA\n1\n\n\n\n\n\n\nlm(outcome ~ treatment, data = d)\n\nWithin-Subjects (Long Format)\n\n\n\n\n\n\nparticipant_id\ntreatment\noutcome\n\n\n\n\n1\nA\n1\n\n\n1\nB\n2\n\n\n1\nC\n5\n\n\n2\nA\n5\n\n\n\n\n\n\nlme4::lmer(outcome ~ treatment + (treatment | participant_id), data = d)"
  },
  {
    "objectID": "experiment/slides.html#vor--und-nachteile",
    "href": "experiment/slides.html#vor--und-nachteile",
    "title": "Experiment: Mediennutzung und -wirkung",
    "section": "Vor- und Nachteile",
    "text": "Vor- und Nachteile\n\n\n\nBetween-Subjects\n\neinfach zu planen und umzusetzen\neinfach auszuwerten\nkeine Reihenfolgeeffekte etc.\ngroße Stichprobe erforderlich\nAufwand Rekrutierung vs. Ertrag\n\n\nWithin-Subjects\n\nmehr statistische Power\nggf. höhere Generalisierbarkeit\netwas mehr Aufwand in der Umsetzung\netwas schwierigere Auswertung\nggf. Reihenfolgeeffekte\n\n\n\nEs sind auch gemischte und/oder unvollständige Designs (within + between Faktoren) möglich."
  },
  {
    "objectID": "experiment/slides.html#umsetzung-unvollständige-within-designs",
    "href": "experiment/slides.html#umsetzung-unvollständige-within-designs",
    "title": "Experiment: Mediennutzung und -wirkung",
    "section": "Umsetzung (unvollständige) Within-Designs",
    "text": "Umsetzung (unvollständige) Within-Designs\n\nstatt immer neu zu randomisieren, werden Pseudo-Between-Gruppen gebildet\nalle relevanten (Kombinationen von) Bedingungen sind enthalten\ninnerhalb dieser Gruppen ist der Ablauf immer gleich\nDesigns können unvollständig sein, aber die wichtigsten Bedingungen enthalten\nReihenfolge nur für die relevantesten Faktoren variieren\n\n\n\n\n\n\n\nGruppe\nTreatment_1\nTreatment_2\nTreatment_3\n\n\n\n\n1\nA\nB\nC\n\n\n2\nB\nC\nA\n\n\n3\nC\nA\nB"
  },
  {
    "objectID": "experiment/slides.html#reihenfolge",
    "href": "experiment/slides.html#reihenfolge",
    "title": "Experiment: Mediennutzung und -wirkung",
    "section": "Reihenfolge",
    "text": "Reihenfolge\n\nCover-Story/Briefing, Studie, Debriefing\nmöglichst sofort mit dem Experiment beginnen, Kovariaten später messen (Abbrecher)\nbei Within-Designs entweder\n\ndirekte Messung nach Exposition zum Stimulus (Stimulus, Messung, Stimulus, Messung, etc.)\nvergleichende/aggregierte Messung nach Präsentation aller Stimuli (z.B. Recall)\n\nzeitlicher Abstand Stimulus-zu-Messung hängt von der Fragestellung ab"
  },
  {
    "objectID": "experiment/slides.html#manipulations-check",
    "href": "experiment/slides.html#manipulations-check",
    "title": "Experiment: Mediennutzung und -wirkung",
    "section": "Manipulations-Check",
    "text": "Manipulations-Check\n\noft werden Manipulationschecks einfach empfohlen, aber zu bedenken:\n\nIst es nötig, dass die Probandinnen die Manipulation erkennen?\nWird durch den Check (die Frage) selbst ein Effekt erzielt?\nWas passiert, wenn jemand durch den Manipulationscheck fällt?\n\nim Zweifelsfall Manipulationscheck erst am Ende oder gar nicht"
  },
  {
    "objectID": "experiment/slides.html#aufgabe",
    "href": "experiment/slides.html#aufgabe",
    "title": "Experiment: Mediennutzung und -wirkung",
    "section": "Aufgabe",
    "text": "Aufgabe\n\nWie viele Faktoren hat ihr Experiment, mit wie vielen Ausprägungen? Gibt es eine Kontrollgruppe?\nSkizzieren Sie in 15 min jeweils grob eine Within- und eine Between-Subject Variante Ihres Experiments.\nMalen Sie den Versuchsablauf auf und gehen Sie das Experiment im Geiste einmal durch.\nWas ist aus Perspektive der Forschenden vs. Probandinnen zu beachten?"
  },
  {
    "objectID": "experiment/slides.html#stichprobe",
    "href": "experiment/slides.html#stichprobe",
    "title": "Experiment: Mediennutzung und -wirkung",
    "section": "Stichprobe",
    "text": "Stichprobe\n\nbeim Experiment vor allem Stichprobenumfang (statistische Power) relevant\nDefinition Grundgesamtheit vs. realisierbare Stichprobe\nRepräsentativität und Generalisierbarkeit der Ergebnisse\nGibt es Zweifel, ob die Experimentalmanipulation unterschiedlich wirken könnte?\nModerationsanalyse (Quasi-Experiment) möglich, aber mit Aufwand verbunden"
  },
  {
    "objectID": "experiment/slides.html#aufgaben-bis-nächste-woche-1",
    "href": "experiment/slides.html#aufgaben-bis-nächste-woche-1",
    "title": "Experiment: Mediennutzung und -wirkung",
    "section": "Aufgaben bis nächste Woche",
    "text": "Aufgaben bis nächste Woche\n\nStudiendesign finalisieren und Studienablauf planen\nfinale Power-Analyse durchführen\nGrundgesamtheit, Stichprobe und Rekrutierungsplan entwerfen"
  },
  {
    "objectID": "experiment/slides.html#agenda-heute-2",
    "href": "experiment/slides.html#agenda-heute-2",
    "title": "Experiment: Mediennutzung und -wirkung",
    "section": "Agenda heute",
    "text": "Agenda heute\n\n5-Min Präsentationen\nFragen zu Grundlagen des Experiments\nTreatments und Stimuli\nKI-generierte Stimuli"
  },
  {
    "objectID": "experiment/slides.html#treatments",
    "href": "experiment/slides.html#treatments",
    "title": "Experiment: Mediennutzung und -wirkung",
    "section": "Treatments",
    "text": "Treatments\n\nStimuli selbst erstellen vs. aus existierenden auswählen und manipulieren\nAnzahl Stimuli pro Versuchsperson bzw. pro Versuchsbedingung\nsubtile vs. starke Manipulation der Stimuli\neigene (willkürliche) Auswahl vs. Pretest bzw. Fremdselektion\n(randomisierte) Präsentation der Stimuli"
  },
  {
    "objectID": "experiment/slides.html#ki-generierte-stimuli",
    "href": "experiment/slides.html#ki-generierte-stimuli",
    "title": "Experiment: Mediennutzung und -wirkung",
    "section": "KI-generierte Stimuli",
    "text": "KI-generierte Stimuli\n\ngenerative Sprachmodelle zur Texterstellung, z.B., https://ki-chat.uni-mainz.de\ngenerative Sprachmodelle zur Erstellung und direkten Bearbeitung von Mockups, z.B.  https://gemini.google/overview/canvas\ngenerative multimodale Modelle zur Bilderstellung, z.B.  https://chatgpt.com/"
  },
  {
    "objectID": "experiment/slides.html#aufgabe-bis-nächste-woche",
    "href": "experiment/slides.html#aufgabe-bis-nächste-woche",
    "title": "Experiment: Mediennutzung und -wirkung",
    "section": "Aufgabe bis nächste Woche",
    "text": "Aufgabe bis nächste Woche\n\nDesign- bzw. Auswahlstrategie für Stimuli entwickeln\nerste Stimuli auswählen bzw. erstellen (und mitbringen!)\nPräsentation der Stimuli im Experiment planen"
  },
  {
    "objectID": "experiment/slides.html#agenda-heute-3",
    "href": "experiment/slides.html#agenda-heute-3",
    "title": "Experiment: Mediennutzung und -wirkung",
    "section": "Agenda heute",
    "text": "Agenda heute\n\n5-Min Präsentationen\nMessinstrumente und Skalen\nSkalenrecherche und -auswahl\nWeiteres zur Fragebogengestaltung: Informed Consent, Datenschutz und Co."
  },
  {
    "objectID": "experiment/slides.html#messinstrumente-und-skalen",
    "href": "experiment/slides.html#messinstrumente-und-skalen",
    "title": "Experiment: Mediennutzung und -wirkung",
    "section": "Messinstrumente und Skalen",
    "text": "Messinstrumente und Skalen\n\nKonstrukte: latent vs. manifest, reflexiv vs. formativ\nMessmethode: Befragung vs. Beobachtung\nUmfang der Messung: multi-item vs. single item, Langskala vs. Kurzskala\nMenge an Messungen: Datensparsamkeit vs. Stichprobenbeschreibung, Teilnahmebürde vs. Ausschöpfung des Merkmalsraums\nPlatzierung der Messung: Reihenfolgen-, Ausstrahlungs- und andere Fragebogeneffekte (inbs. Platzierung des Manipulationschecks)\nMessniveau: Varianz des Konstruktes und Skalierung"
  },
  {
    "objectID": "experiment/slides.html#skalenrecherche-und--auswahl",
    "href": "experiment/slides.html#skalenrecherche-und--auswahl",
    "title": "Experiment: Mediennutzung und -wirkung",
    "section": "Skalenrecherche und -auswahl",
    "text": "Skalenrecherche und -auswahl\n\nSchritt 1: Konstrukte präzise definieren oder Arbeitsdefinition entwickeln, ggf. Dimensionen herausarbeiten (Konstruktexplikation)\nSchritt 2: Messungen recherchieren auf deutsch oder englisch, Tipp: zunächst Suchbegriffe identifizieren (siehe: “Jingle-jangle problem” und “Toothbrush problem”)\nSchritt 3: Übersicht aller Messungen erstellen und nach Güte evaluieren\nSchritt 4: Für Messung entscheiden, ggf. übersetzen/an Gegenstand anpassen/ auf 1-3 Items kürzen (inbs. für within-subjects Design)\nSkalen-Sammlungen z.B.: Sammlung sozialwissenschaftlicher Skalen der GESIS, Skalenhandbuch Kommunikationswissenschaft"
  },
  {
    "objectID": "experiment/slides.html#skalenrecherche-und--auswahl-wie-messungen-nach-güte-bewerten",
    "href": "experiment/slides.html#skalenrecherche-und--auswahl-wie-messungen-nach-güte-bewerten",
    "title": "Experiment: Mediennutzung und -wirkung",
    "section": "Skalenrecherche und -auswahl: Wie Messungen nach Güte bewerten?",
    "text": "Skalenrecherche und -auswahl: Wie Messungen nach Güte bewerten?\n\nValidität (v.a. Inhalts- und Konstruktvalidität)\nReliabilität\nggf. Psychometrie/Deskriptiva anschauen\nItemformulierungen: kurz, präzise und eindeutig, verständlich, passend zur Zielgruppe\nVerortung und Verwendung im Forschungsfeld, Passung zur Konstruktexplikation, Bürde, Eignung für Zielgruppe"
  },
  {
    "objectID": "experiment/slides.html#weiteres-zur-fragebogengestaltung-informed-consent-datenschutz-und-co.",
    "href": "experiment/slides.html#weiteres-zur-fragebogengestaltung-informed-consent-datenschutz-und-co.",
    "title": "Experiment: Mediennutzung und -wirkung",
    "section": "Weiteres zur Fragebogengestaltung: Informed Consent, Datenschutz und Co.",
    "text": "Weiteres zur Fragebogengestaltung: Informed Consent, Datenschutz und Co.\n\nDatenschutz: Klare Aufklärung und Zustimmung über Erhebung, Speicherung und Verwendung Ihrer Daten, Tipp: DSGVO-konforme Speicherung\nFreiwilligkeit: Teilnehmende müssen explizit einen Button klicken zum Zustimmen\nAbsicht der Studie: Ethische Cover-Story überlegen (Studie über Wahrnehmung von XY)\nPrivatsphäre und Risiken: Anonymität und körperliche/seelische Unversehrtheit versichern und gewährleisten, keine nachhaltige Veränderung der Kognitionen, Emotionen oder des Verhaltens anstreben\nAm Schluss: Debriefing und Aufklärung über das tatsächliche Forschungsinteresse"
  },
  {
    "objectID": "experiment/slides.html#formulierungsmuster-informed-consent-datenschutz-und-co.",
    "href": "experiment/slides.html#formulierungsmuster-informed-consent-datenschutz-und-co.",
    "title": "Experiment: Mediennutzung und -wirkung",
    "section": "Formulierungsmuster: Informed Consent, Datenschutz und Co.",
    "text": "Formulierungsmuster: Informed Consent, Datenschutz und Co.\n\nDeutsche Gesellschaft für Psychologie\nVerbund Forschungsdatenbildung\nVorlagen einer Kollegin aus der Kommunikationswissenschaft"
  },
  {
    "objectID": "experiment/slides.html#aufgaben-bis-übernächste-woche",
    "href": "experiment/slides.html#aufgaben-bis-übernächste-woche",
    "title": "Experiment: Mediennutzung und -wirkung",
    "section": "Aufgaben bis übernächste (!) Woche",
    "text": "Aufgaben bis übernächste (!) Woche\n\nPräregistrierung finalisieren\nExperimentaldesign und Stimuli fertigstellen\nSkalen und Items recherchieren\nFragebogen entwickeln (in Word oder SosciSurvey)"
  },
  {
    "objectID": "experiment/slides.html#agenda-heute-4",
    "href": "experiment/slides.html#agenda-heute-4",
    "title": "Experiment: Mediennutzung und -wirkung",
    "section": "Agenda heute",
    "text": "Agenda heute\n\n5-Min Präsentationen\nExperimente in Soscisurvey\nDaten aus Soscisurvey\nDatenanalyse Within-Subject-Designs"
  },
  {
    "objectID": "experiment/slides.html#experimente-in-soscisurvey",
    "href": "experiment/slides.html#experimente-in-soscisurvey",
    "title": "Experiment: Mediennutzung und -wirkung",
    "section": "Experimente in Soscisurvey",
    "text": "Experimente in Soscisurvey\n\nSoscisurvey ist sehr gut für Experimente geeignet\nvielfältige Randomisierungsmöglichkeiten, flexible Programmierung\nDatenexport per API und R-Paket"
  },
  {
    "objectID": "experiment/slides.html#randomisierung-in-soscisurvey",
    "href": "experiment/slides.html#randomisierung-in-soscisurvey",
    "title": "Experiment: Mediennutzung und -wirkung",
    "section": "Randomisierung in Soscisurvey",
    "text": "Randomisierung in Soscisurvey\n\nUrne anlegen (Name z.B. gruppe) mit k Ausprägungen (Anzahl Faktorenkombinationen/Pseudogruppen)\nInterne Variable IV01 anlegen.\nAuf erster Fragebogenseite per PHP aus Urne ziehen:\n\nurnDraw('gruppe', 'IV01');\n\nAuf Stimulusseite per PHP zuordnen:\n\nif (value('IV01_01') == 1) {\n  html('Stimulus 1A');\n} elseif (value('IV01_01') == 2) {\n  html('Stimulus 1B');\n}\n\nItems auf dieselbe oder die folgende Seite."
  },
  {
    "objectID": "experiment/slides.html#within-subject-experiment-in-soscisurvey",
    "href": "experiment/slides.html#within-subject-experiment-in-soscisurvey",
    "title": "Experiment: Mediennutzung und -wirkung",
    "section": "Within-Subject-Experiment in Soscisurvey",
    "text": "Within-Subject-Experiment in Soscisurvey\n\nGleiche Schritte wie oben, aber für jede Messwiederholung:\n\nFrageblock kopieren\nStimulusseite anlegen mit PHP-Code nach Versuchsplan\nJe eine Kopie des Frageblocks pro Stimulusseite\n\nVariablen sollten dann so heißen: BLOCK_i_j, wobei i die Stimulusseite ist, j die Itemnummer\nvorzugsweise ein Variablenblock mit demselben Response-Format, alternativ mehrere (unterschiedliche Kürzel vorn)"
  },
  {
    "objectID": "experiment/slides.html#stimuli-einbinden",
    "href": "experiment/slides.html#stimuli-einbinden",
    "title": "Experiment: Mediennutzung und -wirkung",
    "section": "Stimuli einbinden",
    "text": "Stimuli einbinden\n\nBilder und Videos können in Soscisurvey hochgeladen werden oder extern gehostet\nsystematisch Dateinamen verwenden, etwa thema_bedingung1_bedingung2.jpg, also sport_0_1.jpg\neinbinden mit HTML\n\n&lt;img src=\"sport_0_1.jpg\"/&gt; \n\n&lt;video playsinline controls controlsList=\"nodownload\" style=\"max-width: 100%;\"&gt;\n  &lt;source src=\"sport_0_1.mp4\" type=\"video/mp4\" /&gt;\n&lt;/video&gt;"
  },
  {
    "objectID": "experiment/slides.html#datenanalyse",
    "href": "experiment/slides.html#datenanalyse",
    "title": "Experiment: Mediennutzung und -wirkung",
    "section": "Datenanalyse",
    "text": "Datenanalyse\n\nDaten liegen zunächst im Breitformat vor, d.h. jedes Item aus jedem Block eine Variable\nfür die Auswertung benötigen wir die Daten im Langformat:\n\n\n\n\n\n\n\nCASE\ngruppe\nseite\nbedingung\nitem_1\nitem_2\nitem_3\n\n\n\n\n101\n1\n1\nA\n5\n4\n3\n\n\n101\n1\n2\nB\n2\n5\n1\n\n\n103\n2\n1\nB\n4\n3\n5"
  },
  {
    "objectID": "experiment/slides.html#versuchsplan-als-daten",
    "href": "experiment/slides.html#versuchsplan-als-daten",
    "title": "Experiment: Mediennutzung und -wirkung",
    "section": "Versuchsplan als Daten",
    "text": "Versuchsplan als Daten\n\num die Soscisurvey-Daten möglichst einfach mit den Versuchsbedingungen zu verknüpfen, erstellen wir eine Excel-Datei mit dem Versuchsplan:\n\n\n\n\n\n\n\ngruppe\nseite\nki_ursprung\nki_markierung\n\n\n\n\n1\n1\n1\n1\n\n\n1\n2\n1\n0\n\n\n1\n3\n0\n1\n\n\n1\n4\n0\n0\n\n\n2\n1\n0\n0\n\n\n\n\n\n\n\nzwingend erforderlich sind die Pseudogruppe (gruppe) und die Stimulusseite (seite), in den weiteren Spalten stehen die Versuchsbedingen, Thema, o.ä.\ndie meisten Gruppen hatten das im Rahmen des Designs schon (ggf. in anderem Format) angelegt"
  },
  {
    "objectID": "experiment/slides.html#kombinierte-daten-im-langformat",
    "href": "experiment/slides.html#kombinierte-daten-im-langformat",
    "title": "Experiment: Mediennutzung und -wirkung",
    "section": "Kombinierte Daten im Langformat",
    "text": "Kombinierte Daten im Langformat\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCASE\ngruppe\nseite\nbedingung\nitem_1\nitem_2\nitem_3\nki_ursprung\nki_markierung\n\n\n\n\n101\n1\n1\nA\n5\n4\n3\n1\n1\n\n\n101\n1\n2\nB\n2\n5\n1\n1\n0\n\n\n103\n2\n1\nB\n4\n3\n5\n0\n0\n\n\n\n\n\n\n\nKovariaten auf Personenebene können wir einfach wieder hinzufügen, da die CASE-Variable vorhanden ist"
  },
  {
    "objectID": "experiment/slides.html#datenanalyse-1",
    "href": "experiment/slides.html#datenanalyse-1",
    "title": "Experiment: Mediennutzung und -wirkung",
    "section": "Datenanalyse",
    "text": "Datenanalyse\n\nim Between-Design können wir einfach T-Test oder ANOVA durchführen lm(y ~ bedingung)\nim Within-Subject-Design ist das nicht möglich, weil durch die Messwiederholungen die Unabhängkeitsannahme verletzt ist\nstattdessen schätzen wir ein Multilevel- oder Mixed Effects Modell lmer(y ~ bedingung + (1|CASE)\nInterpretation der Effekt etc. ist identisch, auch die Visualisierung ist problemlos möglich"
  },
  {
    "objectID": "experiment/slides.html#praktische-übung",
    "href": "experiment/slides.html#praktische-übung",
    "title": "Experiment: Mediennutzung und -wirkung",
    "section": "Praktische Übung",
    "text": "Praktische Übung\n\nerstellen oder öffnen Sie Ihr Soscisurvey-Projekt\nwir erstellen gemeinsam Urne, Randomisierung und Frageblöcke sowie API-Zugriff\narbeiten Sie https://stats.ifp.uni-mainz.de/ba-ccs-track/exp-analyse.html durch (gern auch in der Gruppe)\nerstellen Sie eine codeplan.xlsx Datei\npassen Sie den Beispiel-Code für Ihre Studie an"
  },
  {
    "objectID": "experiment/slides.html#aufgaben-bis-nächste-woche-2",
    "href": "experiment/slides.html#aufgaben-bis-nächste-woche-2",
    "title": "Experiment: Mediennutzung und -wirkung",
    "section": "Aufgaben bis nächste Woche",
    "text": "Aufgaben bis nächste Woche\n\nFragebogen inkl. Stimuli und Messinstrumente finalisieren.\nTechnischen Pretest durchführen, eigentlichen Pretest (n ~ 5) durchführen\nCode für Datenanalyse vorbereiten"
  },
  {
    "objectID": "experiment/slides.html#datenauswertung",
    "href": "experiment/slides.html#datenauswertung",
    "title": "Experiment: Mediennutzung und -wirkung",
    "section": "Datenauswertung",
    "text": "Datenauswertung\n\nPlausibilitätscheck, Bereinigung, Stichprobenbeschreibung\nHypothesentests samt Mittelwertvergleichen etc.\nErgebnistabellen oder Grafiken\nggf. explorative Zusatzauswertungen"
  },
  {
    "objectID": "experiment/slides.html#aufgaben-bis-nächste-woche-3",
    "href": "experiment/slides.html#aufgaben-bis-nächste-woche-3",
    "title": "Experiment: Mediennutzung und -wirkung",
    "section": "Aufgaben bis nächste Woche",
    "text": "Aufgaben bis nächste Woche\n\nDatenauswertung\nAbschlusspräsentation (max. 10 Minuten, minimale Herleitung)\nFragen zum Ergebnisbericht etc. mitbringen"
  },
  {
    "objectID": "experiment/slides.html#projektbericht",
    "href": "experiment/slides.html#projektbericht",
    "title": "Experiment: Mediennutzung und -wirkung",
    "section": "Projektbericht",
    "text": "Projektbericht\n\nmaximal (!) 10.000 Wörter insgesamt ohne Anhang\nZusammenfassung des Experiments, kein Praktikumsbericht\nRecycling der Preregistration und Zwischenberichte erwünscht\nStruktur und Inhalte wie ein Journal-Beitrag\nFormalien und Regeln wissenschaftlicher Arbeit sind sehr wichtig und notenrelevant."
  },
  {
    "objectID": "experiment/slides.html#struktur",
    "href": "experiment/slides.html#struktur",
    "title": "Experiment: Mediennutzung und -wirkung",
    "section": "Struktur",
    "text": "Struktur\n\nEinleitung - Forschungsfrage, nicht unbedingt Relevanz\nLiteratur + (Theorie) + Hypothesen (aus Literatur/Theorie entwickelt!)\nMethode - Design - Stimuli - Messung - Stichprobe - ggf. Datenmanagement/Analyse (stat. Verfahren müssen nicht erklärt werden)\nErgebnisse - Basics, Hypothesentests etc., explorative Analysen\nDiskussion - Zusammenfassung, Limitationen, wiss./praktische Implikationen"
  },
  {
    "objectID": "experiment/slides.html#tabellenabbildungen",
    "href": "experiment/slides.html#tabellenabbildungen",
    "title": "Experiment: Mediennutzung und -wirkung",
    "section": "Tabellen/Abbildungen",
    "text": "Tabellen/Abbildungen\n\ngern und viel verwenden (an Leser/Leserin denken!)\nkeine rohen SPSS/R Outputs, sondern APA-Tabellen\nAbbildung auf mögliche Redundanzen prüfen (z.B. Zahlenlabels)\nTab/Abb sind nummeriert, beschriftet, enthalten Fallzahl und ggf. Lesehilfe\nTab/Abb, über die sie schreiben, gehören in die Arbeit, andere in den Anhang\nTabellen/Abbildungen im Anhang müssen nicht groß aufbereitet werden, aber nummeriert, beschriftet, etc."
  },
  {
    "objectID": "experiment/slides.html#häufige-fehler",
    "href": "experiment/slides.html#häufige-fehler",
    "title": "Experiment: Mediennutzung und -wirkung",
    "section": "Häufige Fehler",
    "text": "Häufige Fehler\n\nzu wenig Theorie/Literatur - Suche ggf. erweitern\nHypothesen “fallen vom Himmel” - Belege oder eig. Herleitung\nlogische Brüche - passt Design/Stichprobe/Messung, etc. zueinander\nzuviel Arbeitsbericht (“die Rekrutierung war schwierig und die Absprachen im Team wurden nicht immer eingehalten”)\nunzureichende Ergebnisdarstellung nach APA (zu wenige/viele/falsche Koeffizienten in Tabelle)\nlangweilige Diskussionsteile (triviale Selbstkritik, kaum Ausblick/Anschluss an Einleitung/Literaturteil)\nformale Fehler (Zitationen, Beschriftungen, Rechtschreibung/Grammatik)"
  },
  {
    "objectID": "experiment/slides.html#arbeitsteilungbenotung",
    "href": "experiment/slides.html#arbeitsteilungbenotung",
    "title": "Experiment: Mediennutzung und -wirkung",
    "section": "Arbeitsteilung/Benotung",
    "text": "Arbeitsteilung/Benotung\n\nGruppennote ist der Standard, wenn alles nach Plan läuft\nformale Benennung der Verantwortlichkeiten, wird nicht geprüft\nOptionen für Einzelnoten:\n\nEinzelnoten für Gruppenbericht - Bescheid geben wg. Verantwortlichkeiten\nEinzelarbeit - entweder kurzer Gesamtbericht oder alternative(s) Kapitel\n\nes müssen nicht alle gleich viel schreiben, auch andere Arbeiten sind wertvoll"
  },
  {
    "objectID": "experiment/slides.html#literatur-1",
    "href": "experiment/slides.html#literatur-1",
    "title": "Experiment: Mediennutzung und -wirkung",
    "section": "Literatur",
    "text": "Literatur\n\n\n\n\nBullock, J. G., Green, D. P., & Ha, S. E. (2010). Yes, but what’s the mechanism? (don’t expect an easy answer). Journal of Personality and Social Psychology, 98(4), 550–558. https://doi.org/10.1037/a0018933\n\n\nKoch, T., Peter, C., & Müller, P. (2019). Das Experiment in der Kommunikations- und Medienwissenschaft. Springer Fachmedien Wiesbaden. https://doi.org/10.1007/978-3-658-19754-4\n\n\nLarooij, M., & Törnberg, P. (2025). Do Large Language Models Solve the Problems of Agent-Based Modeling? A Critical Review of Generative Social Simulations. https://doi.org/10.48550/ARXIV.2504.03274\n\n\nRijnhart, J. J. M., Lamp, S. J., Valente, M. J., MacKinnon, D. P., Twisk, J. W. R., & Heymans, M. W. (2021). Mediation analysis methods used in observational research: a scoping review and recommendations. BMC Medical Research Methodology, 21(1). https://doi.org/10.1186/s12874-021-01426-3\n\n\nWaldherr, A., & Wettstein, M. (2019). Bridging the Gaps: Using Agent-Based Modeling to Reconcile Data and Theory in Computational Communication Science. International Journal of Communication, 13(00), 24. https://ijoc.org/index.php/ijoc/article/view/10588\n\n\nWang, J., & Sundar, S. S. (2022). Liking versus commenting on online news: effects of expression affordances on political attitudes. Journal of Computer-Mediated Communication, 27(6). https://doi.org/10.1093/jcmc/zmac018"
  },
  {
    "objectID": "ccs/slides.html#ccs-module",
    "href": "ccs/slides.html#ccs-module",
    "title": "Computational Communication Science",
    "section": "CCS Module",
    "text": "CCS Module\n\nComputational Communication Science is mostly\n\nintroduction to basic literature and methods\nvery practical exercises in computational methods\n\nDatafied Society is more\n\ntheory and research-focused\n(and probably has a unifying topic)\n\nWrite your term paper in either of the classes."
  },
  {
    "objectID": "ccs/slides.html#course-credit-and-requirements",
    "href": "ccs/slides.html#course-credit-and-requirements",
    "title": "Computational Communication Science",
    "section": "Course credit and requirements",
    "text": "Course credit and requirements\n\nactive participation, i.e. by presenting a poster on a CCS study\nsmaller homework assignments, i.e. practical computational methods\nterm paper, preferably a data-driven analysis of your choice\n\neither as traditional 3000 word research paper or\nalternative forms, e.g. Scrollytelling\nfantastic example (in German): Blaue Bücher, rosa Bücher\n\nteam work (in small teams) is more fun ad highly encouraged"
  },
  {
    "objectID": "ccs/slides.html#english",
    "href": "ccs/slides.html#english",
    "title": "Computational Communication Science",
    "section": "English",
    "text": "English\n\nEnglish is used for all spoken and written communication in the module\nEnglish proficiency is never judged or graded\nthe core difficulties in understanding the literature are rarely language-related\nCCS is almost exclusively based on English publications, with two notable intro book exceptions: Jünger & Gärtner (2023); Haim (2023)"
  },
  {
    "objectID": "ccs/slides.html#computational-communication-science",
    "href": "ccs/slides.html#computational-communication-science",
    "title": "Computational Communication Science",
    "section": "Computational Communication Science?",
    "text": "Computational Communication Science?\n\nA field is emerging that leverages the capacity to collect and analyze data at a scale that may reveal patterns of individual and group behaviors. (Lazer et al., 2009)\n\n\n[W]e define computational communication science as the endeavor to understand human communication by developing and applying digital tools that often involve a high degree of automation in observational, theoretical, and experimental research. (Hilbert et al., 2019)"
  },
  {
    "objectID": "ccs/slides.html#computational-communication-science-1",
    "href": "ccs/slides.html#computational-communication-science-1",
    "title": "Computational Communication Science",
    "section": "Computational Communication Science",
    "text": "Computational Communication Science\n\ndefinition based on methods rather than study subject or theoretical background\nsomehow “big data” are involved, as are automatic methods\nterminology and many methods mostly derived from the natural sciences and engineering\ninnovation often (but not always) happens outside academia, e.g. within companies such as Google or Meta"
  },
  {
    "objectID": "ccs/slides.html#computational-methods",
    "href": "ccs/slides.html#computational-methods",
    "title": "Computational Communication Science",
    "section": "Computational methods",
    "text": "Computational methods\n\nthe “Big 3” approaches in CCS:\n\nautomatic content analysis\nanalysis of digital traces and digital behavioral data\nsimulation and agent-based modelling\n\nhistorically, very strong emphasis on web data and automatic content analysis (Van Atteveldt et al., 2022)\nagent-based modeling still very niche topics (see your own study choices for next week!)"
  },
  {
    "objectID": "ccs/slides.html#schedule",
    "href": "ccs/slides.html#schedule",
    "title": "Computational Communication Science",
    "section": "Schedule",
    "text": "Schedule\n\n\n\n\n\n\n\n\n\n\nSession\nDate\nTopic\n\n\n\n\n1\n2025-04-23\nIntroduction\n\n\n2\n2025-04-30\nCCS Paper Potpourri\n\n\n3\n2025-05-07\nEthical and legal perspectives\n\n\n4\n2025-05-21\nDigital trace data\n\n\n5\n2025-05-28\nDigital trace data\n\n\n6\n2025-06-04\nAutomatic content analysis\n\n\n7\n2025-06-11\nAutomatic content analysis\n\n\n8\n2025-06-18\nAutomatic content analysis\n\n\n9\n2025-06-25\nAutomatic content analysis\n\n\n10\n2025-07-02\nSimulation and computational experiments\n\n\n11\n2025-07-09\nSimulation and computational experiments\n\n\n12\n2025-07-16\nQ & A"
  },
  {
    "objectID": "ccs/slides.html#challenges",
    "href": "ccs/slides.html#challenges",
    "title": "Computational Communication Science",
    "section": "Challenges",
    "text": "Challenges\n\ndata access for academic research (Freelon, 2018)\nlegal and ethical challenges in using private or semi-public data\ntechnical and methodological issues in analyzing very large datasets\nnecessary skills for students and scholars, lack of curricula\ncomputational studies are often (by necessity) interdisciplinary\nalso: literacy for reviewing computational studies in communication research"
  },
  {
    "objectID": "ccs/slides.html#caveats",
    "href": "ccs/slides.html#caveats",
    "title": "Computational Communication Science",
    "section": "Caveats",
    "text": "Caveats\n\nthe field is moving extremely fast, that means\n\nmany approaches are outdated within a few years\nplatforms restrict access to data and prohibit distribution of replication data\nreplication of many studies is difficult\n\nstarting from methods or data feels strange (and for some uncomfortable) compared to traditional empirical research\nyou will need (and learn) coding skills at least in R, but might need Python later"
  },
  {
    "objectID": "ccs/slides.html#benefits",
    "href": "ccs/slides.html#benefits",
    "title": "Computational Communication Science",
    "section": "Benefits",
    "text": "Benefits\n\ncomputational skills are extremely valuable on the job market, both in academia and in the real world\nthe CCS perspective challenges many traditional assumptions about how research works, i.e. by valuing creative re-operationalization of existing measures\nwith a full methods toolbox, you can conduct high-quality research even on niche topics\nideally the course will help you conduct better studies in your large empirical modules"
  },
  {
    "objectID": "ccs/slides.html#course-setup",
    "href": "ccs/slides.html#course-setup",
    "title": "Computational Communication Science",
    "section": "Course setup",
    "text": "Course setup\n\n“cold opening” introduction by actually reading CCS papers\nthen, for every approach:\n\nI prepare a small presentation on the basics\nyou work through an application using R at home\nwe discuss the practical tasks in the following session\nwe creatively apply the new methods to our own topics\n\nBring your own ideas, data, research questions to class!"
  },
  {
    "objectID": "ccs/slides.html#ccs-paper-potpourri",
    "href": "ccs/slides.html#ccs-paper-potpourri",
    "title": "Computational Communication Science",
    "section": "CCS Paper Potpourri",
    "text": "CCS Paper Potpourri\n\n10 posters overall, we’ll probably do 2x 45min sessions.\nplease bring the digital versions as well, just in case\nremember to get the posters printed ASAP\nany questions about the studies or posters?"
  },
  {
    "objectID": "ccs/slides.html#ccs-paper-potpourri-1",
    "href": "ccs/slides.html#ccs-paper-potpourri-1",
    "title": "Computational Communication Science",
    "section": "CCS Paper Potpourri",
    "text": "CCS Paper Potpourri\n\n2x 30 minutes/5 papers in the hallway\npresenters:\n\nthink of a 30 second summary pitch to get the conversation started\nnote/remember questions that came up repeatedly or were noteworthy\n\naudience\n\nprovide interactions on the poster site (in English)!\nnote/remember questions you’d like to discuss in class"
  },
  {
    "objectID": "ccs/slides.html#discussion",
    "href": "ccs/slides.html#discussion",
    "title": "Computational Communication Science",
    "section": "Discussion",
    "text": "Discussion\n\nWhich paper/study do you remember best (and why)?\nWhich study was the most difficult to understand (and why)?\nWhich study would you like to replicate?"
  },
  {
    "objectID": "ccs/slides.html#next-week",
    "href": "ccs/slides.html#next-week",
    "title": "Computational Communication Science",
    "section": "Next week",
    "text": "Next week\n\nRead Salganik (2018), Chapter 6 and Freelon (2018).\nRead about (at least skim the posts) the very recent Reddit/AI experiment issue:\n\nsummary article and follow up\noriginal thread on Reddit"
  },
  {
    "objectID": "ccs/slides.html#salganik2018-i",
    "href": "ccs/slides.html#salganik2018-i",
    "title": "Computational Communication Science",
    "section": "Salganik (2018) I",
    "text": "Salganik (2018) I"
  },
  {
    "objectID": "ccs/slides.html#salganik2018-i-1",
    "href": "ccs/slides.html#salganik2018-i-1",
    "title": "Computational Communication Science",
    "section": "Salganik (2018) I",
    "text": "Salganik (2018) I\n\nWhat are the main differences between Consequentialism and Deontology?\nHow can the four mentioned ethical principles be applied to the experiment run by Munger (2017)?\nIn case of doubt, what priority should these principles have among themselves?"
  },
  {
    "objectID": "ccs/slides.html#salganik2018-ii",
    "href": "ccs/slides.html#salganik2018-ii",
    "title": "Computational Communication Science",
    "section": "Salganik (2018) II",
    "text": "Salganik (2018) II"
  },
  {
    "objectID": "ccs/slides.html#research-ethics-in-practice",
    "href": "ccs/slides.html#research-ethics-in-practice",
    "title": "Computational Communication Science",
    "section": "Research Ethics in Practice",
    "text": "Research Ethics in Practice\n\nIs informed consent needed for a content analysis of social media posts from members parliament?\nWhat about comments on posts or public pages, e.g., from parties or politicians?\nWhat about Tinder profiles or other online dating platforms?\nWhat if informed consent is practically not possible?"
  },
  {
    "objectID": "ccs/slides.html#group-task",
    "href": "ccs/slides.html#group-task",
    "title": "Computational Communication Science",
    "section": "Group Task",
    "text": "Group Task\n(four groups, 10 minutes)\n\nSummarise the design and execution of the Reddit AI experiment.\nWhat were the main points of criticism from the Reddit mods/legal people?\nWhat were the main rebuttals from the researcher team and UZH?\nCan you salvage the study idea and run it ethically? How?"
  },
  {
    "objectID": "ccs/slides.html#api-and-non-api-access",
    "href": "ccs/slides.html#api-and-non-api-access",
    "title": "Computational Communication Science",
    "section": "API and non-API access",
    "text": "API and non-API access\n\nfree model (e.g. Wikipedia): everyone can get the data\npaid model (e.g. Twitter/X): you pay the platform or a third party for access\ngrant model (e.g. TikTok): you can apply for access to the API as a scholar\ncollab model (e.g. Meta): you can work with the platforms on spefific research questions\ndata donation model: you ask participants to donate their DDP (Data Download Packages)\nindependent/rogue model: you access a secret API or scrape the data otherwise"
  },
  {
    "objectID": "ccs/slides.html#post-api-era",
    "href": "ccs/slides.html#post-api-era",
    "title": "Computational Communication Science",
    "section": "Post-API era",
    "text": "Post-API era\n\nmost models have failed due to platforms (change of) self-interests (Freelon, 2018)\n\ncommercial interests (i.e. monetization) or concerns about bad PR\nprivacy concerns for well-meaning platforms https://en.wikipedia.org/wiki/Netflix_Prize\n“research data” incomplete and at times worse than public data\n\nbig collaborations like Social Science One failed miserably and publicly\nother were challenging (Wagner, 2023) and ultimately problematic (Bagchi et al., 2024)"
  },
  {
    "objectID": "ccs/slides.html#issues-with-online-data",
    "href": "ccs/slides.html#issues-with-online-data",
    "title": "Computational Communication Science",
    "section": "Issues with online data",
    "text": "Issues with online data\n\nnot all available online data can/should be considered public\nprivacy vs. reproducibility vs. ethics vs. legal questions\nmany instances of well-meaning research with unethically obtained data\nmany instances of unethical research\nsecond and third order effects, e.g. LLM training data or vision models\nplus biases, errors, etc."
  },
  {
    "objectID": "ccs/slides.html#questions-1",
    "href": "ccs/slides.html#questions-1",
    "title": "Computational Communication Science",
    "section": "Questions",
    "text": "Questions\n\nWhen can you scrape and use online data (against the platforms terms)?\nCan you use an AI model based on unethical, possibly illegal training data?\nHow can you ensure reproducible findings with problematic data?"
  },
  {
    "objectID": "ccs/slides.html#next-session-in-2-weeks",
    "href": "ccs/slides.html#next-session-in-2-weeks",
    "title": "Computational Communication Science",
    "section": "Next session (in 2 weeks!)",
    "text": "Next session (in 2 weeks!)\n\nGet data dwnload packages (DDP) for all major online platforms/services that you use (at least 2), e.g. from Google/Youtube, Instagram, TikTok, Spotify, Netflix, etc.\nHow? Google “data download package [PLATFORM]”\nRequest JSON files if given the option between multiple formats\nRead Ohme et al. (2023)"
  },
  {
    "objectID": "ccs/slides.html#digital-trace-data",
    "href": "ccs/slides.html#digital-trace-data",
    "title": "Computational Communication Science",
    "section": "Digital trace data",
    "text": "Digital trace data\n\npeople’s online activities are constantly logged client- and server-side\ndigital trace data from users are unobtrusively and continuously collected (by platforms or researchers)\ntrace data are (less) subject to common biases in self-reports, e.g. memory or social desirability (Scharkow, 2016)\ntrace data are subject to different biases, most notably selection bias (i.e. who we get data from)\nexcellent Gesis Guides"
  },
  {
    "objectID": "ccs/slides.html#api-data",
    "href": "ccs/slides.html#api-data",
    "title": "Computational Communication Science",
    "section": "API data",
    "text": "API data\n\nmostly only public content data with few meta data, e.g. time stamps and account information\npure usage data very rarely available from an API, and mostly only aggregated\nvery rare for any large platforms, severe privacy concerns for individual-level data\nexample 1: Wikipedia Views API, aggregate views per day\nexample 2: Spotify API, 50 recently played tracks only from the logged-in user, can be used for automatic data donations (Ernst et al., 2024)"
  },
  {
    "objectID": "ccs/slides.html#web-tracking-data",
    "href": "ccs/slides.html#web-tracking-data",
    "title": "Computational Communication Science",
    "section": "Web tracking data",
    "text": "Web tracking data\n\ncollected from devices using dedicated tools (e.g. browser plugins) or system logs\ntechnically difficult: mostly per-device, not per user tracking (Scharkow, 2016)\nsevere privacy concerns, even with temporary user opt-out and/or whitelisting\nmost researchers obtain tracking data from third parties (e.g. Respondi panel)\nextensive processing necessary (Clemm von Hohenberg et al., 2024)\nraw data is rarely public (exception: https://zenodo.org/records/4757574)"
  },
  {
    "objectID": "ccs/slides.html#data-donations",
    "href": "ccs/slides.html#data-donations",
    "title": "Computational Communication Science",
    "section": "Data donations",
    "text": "Data donations\n\ncollected from users who requested their data download packages (DDP) from platforms\nfor large platforms, potentially very large DDP, which require filtering before upload\nDDP uploaded via browser, using dedicated tools (e.g. DDM) or custom scripts\n(presumably) fewer trust and privacy issues, but requires motivated and skilled respondents (Pfiffner & Friemel, 2023)\nsingle-platform, single-user, but multi-device data\nmostly in standardized (JSON) format, but with ever-changing variables and labels"
  },
  {
    "objectID": "ccs/slides.html#platform-tracking-donations",
    "href": "ccs/slides.html#platform-tracking-donations",
    "title": "Computational Communication Science",
    "section": "Platform tracking + donations",
    "text": "Platform tracking + donations\n\nZeeschuimer browser extension tracks exposure to specific platforms\nTikTok, Instagram, X/Twitter, LinkedIn, Pinterest, etc.\nwhile active, logs exposure to content, along with content metadata\nlogs can be sent to online server, or downloaded and donated manually\nworks well for lab experiments, linkage studies, etc. that combine use + content data\nrequires very active participation and data management strategies"
  },
  {
    "objectID": "ccs/slides.html#collecting-digital-trace-data",
    "href": "ccs/slides.html#collecting-digital-trace-data",
    "title": "Computational Communication Science",
    "section": "Collecting digital trace data",
    "text": "Collecting digital trace data\n\nSource: Ohme et al. (2023)"
  },
  {
    "objectID": "ccs/slides.html#questions-2",
    "href": "ccs/slides.html#questions-2",
    "title": "Computational Communication Science",
    "section": "Questions",
    "text": "Questions\n\nFor which platforms did you obtain DDP?\nHow difficult was it, how hard would it be for a regular respondent?\nHave you looked at the data? What did you find (interesting)?"
  },
  {
    "objectID": "ccs/slides.html#homework",
    "href": "ccs/slides.html#homework",
    "title": "Computational Communication Science",
    "section": "Homework",
    "text": "Homework\n\nYou need to complete three homework assignments, at least one per topic (trace data, content analysis, simulation/experiments).\nYou can submit each homework until the start of the next topic (e.g. from now until we start with content analysis).\nYou can submit in any format you like (I suggest Quarto HTML), but it should be self-explanatory.\nYou can and are encouraged to work in pairs.\nHomework is, as always, pass or fail."
  },
  {
    "objectID": "ccs/slides.html#practice",
    "href": "ccs/slides.html#practice",
    "title": "Computational Communication Science",
    "section": "Practice",
    "text": "Practice\nTrace data I\n\nData Download Packages\nZeeschuimer browser logs\n\nTrace data II\n\nAggregating and processing digital trace data\nLinking digital traces to survey or content data"
  },
  {
    "objectID": "ccs/slides.html#json-data",
    "href": "ccs/slides.html#json-data",
    "title": "Computational Communication Science",
    "section": "JSON data",
    "text": "JSON data\n\n(How) did you successfully read your a single JSON file?\nHow can we read multiples files? list.files() & map() functions"
  },
  {
    "objectID": "ccs/slides.html#session-detection",
    "href": "ccs/slides.html#session-detection",
    "title": "Computational Communication Science",
    "section": "Session detection",
    "text": "Session detection\n\nDescribe the basic algorithm to detect sessions.\nWhat assumptions do we have to make about user behavior?\nHow can we define sessions for (a) browser or (b) phone log files?\n\nParry & Toth (2025);Clemm von Hohenberg et al. (2024)"
  },
  {
    "objectID": "ccs/slides.html#combining-data",
    "href": "ccs/slides.html#combining-data",
    "title": "Computational Communication Science",
    "section": "Combining data",
    "text": "Combining data\n\nWhat is the difference between join(), left_join() and right_join()?\nWhat kinds of data would you try to combine for a research project?"
  },
  {
    "objectID": "ccs/slides.html#data-collection-for-content-analysis",
    "href": "ccs/slides.html#data-collection-for-content-analysis",
    "title": "Computational Communication Science",
    "section": "Data Collection for Content Analysis",
    "text": "Data Collection for Content Analysis\nMethods for data collection (using R), from simplest to most complex:\n\nDirectly import machine-readable files from the web (e.g., CSV).\nUse pre-built R packages for specific platforms/providers.\nObtain semi-standardized data via APIs.\nDownload and process HTML content from websites using web scraping.\nCollect content or take screenshots using remotely controlled browsers.\nRequest data donations from users."
  },
  {
    "objectID": "ccs/slides.html#machine-readable-files",
    "href": "ccs/slides.html#machine-readable-files",
    "title": "Computational Communication Science",
    "section": "Machine-readable files",
    "text": "Machine-readable files\n\nDownload and read structured data files (like CSV, JSON, XML) that are publicly available online\nBenefit: Often the easiest and most reliable way to obtain data when available\nDrawbacks: Limited availability, needs some searching\nExamples:\n\nStranger Things Dialogue\nParlSpeech V2 dataset\nNSF Grant Terminations"
  },
  {
    "objectID": "ccs/slides.html#specific-r-packages",
    "href": "ccs/slides.html#specific-r-packages",
    "title": "Computational Communication Science",
    "section": "Specific R packages",
    "text": "Specific R packages\n\nBenefit: Simple to install in R, pre-processed or readily accessible text data\nDrawbacks: Very limited scope, sometimes not up-to-date\nExamples:\n\ngutenbergr: Accessing literary works from Project Gutenberg.\nmanifestoR: Contains annotated party manifestos from many countries and years from the Manifesto project\ntaylor: Provides song data, including lyrics for the Taylor Swift discography"
  },
  {
    "objectID": "ccs/slides.html#rss-feeds",
    "href": "ccs/slides.html#rss-feeds",
    "title": "Computational Communication Science",
    "section": "RSS Feeds",
    "text": "RSS Feeds\n\nBenefit: Provides standardized, structured updates for frequently changing content.\nDrawbacks: Content often limited to headlines/summaries, may not include full text; feeds can be discontinued or change formats.\n\n&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;\n&lt;rss version=\"2.0\"&gt;\n  &lt;channel&gt;\n    &lt;title&gt;Minimal News Feed&lt;/title&gt;\n    &lt;link&gt;http://www.example.com/news&lt;/link&gt;\n    &lt;item&gt;\n      &lt;title&gt;First Example News Story&lt;/title&gt;\n      &lt;link&gt;http://www.example.com/news/story1.html&lt;/link&gt;\n      &lt;description&gt;This is a brief summary of the first example news story.&lt;/description&gt;\n    &lt;/item&gt;\n  &lt;/channel&gt;\n&lt;/rss&gt;"
  },
  {
    "objectID": "ccs/slides.html#json-apis",
    "href": "ccs/slides.html#json-apis",
    "title": "Computational Communication Science",
    "section": "JSON APIs",
    "text": "JSON APIs\n\nBenefit: Provides structured, flexible data (JSON format); often allows for specific queries and filters.\nDrawbacks: Requires understanding of API documentation; rate limits and authentication (API keys) are common; APIs can change or be deprecated.\n\n\n\n[\n    {\n        \"quote\": \"Don't drink and drive but if you do, call me.\",\n        \"author\": \"Saul Goodman\"\n    },\n    {\n        \"quote\": \"Is that your fly-sabre?\",\n        \"author\": \"Jesse Pinkman\"\n    }\n]"
  },
  {
    "objectID": "ccs/slides.html#web-scraping",
    "href": "ccs/slides.html#web-scraping",
    "title": "Computational Communication Science",
    "section": "Web Scraping",
    "text": "Web Scraping\n\ninvolves extracting data from websites, and it’s particularly useful for content where APIs might not be available.\nHTML content is downloaded and parsed to extract specific elements (e.g., headlines, article bodies, dates).\nChallenges:\n\nLayout updates can break scraping code.\nWebsites may block or limit automated access.\nContent loaded via JavaScript can be harder to scrape directly."
  },
  {
    "objectID": "ccs/slides.html#scraping-with-remote-controlled-browsers",
    "href": "ccs/slides.html#scraping-with-remote-controlled-browsers",
    "title": "Computational Communication Science",
    "section": "Scraping with remote-controlled browsers",
    "text": "Scraping with remote-controlled browsers\n\nUtilizes automated browsers (e.g., Chrome, Firefox) to navigate websites, interact with elements, and extract content, mimicking human user behavior.\nBenefit: Can handle dynamic content (JavaScript, AJAX), login walls, and other complex interactive elements that traditional web scraping struggles with.\nDrawbacks:\n\nSignificantly slower than direct HTML fetching as it renders the entire page.\nRequires setting up browser drivers (e.g., ChromeDriver, GeckoDriver).\nStill detectable by sophisticated anti-bot systems."
  },
  {
    "objectID": "ccs/slides.html#data-donations-1",
    "href": "ccs/slides.html#data-donations-1",
    "title": "Computational Communication Science",
    "section": "Data Donations",
    "text": "Data Donations\n\nInvolves requesting and collecting data directly from users, who volunteer to share their digital information for research purposes.\nBenefit: Provides access to data from closed platforms (e.g., mobile apps, private social media groups) or highly personalized content that is otherwise inaccessible.\nDrawbacks:\n\nData format and completeness can vary widely across platforms/donors.\nSample may not be representative of the broader population.\nRequires robust infrastructure to collect and process diverse donated data."
  },
  {
    "objectID": "ccs/slides.html#multimodal-data",
    "href": "ccs/slides.html#multimodal-data",
    "title": "Computational Communication Science",
    "section": "Multimodal data",
    "text": "Multimodal data\n\nMany platforms provide text as well as images or audiovisual data.\nImages and audiovisual data need to be downloaded before analysis.\nWe can use the multimodal data directly or convert them to text (e.g. transcripts or image descriptions).\nConversion to text makes things easier for us, but loses lots of information.\nMany useful tools available, e.g. for mass downloading, speech transcription, video-to-image conversion, etc."
  },
  {
    "objectID": "ccs/slides.html#text-as-data",
    "href": "ccs/slides.html#text-as-data",
    "title": "Computational Communication Science",
    "section": "Text as Data",
    "text": "Text as Data\nTextual data, often unstructured, needs to be transformed into a format suitable for computational analysis. Common representations include:\n\nStrings: The raw, sequential characters of text (e.g., “This is a sentence.”). This is the most basic form, preserving the original wording.\nTerm-Document Matrices (TDMs) / Document-Term Matrices (DTMs): Numerical representations where rows are documents and columns are terms (words), with cell values indicating term frequency (or presence) in a document. This focuses on word counts and relationships across documents.\nWord Embeddings: Vector representations of words in a high-dimensional space, where semantically similar words are located closer together. This captures semantic meaning and context."
  },
  {
    "objectID": "ccs/slides.html#text-as-strings",
    "href": "ccs/slides.html#text-as-strings",
    "title": "Computational Communication Science",
    "section": "Text as Strings",
    "text": "Text as Strings\n\n\n\n\n\n\ndocument_id\ntext_content\n\n\n\n\n1\nThe quick brown fox jumps over the lazy dog.\n\n\n2\nA lazy cat sleeps on the mat.\n\n\n3\nThe fox and the dog are friends."
  },
  {
    "objectID": "ccs/slides.html#text-as-term-document-matrix",
    "href": "ccs/slides.html#text-as-term-document-matrix",
    "title": "Computational Communication Science",
    "section": "Text as Term-Document Matrix",
    "text": "Text as Term-Document Matrix\n\nTerm-Document Matrix (TDM) quantify word occurrences.\nEach column is a unique term, each row is a document, and cells indicate how often a term appears in a document.\n\ndocument | brown | cat | dog | fox | friends | jumps | lazy | mat | quick | sleeps |\n|:|:|:-|:-|:-|:–|:|:–|:-|:|:-| | 1 | 1 | 0 | 1 | 1 | 0 | 1 | 1 | 0 | 1 | 0 | | 2 | 0 | 1 | 0 | 0 | 0 | 0 | 1 | 1 | 0 | 1 | | 3 | 0 | 0 | 1 | 1 | 1 | 0 | 0 | 0 | 0 | 0 |"
  },
  {
    "objectID": "ccs/slides.html#text-as-word-embeddings",
    "href": "ccs/slides.html#text-as-word-embeddings",
    "title": "Computational Communication Science",
    "section": "Text as Word Embeddings",
    "text": "Text as Word Embeddings\n\nWord or sentence embeddings represent text as numerical vectors, capturing semantic relationships.\nWe can use vector arithmetic to compute semantic relations like queen = king - man + woman.\nThe embedding dimensions themselves have no interpretable meaning to us.\n\nSentence ID | Dim 1 | Dim 2 | Dim 3 | Dim 4 | Dim 5 | Dim 6 | Dim 7 | Dim 8 | Dim 9 | Dim 10 |\n|:|:|:|:|:|:|:|:|:|:|:-| | 1 | 0.78 | 0.15 | 0.92 | 0.23 | 0.65 | 0.42 | 0.81 | 0.19 | 0.70 | 0.33 | | 2 | 0.21 | 0.89 | 0.10 | 0.77 | 0.33 | 0.95 | 0.05 | 0.68 | 0.25 | 0.87 | | 3 | 0.62 | 0.35 | 0.75 | 0.12 | 0.88 | 0.08 | 0.59 | 0.30 | 0.91 | 0.17 |"
  },
  {
    "objectID": "ccs/slides.html#traditional-automatic-content-analysis",
    "href": "ccs/slides.html#traditional-automatic-content-analysis",
    "title": "Computational Communication Science",
    "section": "Traditional automatic content analysis",
    "text": "Traditional automatic content analysis\n\nPreprocess the data\n\nremove stopwords or infrequent terms\nresolve anaphora or homonyms\ndetect entities, negations, fixed phrases\n\nConvert text to term-document matrix or text embeddings.\nUse unsupervised or supervised machine learning, dictionaries, or other approaches\nGet predictions (i.e. categories) per document or term\nextensive literature, e.g. Scharkow (2013);Van Atteveldt et al. (2022)"
  },
  {
    "objectID": "ccs/slides.html#large-language-models-llm",
    "href": "ccs/slides.html#large-language-models-llm",
    "title": "Computational Communication Science",
    "section": "Large Language Models (LLM)",
    "text": "Large Language Models (LLM)\n\nModels train on vast internet text (books, articles, websites) and learn contextual word embeddings, i.e. word vectors change based on surrounding words (e.g., “river bank” vs. “money bank”), capturing nuanced meaning.\nReinforcement Learning from Human Feedback (RLHF): Human rankings of LLM responses to instructions train a reward model. The LLM then optimizes its responses to maximize this reward.\nGiven a prompt, the LLM uses its learned knowledge to predict the most probable word sequence for a response.\nLLM can be used for many tasks: translation, summarization, text editing, etc.\nLLM Explainer by the FT, RLHF explainer by OpenAI"
  },
  {
    "objectID": "ccs/slides.html#large-multimodal-models-lmms",
    "href": "ccs/slides.html#large-multimodal-models-lmms",
    "title": "Computational Communication Science",
    "section": "Large Multimodal Models (LMMs)",
    "text": "Large Multimodal Models (LMMs)\n\nBeyond text, LMMs integrate modalities like text, images, audio, or video, unlike text-focused LLMs.\nSpecifically trained to understand and generate image-related content\nLMM learn to represent different modalities in a shared “embedding space,” understanding how text relates to visuals.\nLMM can perform tasks like image captioning, visual question answering, image generation from text, and object recognition."
  },
  {
    "objectID": "ccs/slides.html#content-analysis-with-llmlmm",
    "href": "ccs/slides.html#content-analysis-with-llmlmm",
    "title": "Computational Communication Science",
    "section": "Content analysis with LLM/LMM",
    "text": "Content analysis with LLM/LMM\n\nZero-Shot/Few Shot Coding, the LLM performs a task with no or few specific examples, relying solely on a clear instruction in the prompt\nBenefits:\n\nNo preprocessing or training data necessary, can perform a wide array of tasks.\nWe can simply re-use coding instructions for manual content analysis.\nOften better at understanding subtle meanings and complex tasks/contexts.\n\nDrawbacks:\n\nLLM may inherit and amplify biases present in their training data.\nUsing commercial LLM APIs can be costly, and coding is relatively slow.\nPerformance can vary significantly with minor changes in prompt wording or the selection of few-shot examples."
  },
  {
    "objectID": "ccs/slides.html#ai-based-content-analysis",
    "href": "ccs/slides.html#ai-based-content-analysis",
    "title": "Computational Communication Science",
    "section": "AI-based content analysis",
    "text": "AI-based content analysis\n\nIn this course, we use LLM/LMM for basically all content analysis tasks.\nBasic workflow is similar to manual content analysis:\n\nCollect the content data to be coded (text, image, video, etc.).\nDevelop codebook with coding instructions and examples.\nCombine instructions with text/image data to prompts for LLM API.\nCollect structured predictions for each coding unit from the model.\nMaybe combine different predictions (varying tasks, varying LLM/LMM)\n\nAlways validate with human coding!"
  },
  {
    "objectID": "ccs/slides.html#tasks",
    "href": "ccs/slides.html#tasks",
    "title": "Computational Communication Science",
    "section": "Tasks",
    "text": "Tasks\n\nInstall python tools in our RStudio server: pipx install yt-dlp vcsi whisper-ctranslate2 && pipx ensurepath, then start a new terminal.\nTry out yt-dlp in the new terminal.\nWork through the data collection examples\n\nYou need to re-download the ZIP file and data for the next sessions. Sorry!"
  },
  {
    "objectID": "ccs/slides.html#questions-about-coding-tasks",
    "href": "ccs/slides.html#questions-about-coding-tasks",
    "title": "Computational Communication Science",
    "section": "Questions about coding tasks?",
    "text": "Questions about coding tasks?\n\ntabular data and R packages\nJSON and RSS APIs\nweb scraping\ndownloading images and videos\nany additional sources?"
  },
  {
    "objectID": "ccs/slides.html#automatic-text-analysis",
    "href": "ccs/slides.html#automatic-text-analysis",
    "title": "Computational Communication Science",
    "section": "Automatic text analysis",
    "text": "Automatic text analysis\n\nworking with text strings\nbasic text analysis and regular expressions"
  },
  {
    "objectID": "ccs/slides.html#zero-shot-classification",
    "href": "ccs/slides.html#zero-shot-classification",
    "title": "Computational Communication Science",
    "section": "Zero-shot classification",
    "text": "Zero-shot classification\n\nget your API key from https://ki-chat.uni-mainz.de/\ntry out in the regular chat interface"
  },
  {
    "objectID": "ccs/slides.html#questions-about-coding-tasks-1",
    "href": "ccs/slides.html#questions-about-coding-tasks-1",
    "title": "Computational Communication Science",
    "section": "Questions about coding tasks?",
    "text": "Questions about coding tasks?\n\nstring manipulation and regular expressions\nLLM API requests\nstructured JSON responsed and types\nend-to-end coding pipelines"
  },
  {
    "objectID": "ccs/slides.html#image-and-video-coding",
    "href": "ccs/slides.html#image-and-video-coding",
    "title": "Computational Communication Science",
    "section": "Image and video coding",
    "text": "Image and video coding\n\nWhisper transcriptions and vcsi video-to-image\nLarge multimodal or visual models\nHow can we deal with multimodal content?"
  },
  {
    "objectID": "ccs/slides.html#computational-workflows",
    "href": "ccs/slides.html#computational-workflows",
    "title": "Computational Communication Science",
    "section": "Computational workflows",
    "text": "Computational workflows\n\ntry to think in successive steps\nlook up suitable code snippets to re-use\nask me or a LLM, but provide as much detailed information as possible\nsuccessively build pipelines and intermediate objects for your analysis\nget single tasks to work first, than run the same task repeatedly using map() etc."
  },
  {
    "objectID": "ccs/slides.html#term-papers",
    "href": "ccs/slides.html#term-papers",
    "title": "Computational Communication Science",
    "section": "Term papers",
    "text": "Term papers\n\nmax (!) 5000 words, max 3 co-authors\nany communication-related topic, but the method must be computational\nclassic scholarly paper, but also alternative formats\ndeadline etc. as usual\ntalk to me about research questions etc."
  },
  {
    "objectID": "ccs/slides.html#questions-about-coding-tasks-2",
    "href": "ccs/slides.html#questions-about-coding-tasks-2",
    "title": "Computational Communication Science",
    "section": "Questions about coding tasks?",
    "text": "Questions about coding tasks?\n\nvideo downloading and processing with external tools\nzero-shot image classification"
  },
  {
    "objectID": "ccs/slides.html#inspiration-for-term-papers",
    "href": "ccs/slides.html#inspiration-for-term-papers",
    "title": "Computational Communication Science",
    "section": "Inspiration for term papers",
    "text": "Inspiration for term papers\n\nexamples (broadly): Bachl & Scharkow (2015);Bachl (2018)\nblog posts: http://varianceexplained.org/r/trump-tweets/, https://observablehq.com/@uwdata/a2-example-movies-data\nthe pudding: https://pudding.cool/2024/11/love-songs/, https://pudding.cool/2023/05/country-radio/, https://pudding.cool/2017/03/punk/\ndata sources from Kaggle: Netflix content, Top Spotify Songs, TMDB Movies with Credits, etc."
  },
  {
    "objectID": "ccs/slides.html#simulation-and-agent-based-modeling",
    "href": "ccs/slides.html#simulation-and-agent-based-modeling",
    "title": "Computational Communication Science",
    "section": "Simulation and agent-based modeling",
    "text": "Simulation and agent-based modeling\nClassical Empirical Social Research\n\nTheory development in the form of verbal statements\nTheory testing based on empirical data\n(Null) hypothesis testing as a comparison of theory and empiricism\n\nSimulations\n\nTheory development in the form of algorithms/code\nGeneration of (multiple) simulated data\nComparison of simulated data with empirical data"
  },
  {
    "objectID": "ccs/slides.html#types-of-simulations",
    "href": "ccs/slides.html#types-of-simulations",
    "title": "Computational Communication Science",
    "section": "Types of Simulations",
    "text": "Types of Simulations\n\nMonte Carlo simulation\nSocial simulations (Waldherr & Wettstein, 2019)"
  },
  {
    "objectID": "ccs/slides.html#monte-carlo-simulation",
    "href": "ccs/slides.html#monte-carlo-simulation",
    "title": "Computational Communication Science",
    "section": "Monte Carlo Simulation",
    "text": "Monte Carlo Simulation\n\nAssumptions about the distribution of data in the population\nRepeated drawing of random samples from the population\nRepeated application of a procedure and analysis of the results"
  },
  {
    "objectID": "ccs/slides.html#advantages-and-disadvantages-of-monte-carlo-simulation",
    "href": "ccs/slides.html#advantages-and-disadvantages-of-monte-carlo-simulation",
    "title": "Computational Communication Science",
    "section": "Advantages and Disadvantages of Monte Carlo Simulation",
    "text": "Advantages and Disadvantages of Monte Carlo Simulation\n\nEspecially suitable for testing procedures (does my analysis do what it’s supposed to?) and for\nPower analysis (can my study find a specific effect?)\nData-generating process must be known (approximately)\nRule specification via formulas\nIsolated consideration of all cases (no interactions between agents)"
  },
  {
    "objectID": "ccs/slides.html#social-simulations",
    "href": "ccs/slides.html#social-simulations",
    "title": "Computational Communication Science",
    "section": "Social Simulations",
    "text": "Social Simulations\n\nComplex equation systems - Macromodels\nMicrosimulation (sample of agents is artificially “aged”)\nDiscrete-Event Simulations (e.g., queuing models)\nCellular Automata (e.g., Schelling’s segregation model)\nAgent-based Models"
  },
  {
    "objectID": "ccs/slides.html#agent-based-models-abm",
    "href": "ccs/slides.html#agent-based-models-abm",
    "title": "Computational Communication Science",
    "section": "Agent-Based Models (ABM)",
    "text": "Agent-Based Models (ABM)\nComputer models with the following components:\n\nAgents\nEnvironment\nRules\n\nSuitable for modeling and simulating complex systems with\n\nHeterogeneous, interacting, and adaptive agents\nDynamic, non-linear processes\nMicro-macro linkages"
  },
  {
    "objectID": "ccs/slides.html#simulation-specification",
    "href": "ccs/slides.html#simulation-specification",
    "title": "Computational Communication Science",
    "section": "Simulation Specification",
    "text": "Simulation Specification\n\nIn ABM, often relatively simple action rules\nFormal specification with a probabilistic components\nFew parameters within the agents, few for the environment\nProblem 1: Social science theory often not sufficiently specific and complete\nProblem 2: Model assumptions vs. simulation results"
  },
  {
    "objectID": "ccs/slides.html#generative-agent-models",
    "href": "ccs/slides.html#generative-agent-models",
    "title": "Computational Communication Science",
    "section": "Generative Agent Models",
    "text": "Generative Agent Models\n\nInstead of formal (programmed) rules we use verbal rules\nUse of an LLM as an agent (“Roleplaying”)\nLLM supplements verbal instructions and role with verbal responses\nResponses depend on training data and LLM quality\nVery few validation studies to date (Larooij & Törnberg, 2025)\nOften relatively naive assumptions about the generalizability of results (= substitute for human agents)"
  },
  {
    "objectID": "ccs/slides.html#hype",
    "href": "ccs/slides.html#hype",
    "title": "Computational Communication Science",
    "section": "Hype",
    "text": "Hype"
  },
  {
    "objectID": "ccs/slides.html#outlook-on-llm-based-abm",
    "href": "ccs/slides.html#outlook-on-llm-based-abm",
    "title": "Computational Communication Science",
    "section": "Outlook on LLM-based ABM",
    "text": "Outlook on LLM-based ABM\n\nDiverse application areas, especially in reception research\nRelatively simple rule specification, complex agent personas (possibly with memory)\nEasy to link with real stimuli\nInter-agent communication possible, but not yet implemented in Expected Parrot\nDisadvantages: LLM biases shine through, unclear generalizability\nLLM responses are definitely not equivalent to human respondents!"
  },
  {
    "objectID": "ccs/slides.html#tasks-for-the-next-sessions",
    "href": "ccs/slides.html#tasks-for-the-next-sessions",
    "title": "Computational Communication Science",
    "section": "Tasks for the next sessions",
    "text": "Tasks for the next sessions\n\nReview practical exercise https://stats.ifp.uni-mainz.de/ma-ccs/generative-agents.html\nComplete homework in R\nThink about your term paper\nLearn Quarto publishing (practical exercise in 2 weeks)"
  },
  {
    "objectID": "ccs/slides.html#questions-about-coding-tasks-3",
    "href": "ccs/slides.html#questions-about-coding-tasks-3",
    "title": "Computational Communication Science",
    "section": "Questions about coding tasks?",
    "text": "Questions about coding tasks?\n\nscraping headlines for testing\ncreating a persona and generating prompts\ncreating stimuli using LLM\ngenerating stimulus x persona combinations\ngetting and analyzing results"
  },
  {
    "objectID": "ccs/slides.html#writing-papers-with-statistical-analyses",
    "href": "ccs/slides.html#writing-papers-with-statistical-analyses",
    "title": "Computational Communication Science",
    "section": "Writing papers with statistical analyses",
    "text": "Writing papers with statistical analyses\n\nReproducible research is crucial for academic work.\nTraditional word processors present challenges like:\n\nCopy/paste errors: Introducing inconsistencies between code and results.\nManual citation management: Prone to errors and time-consuming.\nReproducibility concerns: Difficulty verifying results and replicating analyses."
  },
  {
    "objectID": "ccs/slides.html#knitr-and-quarto",
    "href": "ccs/slides.html#knitr-and-quarto",
    "title": "Computational Communication Science",
    "section": "Knitr and Quarto",
    "text": "Knitr and Quarto\n\nknitr integrates R code directly into your writing.\nIt automates result inclusion, saving time and reducing errors.\nQuarto uses Pandoc for versatile document conversion.\nIt combines R running code, text, and figures in one file.\nYou can easily create reports in multiple formats.\nCode Example: `{r} qplot(rnorm(100)) – simple code execution."
  },
  {
    "objectID": "ccs/slides.html#code-example",
    "href": "ccs/slides.html#code-example",
    "title": "Computational Communication Science",
    "section": "Code example",
    "text": "Code example\n\nqplot(rnorm(100))"
  },
  {
    "objectID": "ccs/slides.html#enhanced-features-for-academic-writing",
    "href": "ccs/slides.html#enhanced-features-for-academic-writing",
    "title": "Computational Communication Science",
    "section": "Enhanced Features for Academic Writing",
    "text": "Enhanced Features for Academic Writing\n\nCross-referencing simplifies citing figures and tables.\nCallouts highlight important definitions and caveats.\nAutomatic numbering of sections improves readability.\nQuarto ensures consistent formatting throughout your paper."
  },
  {
    "objectID": "ccs/slides.html#term-paper-specific-benefits",
    "href": "ccs/slides.html#term-paper-specific-benefits",
    "title": "Computational Communication Science",
    "section": "Term Paper Specific Benefits",
    "text": "Term Paper Specific Benefits\n\nEasily include statistical analyses and visualizations.\nAutomated bibliography generation with BibTeX or CSL.\nMaintain a clear record of your data analysis steps.\nShare your code and results for transparency and verification.\nCompared to Word: reduces manual formatting, copy/paste and citation errors."
  },
  {
    "objectID": "ccs/slides.html#multiple-output-formats",
    "href": "ccs/slides.html#multiple-output-formats",
    "title": "Computational Communication Science",
    "section": "Multiple Output Formats",
    "text": "Multiple Output Formats\n\nCreate PDFs for submission to professors and journals.\nGenerate HTML reports for online presentations and sharing.\nExport to Word (.docx) for compatibility with specific requirements.\nCompared to Word: simplifies converting between formats automatically.\nBeyond the Basics:\n\nSlides: Create presentation slides (like these!) directly from your document.\nCloseread: Generate scrollytelling narratives with interactive data visualizations."
  },
  {
    "objectID": "ccs/slides.html#quarto-resources",
    "href": "ccs/slides.html#quarto-resources",
    "title": "Computational Communication Science",
    "section": "Quarto Resources",
    "text": "Quarto Resources\n\nQuarto Website: https://quarto.org/\nQuarto Gallery: https://gallery.quarto.org/\nQuarto R Documentation: https://quarto.org/docs/language/r/\nCloseread https://closeread.dev/"
  },
  {
    "objectID": "ccs/slides.html#tasks-for-next-week",
    "href": "ccs/slides.html#tasks-for-next-week",
    "title": "Computational Communication Science",
    "section": "Tasks for next week",
    "text": "Tasks for next week\n\nCheck my basic term paper template, modify settings, text and code, check the resulting document.\nCollect questions you might have about how to accomplish certain tasks in Quarto."
  },
  {
    "objectID": "ccs/slides.html#visual-mode",
    "href": "ccs/slides.html#visual-mode",
    "title": "Computational Communication Science",
    "section": "Visual mode",
    "text": "Visual mode\n\nRStudio provides a visual mode for editing\nit enables you to work using menus and clicking\nespecially useful for citations, images and tables"
  },
  {
    "objectID": "ccs/slides.html#references",
    "href": "ccs/slides.html#references",
    "title": "Computational Communication Science",
    "section": "References",
    "text": "References\n\ncitations in markdown are simply @smith2022\nyou can search and include references in visual mode, based on DOI\nthe Bibtex entry is automatically generated and added to your references file\nsimilarly, there is a Zotero connector if you already use Zotero’s online library"
  },
  {
    "objectID": "ccs/slides.html#code",
    "href": "ccs/slides.html#code",
    "title": "Computational Communication Science",
    "section": "Code",
    "text": "Code\n\nfor smaller documents, writing all your code in the respective chunks works fine\nfor longer documents, move the computations etc. into a separate chunk at the top, then reference only the computed objects in the document\nalternatively: work on your code in a regular R file, and use source(\"mycode.R\") in the first chunk\nfor expensive computations use either caching or write the results into a dedicated file saveRDS(my_regression_model, \"reg1.rds\")"
  },
  {
    "objectID": "ccs/slides.html#visual-branding",
    "href": "ccs/slides.html#visual-branding",
    "title": "Computational Communication Science",
    "section": "Visual branding",
    "text": "Visual branding\n\nQuarto documents can be customized either through YAML header options like mainfont or with a brand file\nuse a _brand.yml file in the same folder, which includes many visual options like colors, fonts, styles\nworks for HTML, RevealJS slides, and some parts of PDF documents\ndoes not impact the ggplot2 graphics, for which you’d need to set theme, colors, etc. separately\n_brand.yml instructions"
  },
  {
    "objectID": "ccs/slides.html#closeread",
    "href": "ccs/slides.html#closeread",
    "title": "Computational Communication Science",
    "section": "Closeread",
    "text": "Closeread\n\na Quarto extension specifically for Scrollytelling articles\nmainly two features: stickies and focus effects (panning, scrolling, zooming, highlighting)\nstickies can be text, regular images or computed images (e.g. ggplot2 graphics)\ncreate fake animations by successively adding layers to your plot, e.g. you start with an empty plot, and add geom_*\nCloseread prize winners all have github repositories, so you can read and copy code"
  },
  {
    "objectID": "ccs/slides.html#references-1",
    "href": "ccs/slides.html#references-1",
    "title": "Computational Communication Science",
    "section": "References",
    "text": "References\n\n\n\n\nBachl, M. (2018). (Alternative) media sources in AfD-centered facebook discussions. Studies in Communication | Media, 7(2), 256–270. https://doi.org/10.5771/2192-4007-2018-2-128\n\n\nBachl, M., & Scharkow, M. (2015). Eine quantitative Bestandsaufnahme von Informationen über Krankheiten auf der deutschsprachigen Wikipedia, 2002-2014. In E. Baumann & M. Hastall (Eds.), Gesundheitskommunikation im gesellschaftlichen Wandel (pp. 93–104). Nomos. https://doi.org/10.5771/9783845264677-93\n\n\nBagchi, C., Menczer, F., Lundquist, J., Tarafdar, M., Paik, A., & Grabowicz, P. A. (2024). Social media algorithms can curb misinformation, but do they? arXiv. https://doi.org/10.48550/ARXIV.2409.18393\n\n\nClemm von Hohenberg, B., Stier, S., Cardenal, A. S., Guess, A. M., Menchen-Trevino, E., & Wojcieszak, M. (2024). Analysis of Web Browsing Data: A Guide. Social Science Computer Review, 42(6), 1479–1504. https://doi.org/10.1177/08944393241227868\n\n\nErnst, A., Dietrich, F., Rohr, B., Reinecke, L., & Scharkow, M. (2024). Revisiting the digital jukebox in daily life: Applying mood management theory to algorithmically curated music streaming environments. http://dx.doi.org/10.31234/osf.io/7eb4g\n\n\nFreelon, D. (2018). Computational Research in the Post-API Age. Political Communication, 35(4), 665–668. https://doi.org/10.1080/10584609.2018.1477506\n\n\nHaim, M. (2023). Computational Communication Science. Springer Fachmedien Wiesbaden. https://doi.org/10.1007/978-3-658-40171-9\n\n\nHilbert, M., Barnett, G., Blumenstock, J., Contractor, N., Diesner, J., Frey, S., González-Bailón, S., Lamberson, P., Pan, J., Peng, T.-Q., et al. (2019). Computational communication science: A methodological catalyzer for a maturing discipline. International Journal of Communication, 13, 3912–3934.\n\n\nJünger, J., & Gärtner, C. (2023). Computational Methods für die Sozial- und Geisteswissenschaften. Springer Fachmedien Wiesbaden. https://doi.org/10.1007/978-3-658-37747-2\n\n\nLarooij, M., & Törnberg, P. (2025). Do large language models solve the problems of agent-based modeling? A critical review of generative social simulations. https://doi.org/10.48550/ARXIV.2504.03274\n\n\nLazer, D., Pentland, A., Adamic, L., Aral, S., Barabási, A.-L., Brewer, D., Christakis, N., Contractor, N., Fowler, J., Gutmann, M., et al. (2009). Computational social science. Science, 323(5915), 721–723.\n\n\nMunger, K. (2017). Tweetment effects on the tweeted: Experimentally reducing racist harassment. Political Behavior, 39(3), 629–649. https://doi.org/10.1007/s11109-016-9373-5\n\n\nOhme, J., Araujo, T., Boeschoten, L., Freelon, D., Ram, N., Reeves, B. B., & Robinson, T. N. (2023). Digital Trace Data Collection for Social Media Effects Research: APIs, Data Donation, and (Screen) Tracking. Communication Methods and Measures, 18(2), 124–141. https://doi.org/10.1080/19312458.2023.2181319\n\n\nParry, D., & Toth, R. (2025). Extracting Meaningful Measures of Smartphone Usage from Android Event Log Data: A Methodological Primer. Computational Communication Research, 7(1), 1. https://doi.org/10.5117/ccr2025.1.8.parr\n\n\nPfiffner, N., & Friemel, Thomas. N. (2023). Leveraging Data Donations for Communication Research: Exploring Drivers Behind the Willingness to Donate. Communication Methods and Measures, 17(3), 227–249. https://doi.org/10.1080/19312458.2023.2176474\n\n\nSalganik, M. (2018). Bit by bit: Social research in the digital age. Princeton University Press.\n\n\nScharkow, M. (2013). Thematic content analysis using supervised machine learning: An empirical evaluation using german online news. Quality & Quantity, 47(2), 761–773.\n\n\nScharkow, M. (2016). The accuracy of self-reported internet use. A validation study using client log data. Communication Methods and Measures, 10(1), 13–27. https://doi.org/10.1080/19312458.2015.1118446\n\n\nVan Atteveldt, W., Trilling, D., & Calderón, C. A. (2022). Computational analysis of communication. Wiley Blackwell.\n\n\nWagner, M. W. (2023). Independence by permission. Science, 381(6656), 388–391. https://doi.org/10.1126/science.adi2430\n\n\nWaldherr, A., & Wettstein, M. (2019). Bridging the gaps: Using agent-based modeling to reconcile data and theory in computational communication science. International Journal of Communication, 13(00), 24. https://ijoc.org/index.php/ijoc/article/view/10588"
  }
]