---
title: "Computational Communication Science"
author: "Prof. Dr. Michael Scharkow"
date: today
date-format: "[Sommersemester] 2025"
format: minimalist-revealjs
df-print: kable
bibliography: references.bib
csl: https://www.zotero.org/styles/apa
lang: en
---

# Session 1 {#s1}

## CCS Module

-   *Computational Communication Science* is mostly
    -   introduction to basic literature and methods
    -   very practical exercises in computational methods
-   *Datafied Society* is more
    -   theory and research-focused
    -   (and probably has a unifying topic)
-   Write your term paper in either of the classes.

## Course credit and requirements

-   active participation, i.e. by presenting a poster on a CCS study
-   smaller homework assignments, i.e. practical computational methods
-   term paper, preferably a data-driven analysis of your choice
    -   either as traditional 3000 word research paper or
    -   alternative forms, e.g. [Scrollytelling](https://posit.co/blog/closeread-prize-winners/)
    -   fantastic example (in German): [Blaue Bücher, rosa Bücher](https://www.sueddeutsche.de/projekte/artikel/kultur/gender-wie-gleichberechtigt-sind-kinderbuecher-e970817/)
-   team work (in small teams) is more fun ad highly encouraged

## English

-   English is used for **all** spoken and written communication in the module
-   English proficiency is never judged or graded
-   the core difficulties in understanding the literature are rarely language-related
-   CCS is almost exclusively based on English publications, with two notable intro book exceptions: @jünger2023; @haim2023

## Computational Communication Science?

> A field is emerging that leverages the capacity to collect and analyze data at a scale that may reveal patterns of individual and group behaviors. [@lazerpentland2009]

> \[W\]e define computational communication science as the endeavor to understand human communication by developing and applying digital tools that often involve a high degree of automation in observational, theoretical, and experimental research. [@hilbertbarnett2019]

## Computational Communication Science

-   definition based on methods rather than study subject or theoretical background
-   somehow "big data" are involved, as are automatic methods
-   terminology and many methods mostly derived from the natural sciences and engineering
-   innovation often (but not always) happens outside academia, e.g. within companies such as Google or Meta

## Computational methods

-   the "Big 3" approaches in CCS:
    1.  automatic content analysis
    2.  analysis of digital traces and digital behavioral data
    3.  simulation and agent-based modelling
-   historically, *very* strong emphasis on web data and automatic content analysis [@vanatteveldt2022computational]
-   agent-based modeling still very niche topics (see your own study choices for next week!)

## Schedule

```{r}
library(tidyverse)
plan <- readr::read_tsv("plan.tsv") |> 
  dplyr::rename(Session = Sitzung, Date = Datum, Topic = Thema)
knitr::kable(plan)
```

## Challenges

-   data access for academic research [@freelon2018]
-   legal and ethical challenges in using private or semi-public data
-   technical and methodological issues in analyzing very large datasets
-   necessary skills for students and scholars, lack of curricula
-   computational studies are often (by necessity) interdisciplinary
-   also: literacy for reviewing computational studies in communication research

## Caveats

-   the field is moving extremely fast, that means
    -   many approaches are outdated within a few years
    -   platforms restrict access to data and prohibit distribution of replication data
    -   replication of many studies is difficult
-   starting from methods or data feels strange (and for some uncomfortable) compared to traditional empirical research
-   you will need (and learn) coding skills at least in R, but might need Python later

## Benefits

-   computational skills are **extremely** valuable on the job market, both in academia and in the real world
-   the CCS perspective challenges many traditional assumptions about how research works, i.e. by valuing creative re-operationalization of existing measures
-   with a full methods toolbox, you can conduct high-quality research even on niche topics
-   ideally the course will help you conduct better studies in your large empirical modules

## Course setup

-   "cold opening" introduction by actually reading CCS papers
-   then, for every approach:
    -   I prepare a small presentation on the basics
    -   you work through an application using R at home
    -   we discuss the practical tasks in the following session
    -   we creatively apply the new methods to our own topics
-   Bring your own ideas, data, research questions to class!

## CCS Paper Potpourri

-   10 posters overall, we'll probably do 2x 45min sessions.
-   please bring the digital versions as well, just in case
-   remember to get the posters printed ASAP
-   any questions about the studies or posters?

# Questions?

# Session 2 {#s2}

## CCS Paper Potpourri

-   2x 30 minutes/5 papers in the hallway
-   presenters:
    -   think of a 30 second summary pitch to get the conversation started
    -   note/remember questions that came up repeatedly or were noteworthy
-   audience
    -   provide interactions on the poster site (in English)!
    -   note/remember questions you'd like to discuss in class

## Discussion

1.  Which paper/study do you remember best (and why)?
2.  Which study was the most difficult to understand (and why)?
3.  Which study would you like to replicate?

## Next week

1.  Read @salganik2018, Chapter 6 and @freelon2018.
2.  Read about (at least skim the posts) the very recent Reddit/AI experiment issue:
    -   [summary article](https://retractionwatch.com/2025/04/28/experiment-using-ai-generated-posts-on-reddit-draws-fire-for-ethics-concerns/) and [follow up](https://retractionwatch.com/2025/04/29/ethics-committee-ai-llm-reddit-changemyview-university-zurich/)
    -   [original thread on Reddit](%3Chttps://www.reddit.com/r/changemyview/comments/1k8b2hj/meta_unauthorized_experiment_on_cmv_involving)

# Session 3 {#s3}

## @salganik2018 I

![](images/sal61.png)

## @salganik2018 I

-   What are the main differences between Consequentialism and Deontology?
-   How can the four mentioned ethical principles be applied to the experiment run by @munger2017?
-   In case of doubt, what priority should these principles have among themselves?

## @salganik2018 II

![](images/sal63.png)

## Research Ethics in Practice

-   Is informed consent needed for a content analysis of social media posts from members parliament?
-   What about comments on posts or public pages, e.g., from parties or politicians?
-   What about Tinder profiles or other online dating platforms?
-   What if informed consent is practically not possible?

## Group Task

(four groups, 10 minutes)

1.  Summarise the design and execution of the Reddit AI experiment.
2.  What were the main points of criticism from the Reddit mods/legal people?
3.  What were the main rebuttals from the researcher team and UZH?
4.  Can you salvage the study idea and run it ethically? How?

## API and non-API access

-   free model (e.g. Wikipedia): everyone can get the data
-   paid model (e.g. Twitter/X): you pay the platform or a third party for access
-   grant model (e.g. TikTok): you can apply for access to the API as a scholar
-   collab model (e.g. Meta): you can work with the platforms on spefific research questions
-   data donation model: you ask participants to donate their DDP (Data Download Packages)
-   independent/rogue model: you access a secret API or scrape the data otherwise

## Post-API era

-   most models have failed due to platforms (change of) self-interests [@freelon2018]
    -   commercial interests (i.e. monetization) or concerns about bad PR
    -   privacy concerns for well-meaning platforms <https://en.wikipedia.org/wiki/Netflix_Prize>
    -   "research data" incomplete and at times worse than public data
-   big collaborations like [Social Science One](https://www.buzzfeednews.com/article/craigsilverman/funders-are-ready-to-pull-out-of-facebooks-academic-data) failed miserably and publicly
-   other were challenging [@wagner2023] and ultimately problematic [@bagchi2024]

## Issues with online data

-   not all available online data can/should be considered public
-   privacy vs. reproducibility vs. ethics vs. legal questions
-   many instances of well-meaning research with unethically obtained data
-   many instances of unethical research
-   second and third order effects, e.g. LLM training data or vision models
-   plus biases, errors, etc.

## Questions

-   When can you scrape and use online data (against the platforms terms)?
-   Can you use an AI model based on unethical, possibly illegal training data?
-   How can you ensure reproducible findings with problematic data?

## Next session (in 2 weeks!)

-   Get data dwnload packages (DDP) for all major online platforms/services that you use (at least 2), e.g. from Google/Youtube, Instagram, TikTok, Spotify, Netflix, etc.
-   How? Google "data download package \[PLATFORM\]"
-   Request JSON files if given the option between multiple formats
-   Read @ohme2023

# Session 4 {#s4}

## Digital trace data

-   people's online activities are constantly logged client- and server-side
-   digital trace data from users are unobtrusively and continuously collected (by platforms or researchers)
-   trace data are (less) subject to common biases in self-reports, e.g. memory or social desirability [@scharkow2016]
-   trace data are subject to different biases, most notably selection bias (i.e. who we get data from)
-   excellent [Gesis Guides](https://www.gesis.org/en/gesis-guides/gesis-guides-to-digital-behavioral-data)

## API data

-   mostly only public **content** data with few meta data, e.g. time stamps and account information
-   pure usage data very rarely available from an API, and mostly only aggregated
-   very rare for any large platforms, severe privacy concerns for individual-level data
-   example 1: [Wikipedia Views API](https://wikimedia.org/api/rest_v1/metrics/pageviews/per-article/de.wikipedia/all-access/all-agents/Deutscher_Bundestag/daily/20240101/20250101), aggregate views per day
-   example 2: [Spotify API](https://developer.spotify.com/documentation/web-api/reference/get-recently-played), 50 recently played tracks *only* from the logged-in user, can be used for automatic data donations [@ernst2024]

## Web tracking data

-   collected from devices using dedicated tools (e.g. browser plugins) or system logs
-   technically difficult: mostly per-device, not per user tracking [@scharkow2016]
-   severe privacy concerns, even with temporary user opt-out and/or whitelisting
-   most researchers obtain tracking data from third parties (e.g. Respondi panel)
-   extensive processing necessary [@clemmvonhohenberg2024]
-   raw data is rarely public (exception: <https://zenodo.org/records/4757574>)

## Data donations

-   collected from users who requested their data download packages (DDP) from platforms
-   for large platforms, potentially very large DDP, which require filtering before upload
-   DDP uploaded via browser, using dedicated tools (e.g. [DDM](https://github.com/uzh/ddm)) or custom scripts
-   (presumably) fewer trust and privacy issues, but requires motivated and skilled respondents [@pfiffner2023]
-   single-platform, single-user, but multi-device data
-   mostly in standardized (JSON) format, but with ever-changing variables and labels

## Platform tracking + donations

-   [Zeeschuimer](https://github.com/digitalmethodsinitiative/zeeschuimer) browser extension tracks exposure to specific platforms
-   TikTok, Instagram, X/Twitter, LinkedIn, Pinterest, etc.
-   while active, logs exposure to content, along with content metadata
-   logs can be sent to online server, or downloaded and donated manually
-   works well for lab experiments, linkage studies, etc. that combine use + content data
-   requires very active participation and data management strategies

## Collecting digital trace data

![Source: @ohme2023](images/clipboard-4204924014.png)

## Questions

1.  For which platforms did you obtain DDP?
2.  How difficult was it, how hard would it be for a regular respondent?
3.  Have you looked at the data? What did you find (interesting)?

## Homework

1.  You need to complete three homework assignments, at least one per topic (trace data, content analysis, simulation/experiments).
2.  You can submit each homework until the start of the next topic (e.g. from now until we start with content analysis).
3.  You can submit in any format you like (I suggest [Quarto HTML](https://quarto.org/docs/get-started/hello/rstudio.html)), but it should be self-explanatory.
4.  You can and are encouraged to work in pairs.
5.  Homework is, as always, pass or fail.

## Practice

### [Trace data I](https://stats.ifp.uni-mainz.de/ma-ccs/individual-trace-data.html)

1.  Data Download Packages
2.  Zeeschuimer browser logs

### [Trace data II](https://stats.ifp.uni-mainz.de/ma-ccs/aggregate-trace-data.html)

3.  Aggregating and processing digital trace data
4.  Linking digital traces to survey or content data

# Session 5 {#s5}

## JSON data

1.  (How) did you successfully read your a single JSON file?
2.  How can we read multiples files? `list.files()` & `map()` functions

## Session detection

1.  Describe the basic algorithm to detect sessions.
2.  What assumptions do we have to make about user behavior?
3.  How can we define sessions for (a) browser or (b) phone log files?

@douglasparry2025;@clemmvonhohenberg2024

## Combining data

1.  What is the difference between `join()`, `left_join()` and `right_join()`?
2.  What kinds of data would you try to combine for a research project?

# Session 6 {#s6}

## Data Collection for Content Analysis

Methods for data collection (using R), from simplest to most complex:

1.  **Directly import machine-readable files** from the web (e.g., CSV).
2.  **Use pre-built R packages** for specific platforms/providers.
3.  **Obtain semi-standardized data via APIs**.
4.  **Download and process HTML content** from websites using web scraping.
5.  **Collect content or take screenshots** using remotely controlled browsers.
6.  **Request data donations** from users.

## Machine-readable files

-   Download and read structured data files (like CSV, JSON, XML) that are publicly available online
-   **Benefit:** Often the easiest and most reliable way to obtain data when available
-   **Drawbacks:** Limited availability, needs some searching
-   Examples:
    -   [Stranger Things Dialogue](https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2022/2022-10-18/stranger_things_all_dialogue.csv)
    -   [ParlSpeech V2 dataset](https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/L4OAKN)
    -   [NSF Grant Terminations](https://raw.githubusercontent.com/rfordatascience/tidytuesday/main/data/2025/2025-05-06/nsf_terminations.csv)

## Specific R packages

-   **Benefit:** Simple to install in R, pre-processed or readily accessible text data
-   **Drawbacks:** Very limited scope, sometimes not up-to-date
-   **Examples:**
    -   **`gutenbergr`**: Accessing literary works from Project Gutenberg.
    -   **`manifestoR`**: Contains annotated party manifestos from many countries and years from the Manifesto project
    -   **`taylor`**: Provides song data, including lyrics for the Taylor Swift discography

## RSS Feeds

-   **Benefit:** Provides standardized, structured updates for frequently changing content.
-   **Drawbacks:** Content often limited to headlines/summaries, may not include full text; feeds can be discontinued or change formats.

```         
<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>Minimal News Feed</title>
    <link>http://www.example.com/news</link>
    <item>
      <title>First Example News Story</title>
      <link>http://www.example.com/news/story1.html</link>
      <description>This is a brief summary of the first example news story.</description>
    </item>
  </channel>
</rss>
```

## JSON APIs

-   **Benefit:** Provides structured, flexible data (JSON format); often allows for specific queries and filters.
-   **Drawbacks:** Requires understanding of API documentation; rate limits and authentication (API keys) are common; APIs can change or be deprecated.

```{r, echo = F, results='markup'}
a = read_lines("https://api.breakingbadquotes.xyz/v1/quotes/2") 
a |> jsonlite::prettify()
```

## Web Scraping

-   involves extracting data from websites, and it's particularly useful for content where APIs might not be available.
-   HTML content is downloaded and parsed to extract specific elements (e.g., headlines, article bodies, dates).
-   **Challenges:**
    -   Layout updates can break scraping code.
    -   Websites may block or limit automated access.
    -   Content loaded via JavaScript can be harder to scrape directly.

## Scraping with remote-controlled browsers

-   Utilizes automated browsers (e.g., Chrome, Firefox) to navigate websites, interact with elements, and extract content, mimicking human user behavior.
-   **Benefit:** Can handle dynamic content (JavaScript, AJAX), login walls, and other complex interactive elements that traditional web scraping struggles with.
-   **Drawbacks:**
    -   Significantly slower than direct HTML fetching as it renders the entire page.
    -   Requires setting up browser drivers (e.g., ChromeDriver, GeckoDriver).
    -   Still detectable by sophisticated anti-bot systems.

## Data Donations

-   Involves requesting and collecting data directly from users, who volunteer to share their digital information for research purposes.
-   **Benefit:** Provides access to data from closed platforms (e.g., mobile apps, private social media groups) or highly personalized content that is otherwise inaccessible.
-   **Drawbacks:**
    -   Data format and completeness can vary widely across platforms/donors.
    -   Sample may not be representative of the broader population.
    -   Requires robust infrastructure to collect and process diverse donated data.

## Multimodal data

-   Many platforms provide text as well as images or audiovisual data.
-   Images and audiovisual data need to be downloaded before analysis.
-   We can use the multimodal data directly or convert them to text (e.g. transcripts or image descriptions).
-   Conversion to text makes things easier for us, but loses lots of information.
-   Many useful tools available, e.g. for [mass downloading](https://github.com/yt-dlp/yt-dlp), [speech transcription](https://github.com/Softcatala/whisper-ctranslate2), [video-to-image conversion](https://github.com/amietn/vcsi), etc.

# Automatic content analysis

## Text as Data

Textual data, often unstructured, needs to be transformed into a format suitable for computational analysis. Common representations include:

-   **Strings:** The raw, sequential characters of text (e.g., "This is a sentence."). This is the most basic form, preserving the original wording.
-   **Term-Document Matrices (TDMs) / Document-Term Matrices (DTMs):** Numerical representations where rows are documents and columns are terms (words), with cell values indicating term frequency (or presence) in a document. This focuses on word counts and relationships across documents.
-   **Word Embeddings:** Vector representations of words in a high-dimensional space, where semantically similar words are located closer together. This captures semantic meaning and context.

## Text as Strings

```{r}
tibble(
  document_id = 1:3,
  text_content = c(
    "The quick brown fox jumps over the lazy dog.",
    "A lazy cat sleeps on the mat.",
    "The fox and the dog are friends."
  )
)
```

## Text as Term-Document Matrix

-   Term-Document Matrix (TDM) quantify word occurrences.
-   Each column is a unique term, each row is a document, and cells indicate how often a term appears in a document.

| document \| brown \| cat \| dog \| fox \| friends \| jumps \| lazy \| mat \| quick \| sleeps \|

\|:\|:\|:-\|:-\|:-\|:--\|:\|:--\|:-\|:\|:-\| \| 1 \| 1 \| 0 \| 1 \| 1 \| 0 \| 1 \| 1 \| 0 \| 1 \| 0 \| \| 2 \| 0 \| 1 \| 0 \| 0 \| 0 \| 0 \| 1 \| 1 \| 0 \| 1 \| \| 3 \| 0 \| 0 \| 1 \| 1 \| 1 \| 0 \| 0 \| 0 \| 0 \| 0 \|

## Text as Word Embeddings

-   Word or sentence embeddings represent text as numerical vectors, capturing semantic relationships.
-   We can use vector arithmetic to compute semantic relations like `queen = king - man + woman`.
-   The embedding dimensions themselves have no interpretable meaning to us.

| Sentence ID \| Dim 1 \| Dim 2 \| Dim 3 \| Dim 4 \| Dim 5 \| Dim 6 \| Dim 7 \| Dim 8 \| Dim 9 \| Dim 10 \|

\|:\|:\|:\|:\|:\|:\|:\|:\|:\|:\|:-\| \| 1 \| 0.78 \| 0.15 \| 0.92 \| 0.23 \| 0.65 \| 0.42 \| 0.81 \| 0.19 \| 0.70 \| 0.33 \| \| 2 \| 0.21 \| 0.89 \| 0.10 \| 0.77 \| 0.33 \| 0.95 \| 0.05 \| 0.68 \| 0.25 \| 0.87 \| \| 3 \| 0.62 \| 0.35 \| 0.75 \| 0.12 \| 0.88 \| 0.08 \| 0.59 \| 0.30 \| 0.91 \| 0.17 \|

## Traditional automatic content analysis

-   Preprocess the data
    -   remove stopwords or infrequent terms
    -   resolve anaphora or homonyms
    -   detect entities, negations, fixed phrases
-   Convert text to term-document matrix or text embeddings.
-   Use unsupervised or supervised machine learning, dictionaries, or other approaches
-   Get predictions (i.e. categories) per document or term
-   extensive literature, e.g. @scharkow2013;@vanatteveldt2022computational

## Large Language Models (LLM)

-   Models train on vast internet text (books, articles, websites) and learn **contextual word embeddings**, i.e. word vectors change based on surrounding words (e.g., "river bank" vs. "money bank"), capturing nuanced meaning.
-   **Reinforcement Learning from Human Feedback (RLHF):** Human rankings of LLM responses to instructions train a reward model. The LLM then optimizes its responses to maximize this reward.
-   Given a prompt, the LLM uses its learned knowledge to **predict the most probable word sequence** for a response.
-   LLM can be used for many tasks: translation, summarization, text editing, etc.
-   [LLM Explainer by the FT](https://ig.ft.com/generative-ai/), [RLHF explainer by OpenAI](https://openai.com/index/instruction-following/)

## Large Multimodal Models (LMMs)

-   Beyond text, LMMs integrate modalities like text, images, audio, or video, unlike text-focused LLMs.
-   Specifically trained to understand and generate image-related content
-   LMM learn to represent different modalities in a shared "embedding space," understanding how text relates to visuals.
-   LMM can perform tasks like image captioning, visual question answering, image generation from text, and object recognition.

## Content analysis with LLM/LMM

-   **Zero-Shot/Few Shot Coding**, the LLM performs a task with no or few specific examples, relying solely on a clear instruction in the prompt
-   **Benefits:**
    -   No preprocessing or training data necessary, can perform a wide array of tasks.
    -   We can simply re-use coding instructions for manual content analysis.
    -   Often better at understanding subtle meanings and complex tasks/contexts.
-   **Drawbacks:**
    -   LLM may inherit and amplify biases present in their training data.
    -   Using commercial LLM APIs can be costly, and coding is relatively slow.
    -   Performance can vary significantly with minor changes in prompt wording or the selection of few-shot examples.

## AI-based content analysis

-   In this course, we use LLM/LMM for basically all content analysis tasks.
-   Basic workflow is similar to manual content analysis:
    1.  Collect the content data to be coded (text, image, video, etc.).
    2.  Develop codebook with coding instructions and examples.
    3.  Combine instructions with text/image data to prompts for LLM API.
    4.  Collect structured predictions for each coding unit from the model.
    5.  Maybe combine different predictions (varying tasks, varying LLM/LMM)
-   Always validate with human coding!

## Tasks

1.  Install python tools in our RStudio server: `pipx install yt-dlp vcsi whisper-ctranslate2 && pipx ensurepath`, then start a new terminal.
2.  Try out `yt-dlp` in the new terminal.
3.  Work through the [data collection examples](https://stats.ifp.uni-mainz.de/ma-ccs/content-data.html)

You need to re-download the ZIP file and data for the next sessions. Sorry!

# Session 7 {#s7}

## Questions about coding tasks?

-   tabular data and R packages
-   JSON and RSS APIs
-   web scraping
-   downloading images and videos
-   any additional sources?

## Automatic text analysis

-   working with text strings
-   basic text analysis and regular expressions

## Zero-shot classification

-   get your API key from <https://ki-chat.uni-mainz.de/>
-   try out in the regular chat interface

# Session 8 {#s8}

## Questions about coding tasks?

-   string manipulation and regular expressions
-   LLM API requests
-   structured JSON responsed and types
-   end-to-end coding pipelines

## Image and video coding

-   Whisper transcriptions and vcsi video-to-image

-   Large multimodal or visual models

-   How can we deal with multimodal content?

## Computational workflows

-   try to think in successive steps
-   look up suitable code snippets to re-use
-   ask me or a LLM, but provide as much detailed information as possible
-   successively build pipelines and intermediate objects for your analysis
-   get single tasks to work first, than run the same task repeatedly using `map()` etc.

## Term papers

-   max (!) 5000 words, max 3 co-authors
-   any communication-related topic, but the method must be computational
-   classic scholarly paper, but also alternative formats
-   deadline etc. as usual
-   talk to me about research questions etc.

# Session 9 {#s9}

## Questions about coding tasks?

-   video downloading and processing with external tools
-   zero-shot image classification

## Inspiration for term papers

-   examples (broadly): @bachlscharkow2015;@bachl2018
- blog posts: <http://varianceexplained.org/r/trump-tweets/>, <https://observablehq.com/@uwdata/a2-example-movies-data>
- the pudding: <https://pudding.cool/2024/11/love-songs/>, <https://pudding.cool/2023/05/country-radio/>, <https://pudding.cool/2017/03/punk/>

-   data sources from Kaggle: [Netflix content](https://www.kaggle.com/datasets/shivamb/netflix-shows), [Top Spotify Songs](https://www.kaggle.com/datasets/asaniczka/top-spotify-songs-in-73-countries-daily-updated), [TMDB Movies with Credits](https://www.kaggle.com/datasets/tmdb/tmdb-movie-metadata), etc.


## Simulation and agent-based modeling

### Classical Empirical Social Research

-   Theory development in the form of verbal statements
-   Theory testing based on empirical data
-   (Null) hypothesis testing as a comparison of theory and empiricism

### Simulations

-   Theory development in the form of algorithms/code
-   Generation of (multiple) simulated data
-   Comparison of simulated data with empirical data

## Types of Simulations

-   Monte Carlo simulation
-   Social simulations [@waldherr2019]

## Monte Carlo Simulation

-   Assumptions about the distribution of data in the population
-   Repeated drawing of random samples from the population
-   Repeated application of a procedure and analysis of the results

## Advantages and Disadvantages of Monte Carlo Simulation

-   Especially suitable for testing procedures (does my analysis do what it's supposed to?) and for
-   Power analysis (can my study find a specific effect?)
-   Data-generating process must be known (approximately)
-   Rule specification via formulas
-   Isolated consideration of all cases (no interactions between agents)

## Social Simulations

-   Complex equation systems - Macromodels
-   Microsimulation (sample of agents is artificially "aged")
-   Discrete-Event Simulations (e.g., queuing models)
-   Cellular Automata (e.g., Schelling's segregation model)
-   Agent-based Models

## Agent-Based Models (ABM)

### Computer models with the following components:

-   Agents
-   Environment
-   Rules

### Suitable for modeling and simulating complex systems with

-   Heterogeneous, interacting, and adaptive agents
-   Dynamic, non-linear processes
-   Micro-macro linkages

## Simulation Specification

-   In ABM, often relatively simple action rules
-   Formal specification with a probabilistic components
-   Few parameters within the agents, few for the environment
-   Problem 1: Social science theory often not sufficiently specific and complete
-   Problem 2: Model assumptions vs. simulation results

## Generative Agent Models

-   Instead of formal (programmed) rules we use verbal rules
-   Use of an LLM as an agent ("Roleplaying")
-   LLM supplements verbal instructions and role with verbal responses
-   Responses depend on training data and LLM quality
-   Very few validation studies to date [@larooij2025]
-   Often relatively naive assumptions about the generalizability of results (= substitute for human agents)

## Hype

![](images/clipboard-4111669777.png)

## Outlook on LLM-based ABM

-   Diverse application areas, especially in reception research
-   Relatively simple rule specification, complex agent personas (possibly with memory)
-   Easy to link with real stimuli
-   Inter-agent communication possible, but not yet implemented in Expected Parrot
-   Disadvantages: LLM biases shine through, unclear generalizability
-   LLM responses are definitely not equivalent to human respondents!

## Tasks for the next sessions

-   Review practical exercise <https://stats.ifp.uni-mainz.de/ma-ccs/generative-agents.html>
-   Complete homework in R
- Think about your term paper
- Learn Quarto publishing (practical exercise in 2 weeks)


## References
